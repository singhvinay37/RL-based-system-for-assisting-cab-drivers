{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 24, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  6.,  5.,  7.,  7.,  9.,  7.],\n",
       "       [ 5.,  6.,  5.,  7.,  7.,  9.,  7.],\n",
       "       [ 5.,  6.,  5.,  7.,  7.,  9.,  7.],\n",
       "       [ 5.,  6.,  5.,  7.,  7.,  9.,  7.],\n",
       "       [ 5.,  6.,  5.,  7.,  7.,  9.,  7.],\n",
       "       [ 5.,  6.,  5.,  7.,  7.,  9.,  7.],\n",
       "       [10.,  9.,  4., 10.,  7., 11.,  4.],\n",
       "       [10.,  9.,  4., 10.,  7., 11.,  4.],\n",
       "       [10.,  9.,  4., 10.,  7., 11.,  4.],\n",
       "       [10.,  9.,  4., 10.,  7., 11.,  4.],\n",
       "       [10.,  9.,  4., 10.,  7., 11.,  4.],\n",
       "       [10.,  9.,  4., 10.,  7., 11.,  4.],\n",
       "       [ 1.,  3.,  1.,  1.,  1.,  2.,  2.],\n",
       "       [ 1.,  3.,  1.,  1.,  1.,  2.,  2.],\n",
       "       [ 1.,  3.,  1.,  1.,  1.,  2.,  2.],\n",
       "       [ 1.,  3.,  1.,  1.,  1.,  2.,  2.],\n",
       "       [ 1.,  3.,  1.,  1.,  1.,  2.,  2.],\n",
       "       [ 1.,  3.,  1.,  1.,  1.,  2.,  2.],\n",
       "       [ 5., 11.,  7.,  8., 10.,  6.,  8.],\n",
       "       [ 5., 11.,  7.,  8., 10.,  6.,  8.],\n",
       "       [ 5., 11.,  7.,  8., 10.,  6.,  8.],\n",
       "       [ 5., 11.,  7.,  8., 10.,  6.,  8.],\n",
       "       [ 5., 11.,  7.,  8., 10.,  6.,  8.],\n",
       "       [ 5., 11.,  7.,  8., 10.,  6.,  8.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "States_track = collections.defaultdict(dict)\n",
    "print(len(States_track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_tracking_states():\n",
    "    sample_q_values = [((0, 0, 0), (0,1)), ((0, 0, 0), (0,2))]    \n",
    "    for q_values in sample_q_values:\n",
    "        state = q_values[0]\n",
    "        action = q_values[1]\n",
    "        States_track[state][action] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    #The playing agent.\n",
    "    def __init__(self, state_size, action_size, discount_factor=0.90, learning_rate=0.001,\n",
    "                 epsilon=1, epsilon_decay=0.0002, epsilon_min=0.00001):\n",
    "        \n",
    "        # action and state sizes\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # parameters\n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate   \n",
    "        self.epsilon_max = epsilon\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.batch_size = 32    \n",
    "        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        \n",
    "        # Initialize the value of the states tracked\n",
    "        self.states_tracked = []\n",
    "        self.track_state = np.array(env.state_encod_arch1([0,0,0])).reshape(1,36)\n",
    "        \n",
    "        # build the NN model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets  \n",
    "        # hidden layers\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu',kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def get_action(self, state, action_space, possible_actions_index):\n",
    "        # Write your code here:\n",
    "        # get action from model using epsilon-greedy policy\n",
    "        # Decay in Îµ after we generate each sample from the environment       \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from all possible actions\n",
    "            index = random.randrange(len(possible_actions_index))\n",
    "            action_index = possible_actions_index[index]\n",
    "            action = action_space[action_index]\n",
    "            return action_index, action\n",
    "        else:     \n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state = np.array(state).reshape(1, self.state_size)\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0]), action_space[np.argmax(q_value[0])]   \n",
    "             \n",
    "        \n",
    "    def append_sample(self, state, action, reward, next_state):     \n",
    "        # Write your code here:\n",
    "        # save sample <s,a,r,s'> to memory (replay buffer) after every action\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):    \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            # initialise two matrices - update_input and update_output\n",
    "            update_output = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            \n",
    "            actions, rewards = [], []\n",
    "            \n",
    "            # populate update_input and update_output and the lists rewards, actions\n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state = mini_batch[i]\n",
    "                update_input[i] = state\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = next_state\n",
    "                \n",
    "                # Write your code from here\n",
    "                # 1. Predict the target from earlier model\n",
    "                target = self.model.predict(update_input)\n",
    "                \n",
    "                # 2. Get the target for the Q-network\n",
    "                target_qval = self.model.predict(update_output)\n",
    "                \n",
    "                #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                # non-terminal state\n",
    "                target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "    \n",
    "    def store_q_values(self):\n",
    "        #We are keeping track of q value for state [0,0,0] and action (0,2)\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        self.states_tracked.append(q_value[0][2])\n",
    "\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ankita Paithankar\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Ankita Paithankar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "state terminated\n",
      "episode 0, reward -200.0, memory_length 157, epsilon 1.0\n",
      "Total time taken  10.475599527359009\n",
      "state terminated\n",
      "episode 1, reward 190.0, memory_length 311, epsilon 0.9998000219984667\n",
      "state terminated\n",
      "episode 2, reward -149.0, memory_length 476, epsilon 0.9996000839885345\n",
      "state terminated\n",
      "episode 3, reward -333.0, memory_length 642, epsilon 0.9994001859622058\n",
      "state terminated\n",
      "episode 4, reward -56.0, memory_length 795, epsilon 0.9992003279114846\n",
      "state terminated\n",
      "episode 5, reward -195.0, memory_length 952, epsilon 0.9990005098283767\n",
      "state terminated\n",
      "episode 6, reward -345.0, memory_length 1103, epsilon 0.9988007317048893\n",
      "state terminated\n",
      "episode 7, reward -223.0, memory_length 1253, epsilon 0.9986009935330312\n",
      "state terminated\n",
      "episode 8, reward -298.0, memory_length 1386, epsilon 0.9984012953048131\n",
      "state terminated\n",
      "episode 9, reward -277.0, memory_length 1527, epsilon 0.998201637012247\n",
      "state terminated\n",
      "episode 10, reward -157.0, memory_length 1680, epsilon 0.9980020186473464\n",
      "state terminated\n",
      "episode 11, reward -6.0, memory_length 1815, epsilon 0.9978024402021267\n",
      "state terminated\n",
      "episode 12, reward -547.0, memory_length 1960, epsilon 0.9976029016686048\n",
      "state terminated\n",
      "episode 13, reward -384.0, memory_length 2000, epsilon 0.997403403038799\n",
      "state terminated\n",
      "episode 14, reward -592.0, memory_length 2000, epsilon 0.9972039443047295\n",
      "state terminated\n",
      "episode 15, reward -457.0, memory_length 2000, epsilon 0.997004525458418\n",
      "state terminated\n",
      "episode 16, reward -343.0, memory_length 2000, epsilon 0.9968051464918875\n",
      "state terminated\n",
      "episode 17, reward -129.0, memory_length 2000, epsilon 0.9966058073971631\n",
      "state terminated\n",
      "episode 18, reward -176.0, memory_length 2000, epsilon 0.996406508166271\n",
      "state terminated\n",
      "episode 19, reward -368.0, memory_length 2000, epsilon 0.9962072487912396\n",
      "state terminated\n",
      "episode 20, reward -385.0, memory_length 2000, epsilon 0.996008029264098\n",
      "state terminated\n",
      "episode 21, reward -73.0, memory_length 2000, epsilon 0.9958088495768779\n",
      "state terminated\n",
      "episode 22, reward -401.0, memory_length 2000, epsilon 0.9956097097216119\n",
      "state terminated\n",
      "episode 23, reward -306.0, memory_length 2000, epsilon 0.9954106096903343\n",
      "state terminated\n",
      "episode 24, reward -478.0, memory_length 2000, epsilon 0.9952115494750813\n",
      "state terminated\n",
      "episode 25, reward -275.0, memory_length 2000, epsilon 0.9950125290678904\n",
      "state terminated\n",
      "episode 26, reward -412.0, memory_length 2000, epsilon 0.9948135484608008\n",
      "state terminated\n",
      "episode 27, reward -97.0, memory_length 2000, epsilon 0.9946146076458533\n",
      "state terminated\n",
      "episode 28, reward 9.0, memory_length 2000, epsilon 0.9944157066150902\n",
      "state terminated\n",
      "episode 29, reward -74.0, memory_length 2000, epsilon 0.9942168453605555\n",
      "state terminated\n",
      "episode 30, reward -375.0, memory_length 2000, epsilon 0.9940180238742947\n",
      "state terminated\n",
      "episode 31, reward 0.0, memory_length 2000, epsilon 0.993819242148355\n",
      "state terminated\n",
      "episode 32, reward -141.0, memory_length 2000, epsilon 0.9936205001747852\n",
      "state terminated\n",
      "episode 33, reward -158.0, memory_length 2000, epsilon 0.9934217979456356\n",
      "state terminated\n",
      "episode 34, reward -81.0, memory_length 2000, epsilon 0.9932231354529578\n",
      "state terminated\n",
      "episode 35, reward -198.0, memory_length 2000, epsilon 0.9930245126888058\n",
      "state terminated\n",
      "episode 36, reward -127.0, memory_length 2000, epsilon 0.9928259296452343\n",
      "state terminated\n",
      "episode 37, reward -181.0, memory_length 2000, epsilon 0.9926273863143003\n",
      "state terminated\n",
      "episode 38, reward -414.0, memory_length 2000, epsilon 0.9924288826880616\n",
      "state terminated\n",
      "episode 39, reward -302.0, memory_length 2000, epsilon 0.9922304187585785\n",
      "state terminated\n",
      "episode 40, reward -290.0, memory_length 2000, epsilon 0.9920319945179122\n",
      "state terminated\n",
      "episode 41, reward -433.0, memory_length 2000, epsilon 0.991833609958126\n",
      "state terminated\n",
      "episode 42, reward -36.0, memory_length 2000, epsilon 0.9916352650712842\n",
      "state terminated\n",
      "episode 43, reward -575.0, memory_length 2000, epsilon 0.9914369598494531\n",
      "state terminated\n",
      "episode 44, reward 123.0, memory_length 2000, epsilon 0.9912386942847006\n",
      "state terminated\n",
      "episode 45, reward -373.0, memory_length 2000, epsilon 0.9910404683690959\n",
      "state terminated\n",
      "episode 46, reward -546.0, memory_length 2000, epsilon 0.9908422820947103\n",
      "state terminated\n",
      "episode 47, reward 89.0, memory_length 2000, epsilon 0.9906441354536158\n",
      "state terminated\n",
      "episode 48, reward 34.0, memory_length 2000, epsilon 0.9904460284378871\n",
      "state terminated\n",
      "episode 49, reward -416.0, memory_length 2000, epsilon 0.9902479610395996\n",
      "state terminated\n",
      "episode 50, reward -217.0, memory_length 2000, epsilon 0.9900499332508306\n",
      "state terminated\n",
      "episode 51, reward 63.0, memory_length 2000, epsilon 0.989851945063659\n",
      "state terminated\n",
      "episode 52, reward -137.0, memory_length 2000, epsilon 0.9896539964701655\n",
      "state terminated\n",
      "episode 53, reward -128.0, memory_length 2000, epsilon 0.989456087462432\n",
      "state terminated\n",
      "episode 54, reward -58.0, memory_length 2000, epsilon 0.9892582180325421\n",
      "state terminated\n",
      "episode 55, reward -137.0, memory_length 2000, epsilon 0.989060388172581\n",
      "state terminated\n",
      "episode 56, reward -23.0, memory_length 2000, epsilon 0.9888625978746355\n",
      "state terminated\n",
      "episode 57, reward -485.0, memory_length 2000, epsilon 0.9886648471307942\n",
      "state terminated\n",
      "episode 58, reward -433.0, memory_length 2000, epsilon 0.9884671359331467\n",
      "state terminated\n",
      "episode 59, reward 166.0, memory_length 2000, epsilon 0.988269464273785\n",
      "state terminated\n",
      "episode 60, reward -433.0, memory_length 2000, epsilon 0.9880718321448019\n",
      "state terminated\n",
      "episode 61, reward -360.0, memory_length 2000, epsilon 0.9878742395382922\n",
      "state terminated\n",
      "episode 62, reward -32.0, memory_length 2000, epsilon 0.9876766864463523\n",
      "state terminated\n",
      "episode 63, reward 13.0, memory_length 2000, epsilon 0.98747917286108\n",
      "state terminated\n",
      "episode 64, reward -467.0, memory_length 2000, epsilon 0.9872816987745746\n",
      "state terminated\n",
      "episode 65, reward 63.0, memory_length 2000, epsilon 0.9870842641789374\n",
      "state terminated\n",
      "episode 66, reward -366.0, memory_length 2000, epsilon 0.9868868690662709\n",
      "state terminated\n",
      "episode 67, reward -137.0, memory_length 2000, epsilon 0.9866895134286792\n",
      "state terminated\n",
      "episode 68, reward -74.0, memory_length 2000, epsilon 0.9864921972582682\n",
      "state terminated\n",
      "episode 69, reward -185.0, memory_length 2000, epsilon 0.9862949205471453\n",
      "state terminated\n",
      "episode 70, reward -294.0, memory_length 2000, epsilon 0.9860976832874193\n",
      "state terminated\n",
      "episode 71, reward -358.0, memory_length 2000, epsilon 0.9859004854712007\n",
      "state terminated\n",
      "episode 72, reward -216.0, memory_length 2000, epsilon 0.9857033270906017\n",
      "state terminated\n",
      "episode 73, reward -225.0, memory_length 2000, epsilon 0.985506208137736\n",
      "state terminated\n",
      "episode 74, reward 12.0, memory_length 2000, epsilon 0.9853091286047186\n",
      "state terminated\n",
      "episode 75, reward -289.0, memory_length 2000, epsilon 0.9851120884836666\n",
      "state terminated\n",
      "episode 76, reward -110.0, memory_length 2000, epsilon 0.9849150877666983\n",
      "state terminated\n",
      "episode 77, reward -172.0, memory_length 2000, epsilon 0.9847181264459336\n",
      "state terminated\n",
      "episode 78, reward -258.0, memory_length 2000, epsilon 0.984521204513494\n",
      "state terminated\n",
      "episode 79, reward -384.0, memory_length 2000, epsilon 0.9843243219615028\n",
      "state terminated\n",
      "episode 80, reward -393.0, memory_length 2000, epsilon 0.9841274787820846\n",
      "state terminated\n",
      "episode 81, reward -392.0, memory_length 2000, epsilon 0.9839306749673656\n",
      "state terminated\n",
      "episode 82, reward -353.0, memory_length 2000, epsilon 0.9837339105094739\n",
      "state terminated\n",
      "episode 83, reward -171.0, memory_length 2000, epsilon 0.9835371854005385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 84, reward -237.0, memory_length 2000, epsilon 0.9833404996326909\n",
      "state terminated\n",
      "episode 85, reward -406.0, memory_length 2000, epsilon 0.9831438531980633\n",
      "state terminated\n",
      "episode 86, reward -307.0, memory_length 2000, epsilon 0.9829472460887899\n",
      "state terminated\n",
      "episode 87, reward -146.0, memory_length 2000, epsilon 0.9827506782970066\n",
      "state terminated\n",
      "episode 88, reward 8.0, memory_length 2000, epsilon 0.9825541498148506\n",
      "state terminated\n",
      "episode 89, reward -544.0, memory_length 2000, epsilon 0.9823576606344606\n",
      "state terminated\n",
      "episode 90, reward -99.0, memory_length 2000, epsilon 0.9821612107479771\n",
      "state terminated\n",
      "episode 91, reward -308.0, memory_length 2000, epsilon 0.9819648001475423\n",
      "state terminated\n",
      "episode 92, reward 31.0, memory_length 2000, epsilon 0.9817684288252996\n",
      "state terminated\n",
      "episode 93, reward -90.0, memory_length 2000, epsilon 0.9815720967733942\n",
      "state terminated\n",
      "episode 94, reward 112.0, memory_length 2000, epsilon 0.9813758039839727\n",
      "state terminated\n",
      "episode 95, reward -162.0, memory_length 2000, epsilon 0.9811795504491836\n",
      "state terminated\n",
      "episode 96, reward -78.0, memory_length 2000, epsilon 0.9809833361611765\n",
      "state terminated\n",
      "episode 97, reward -101.0, memory_length 2000, epsilon 0.9807871611121032\n",
      "state terminated\n",
      "episode 98, reward -267.0, memory_length 2000, epsilon 0.9805910252941163\n",
      "state terminated\n",
      "episode 99, reward -410.0, memory_length 2000, epsilon 0.9803949286993706\n",
      "state terminated\n",
      "episode 100, reward -279.0, memory_length 2000, epsilon 0.9801988713200221\n",
      "state terminated\n",
      "episode 101, reward -153.0, memory_length 2000, epsilon 0.9800028531482288\n",
      "state terminated\n",
      "episode 102, reward 53.0, memory_length 2000, epsilon 0.9798068741761496\n",
      "state terminated\n",
      "episode 103, reward -118.0, memory_length 2000, epsilon 0.9796109343959455\n",
      "state terminated\n",
      "episode 104, reward -167.0, memory_length 2000, epsilon 0.979415033799779\n",
      "state terminated\n",
      "episode 105, reward -189.0, memory_length 2000, epsilon 0.9792191723798138\n",
      "state terminated\n",
      "episode 106, reward -387.0, memory_length 2000, epsilon 0.9790233501282158\n",
      "state terminated\n",
      "episode 107, reward 85.0, memory_length 2000, epsilon 0.9788275670371519\n",
      "state terminated\n",
      "episode 108, reward -349.0, memory_length 2000, epsilon 0.9786318230987908\n",
      "state terminated\n",
      "episode 109, reward -252.0, memory_length 2000, epsilon 0.9784361183053027\n",
      "state terminated\n",
      "episode 110, reward -185.0, memory_length 2000, epsilon 0.9782404526488595\n",
      "state terminated\n",
      "episode 111, reward -77.0, memory_length 2000, epsilon 0.9780448261216346\n",
      "state terminated\n",
      "episode 112, reward -193.0, memory_length 2000, epsilon 0.9778492387158028\n",
      "state terminated\n",
      "episode 113, reward -411.0, memory_length 2000, epsilon 0.9776536904235407\n",
      "state terminated\n",
      "episode 114, reward -92.0, memory_length 2000, epsilon 0.9774581812370263\n",
      "state terminated\n",
      "episode 115, reward 45.0, memory_length 2000, epsilon 0.9772627111484393\n",
      "state terminated\n",
      "episode 116, reward -168.0, memory_length 2000, epsilon 0.977067280149961\n",
      "state terminated\n",
      "episode 117, reward -69.0, memory_length 2000, epsilon 0.9768718882337739\n",
      "state terminated\n",
      "episode 118, reward -221.0, memory_length 2000, epsilon 0.9766765353920625\n",
      "state terminated\n",
      "episode 119, reward 30.0, memory_length 2000, epsilon 0.9764812216170126\n",
      "state terminated\n",
      "episode 120, reward -351.0, memory_length 2000, epsilon 0.9762859469008117\n",
      "state terminated\n",
      "episode 121, reward -642.0, memory_length 2000, epsilon 0.9760907112356488\n",
      "state terminated\n",
      "episode 122, reward -356.0, memory_length 2000, epsilon 0.9758955146137146\n",
      "state terminated\n",
      "episode 123, reward -65.0, memory_length 2000, epsilon 0.975700357027201\n",
      "state terminated\n",
      "episode 124, reward -261.0, memory_length 2000, epsilon 0.9755052384683018\n",
      "state terminated\n",
      "episode 125, reward -293.0, memory_length 2000, epsilon 0.9753101589292124\n",
      "state terminated\n",
      "episode 126, reward 128.0, memory_length 2000, epsilon 0.9751151184021294\n",
      "state terminated\n",
      "episode 127, reward -42.0, memory_length 2000, epsilon 0.9749201168792513\n",
      "state terminated\n",
      "episode 128, reward -178.0, memory_length 2000, epsilon 0.974725154352778\n",
      "state terminated\n",
      "episode 129, reward 311.0, memory_length 2000, epsilon 0.974530230814911\n",
      "state terminated\n",
      "episode 130, reward 103.0, memory_length 2000, epsilon 0.9743353462578532\n",
      "state terminated\n",
      "episode 131, reward -271.0, memory_length 2000, epsilon 0.9741405006738095\n",
      "state terminated\n",
      "episode 132, reward -126.0, memory_length 2000, epsilon 0.9739456940549861\n",
      "state terminated\n",
      "episode 133, reward 47.0, memory_length 2000, epsilon 0.9737509263935904\n",
      "state terminated\n",
      "episode 134, reward -189.0, memory_length 2000, epsilon 0.973556197681832\n",
      "state terminated\n",
      "episode 135, reward -46.0, memory_length 2000, epsilon 0.9733615079119216\n",
      "state terminated\n",
      "episode 136, reward -643.0, memory_length 2000, epsilon 0.9731668570760716\n",
      "state terminated\n",
      "episode 137, reward -105.0, memory_length 2000, epsilon 0.972972245166496\n",
      "state terminated\n",
      "episode 138, reward -44.0, memory_length 2000, epsilon 0.9727776721754104\n",
      "state terminated\n",
      "episode 139, reward -365.0, memory_length 2000, epsilon 0.9725831380950318\n",
      "state terminated\n",
      "episode 140, reward -162.0, memory_length 2000, epsilon 0.9723886429175789\n",
      "state terminated\n",
      "episode 141, reward -267.0, memory_length 2000, epsilon 0.9721941866352718\n",
      "state terminated\n",
      "episode 142, reward -272.0, memory_length 2000, epsilon 0.9719997692403323\n",
      "state terminated\n",
      "episode 143, reward -158.0, memory_length 2000, epsilon 0.9718053907249836\n",
      "state terminated\n",
      "episode 144, reward -172.0, memory_length 2000, epsilon 0.9716110510814508\n",
      "state terminated\n",
      "episode 145, reward -183.0, memory_length 2000, epsilon 0.9714167503019602\n",
      "state terminated\n",
      "episode 146, reward -147.0, memory_length 2000, epsilon 0.9712224883787396\n",
      "state terminated\n",
      "episode 147, reward -186.0, memory_length 2000, epsilon 0.9710282653040188\n",
      "state terminated\n",
      "episode 148, reward -413.0, memory_length 2000, epsilon 0.9708340810700287\n",
      "state terminated\n",
      "episode 149, reward -581.0, memory_length 2000, epsilon 0.9706399356690019\n",
      "state terminated\n",
      "episode 150, reward -21.0, memory_length 2000, epsilon 0.9704458290931727\n",
      "state terminated\n",
      "episode 151, reward -114.0, memory_length 2000, epsilon 0.9702517613347768\n",
      "state terminated\n",
      "episode 152, reward -290.0, memory_length 2000, epsilon 0.9700577323860514\n",
      "state terminated\n",
      "episode 153, reward 116.0, memory_length 2000, epsilon 0.9698637422392355\n",
      "state terminated\n",
      "episode 154, reward -176.0, memory_length 2000, epsilon 0.9696697908865696\n",
      "state terminated\n",
      "episode 155, reward 149.0, memory_length 2000, epsilon 0.9694758783202951\n",
      "state terminated\n",
      "episode 156, reward -266.0, memory_length 2000, epsilon 0.9692820045326561\n",
      "state terminated\n",
      "episode 157, reward -613.0, memory_length 2000, epsilon 0.9690881695158974\n",
      "state terminated\n",
      "episode 158, reward -10.0, memory_length 2000, epsilon 0.9688943732622656\n",
      "state terminated\n",
      "episode 159, reward -251.0, memory_length 2000, epsilon 0.9687006157640088\n",
      "state terminated\n",
      "episode 160, reward -137.0, memory_length 2000, epsilon 0.9685068970133768\n",
      "state terminated\n",
      "episode 161, reward -198.0, memory_length 2000, epsilon 0.9683132170026207\n",
      "state terminated\n",
      "episode 162, reward -307.0, memory_length 2000, epsilon 0.9681195757239935\n",
      "state terminated\n",
      "episode 163, reward 206.0, memory_length 2000, epsilon 0.9679259731697496\n",
      "state terminated\n",
      "episode 164, reward 118.0, memory_length 2000, epsilon 0.9677324093321445\n",
      "state terminated\n",
      "episode 165, reward 65.0, memory_length 2000, epsilon 0.9675388842034361\n",
      "state terminated\n",
      "episode 166, reward -149.0, memory_length 2000, epsilon 0.9673453977758831\n",
      "state terminated\n",
      "episode 167, reward -33.0, memory_length 2000, epsilon 0.9671519500417461\n",
      "state terminated\n",
      "episode 168, reward -233.0, memory_length 2000, epsilon 0.9669585409932874\n",
      "state terminated\n",
      "episode 169, reward -300.0, memory_length 2000, epsilon 0.9667651706227705\n",
      "state terminated\n",
      "episode 170, reward -198.0, memory_length 2000, epsilon 0.9665718389224602\n",
      "state terminated\n",
      "episode 171, reward -6.0, memory_length 2000, epsilon 0.9663785458846238\n",
      "state terminated\n",
      "episode 172, reward -117.0, memory_length 2000, epsilon 0.9661852915015294\n",
      "state terminated\n",
      "episode 173, reward 112.0, memory_length 2000, epsilon 0.9659920757654468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 174, reward 36.0, memory_length 2000, epsilon 0.9657988986686473\n",
      "state terminated\n",
      "episode 175, reward -211.0, memory_length 2000, epsilon 0.9656057602034039\n",
      "state terminated\n",
      "episode 176, reward -226.0, memory_length 2000, epsilon 0.965412660361991\n",
      "state terminated\n",
      "episode 177, reward -226.0, memory_length 2000, epsilon 0.9652195991366846\n",
      "state terminated\n",
      "episode 178, reward 46.0, memory_length 2000, epsilon 0.9650265765197625\n",
      "state terminated\n",
      "episode 179, reward -213.0, memory_length 2000, epsilon 0.9648335925035034\n",
      "state terminated\n",
      "episode 180, reward -163.0, memory_length 2000, epsilon 0.9646406470801883\n",
      "state terminated\n",
      "episode 181, reward -230.0, memory_length 2000, epsilon 0.964447740242099\n",
      "state terminated\n",
      "episode 182, reward -200.0, memory_length 2000, epsilon 0.9642548719815195\n",
      "state terminated\n",
      "episode 183, reward 94.0, memory_length 2000, epsilon 0.964062042290735\n",
      "state terminated\n",
      "episode 184, reward -1.0, memory_length 2000, epsilon 0.9638692511620324\n",
      "state terminated\n",
      "episode 185, reward -7.0, memory_length 2000, epsilon 0.9636764985877\n",
      "state terminated\n",
      "episode 186, reward -297.0, memory_length 2000, epsilon 0.9634837845600276\n",
      "state terminated\n",
      "episode 187, reward -92.0, memory_length 2000, epsilon 0.9632911090713067\n",
      "state terminated\n",
      "episode 188, reward -60.0, memory_length 2000, epsilon 0.9630984721138303\n",
      "state terminated\n",
      "episode 189, reward -293.0, memory_length 2000, epsilon 0.9629058736798929\n",
      "state terminated\n",
      "episode 190, reward -54.0, memory_length 2000, epsilon 0.9627133137617906\n",
      "state terminated\n",
      "episode 191, reward 84.0, memory_length 2000, epsilon 0.9625207923518211\n",
      "state terminated\n",
      "episode 192, reward 106.0, memory_length 2000, epsilon 0.9623283094422832\n",
      "state terminated\n",
      "episode 193, reward -306.0, memory_length 2000, epsilon 0.962135865025478\n",
      "state terminated\n",
      "episode 194, reward -151.0, memory_length 2000, epsilon 0.9619434590937074\n",
      "state terminated\n",
      "episode 195, reward -27.0, memory_length 2000, epsilon 0.9617510916392753\n",
      "state terminated\n",
      "episode 196, reward -223.0, memory_length 2000, epsilon 0.961558762654487\n",
      "state terminated\n",
      "episode 197, reward -216.0, memory_length 2000, epsilon 0.9613664721316494\n",
      "state terminated\n",
      "episode 198, reward 40.0, memory_length 2000, epsilon 0.9611742200630707\n",
      "state terminated\n",
      "episode 199, reward -218.0, memory_length 2000, epsilon 0.960982006441061\n",
      "state terminated\n",
      "episode 200, reward -135.0, memory_length 2000, epsilon 0.9607898312579316\n",
      "state terminated\n",
      "episode 201, reward -14.0, memory_length 2000, epsilon 0.9605976945059957\n",
      "state terminated\n",
      "episode 202, reward -240.0, memory_length 2000, epsilon 0.9604055961775677\n",
      "state terminated\n",
      "episode 203, reward 148.0, memory_length 2000, epsilon 0.9602135362649636\n",
      "state terminated\n",
      "episode 204, reward -88.0, memory_length 2000, epsilon 0.9600215147605011\n",
      "state terminated\n",
      "episode 205, reward 87.0, memory_length 2000, epsilon 0.9598295316564994\n",
      "state terminated\n",
      "episode 206, reward -12.0, memory_length 2000, epsilon 0.959637586945279\n",
      "state terminated\n",
      "episode 207, reward -37.0, memory_length 2000, epsilon 0.9594456806191622\n",
      "state terminated\n",
      "episode 208, reward -27.0, memory_length 2000, epsilon 0.9592538126704729\n",
      "state terminated\n",
      "episode 209, reward -118.0, memory_length 2000, epsilon 0.9590619830915361\n",
      "state terminated\n",
      "episode 210, reward -133.0, memory_length 2000, epsilon 0.9588701918746788\n",
      "state terminated\n",
      "episode 211, reward -46.0, memory_length 2000, epsilon 0.9586784390122294\n",
      "state terminated\n",
      "episode 212, reward 250.0, memory_length 2000, epsilon 0.9584867244965175\n",
      "state terminated\n",
      "episode 213, reward -178.0, memory_length 2000, epsilon 0.9582950483198748\n",
      "state terminated\n",
      "episode 214, reward 8.0, memory_length 2000, epsilon 0.9581034104746341\n",
      "state terminated\n",
      "episode 215, reward -585.0, memory_length 2000, epsilon 0.9579118109531299\n",
      "state terminated\n",
      "episode 216, reward 317.0, memory_length 2000, epsilon 0.9577202497476984\n",
      "state terminated\n",
      "episode 217, reward -83.0, memory_length 2000, epsilon 0.957528726850677\n",
      "state terminated\n",
      "episode 218, reward -564.0, memory_length 2000, epsilon 0.9573372422544048\n",
      "state terminated\n",
      "episode 219, reward 69.0, memory_length 2000, epsilon 0.9571457959512224\n",
      "state terminated\n",
      "episode 220, reward -133.0, memory_length 2000, epsilon 0.956954387933472\n",
      "state terminated\n",
      "episode 221, reward -194.0, memory_length 2000, epsilon 0.9567630181934972\n",
      "state terminated\n",
      "episode 222, reward -172.0, memory_length 2000, epsilon 0.9565716867236432\n",
      "state terminated\n",
      "episode 223, reward 159.0, memory_length 2000, epsilon 0.9563803935162569\n",
      "state terminated\n",
      "episode 224, reward 137.0, memory_length 2000, epsilon 0.9561891385636864\n",
      "state terminated\n",
      "episode 225, reward 98.0, memory_length 2000, epsilon 0.9559979218582815\n",
      "state terminated\n",
      "episode 226, reward -2.0, memory_length 2000, epsilon 0.9558067433923938\n",
      "state terminated\n",
      "episode 227, reward 174.0, memory_length 2000, epsilon 0.9556156031583758\n",
      "state terminated\n",
      "episode 228, reward -95.0, memory_length 2000, epsilon 0.9554245011485821\n",
      "state terminated\n",
      "episode 229, reward -89.0, memory_length 2000, epsilon 0.9552334373553686\n",
      "state terminated\n",
      "episode 230, reward -450.0, memory_length 2000, epsilon 0.9550424117710927\n",
      "state terminated\n",
      "episode 231, reward -123.0, memory_length 2000, epsilon 0.9548514243881134\n",
      "state terminated\n",
      "episode 232, reward 179.0, memory_length 2000, epsilon 0.9546604751987913\n",
      "state terminated\n",
      "episode 233, reward -279.0, memory_length 2000, epsilon 0.9544695641954882\n",
      "state terminated\n",
      "episode 234, reward -156.0, memory_length 2000, epsilon 0.9542786913705679\n",
      "state terminated\n",
      "episode 235, reward -261.0, memory_length 2000, epsilon 0.9540878567163952\n",
      "state terminated\n",
      "episode 236, reward -66.0, memory_length 2000, epsilon 0.953897060225337\n",
      "state terminated\n",
      "episode 237, reward 22.0, memory_length 2000, epsilon 0.9537063018897614\n",
      "state terminated\n",
      "episode 238, reward -382.0, memory_length 2000, epsilon 0.9535155817020379\n",
      "state terminated\n",
      "episode 239, reward -113.0, memory_length 2000, epsilon 0.9533248996545379\n",
      "state terminated\n",
      "episode 240, reward 228.0, memory_length 2000, epsilon 0.953134255739634\n",
      "state terminated\n",
      "episode 241, reward -423.0, memory_length 2000, epsilon 0.9529436499497004\n",
      "state terminated\n",
      "episode 242, reward 3.0, memory_length 2000, epsilon 0.952753082277113\n",
      "state terminated\n",
      "episode 243, reward -235.0, memory_length 2000, epsilon 0.952562552714249\n",
      "state terminated\n",
      "episode 244, reward -492.0, memory_length 2000, epsilon 0.9523720612534872\n",
      "state terminated\n",
      "episode 245, reward 178.0, memory_length 2000, epsilon 0.9521816078872078\n",
      "state terminated\n",
      "episode 246, reward 49.0, memory_length 2000, epsilon 0.9519911926077931\n",
      "state terminated\n",
      "episode 247, reward 303.0, memory_length 2000, epsilon 0.9518008154076262\n",
      "state terminated\n",
      "episode 248, reward -92.0, memory_length 2000, epsilon 0.9516104762790919\n",
      "state terminated\n",
      "episode 249, reward 125.0, memory_length 2000, epsilon 0.9514201752145769\n",
      "state terminated\n",
      "episode 250, reward 137.0, memory_length 2000, epsilon 0.951229912206469\n",
      "state terminated\n",
      "episode 251, reward -265.0, memory_length 2000, epsilon 0.9510396872471577\n",
      "state terminated\n",
      "episode 252, reward 185.0, memory_length 2000, epsilon 0.950849500329034\n",
      "state terminated\n",
      "episode 253, reward -131.0, memory_length 2000, epsilon 0.9506593514444905\n",
      "state terminated\n",
      "episode 254, reward -327.0, memory_length 2000, epsilon 0.9504692405859212\n",
      "state terminated\n",
      "episode 255, reward -454.0, memory_length 2000, epsilon 0.9502791677457216\n",
      "state terminated\n",
      "episode 256, reward -159.0, memory_length 2000, epsilon 0.9500891329162888\n",
      "state terminated\n",
      "episode 257, reward -321.0, memory_length 2000, epsilon 0.9498991360900215\n",
      "state terminated\n",
      "episode 258, reward -243.0, memory_length 2000, epsilon 0.9497091772593198\n",
      "state terminated\n",
      "episode 259, reward 54.0, memory_length 2000, epsilon 0.9495192564165853\n",
      "state terminated\n",
      "episode 260, reward 194.0, memory_length 2000, epsilon 0.9493293735542211\n",
      "state terminated\n",
      "episode 261, reward 105.0, memory_length 2000, epsilon 0.9491395286646321\n",
      "state terminated\n",
      "episode 262, reward -388.0, memory_length 2000, epsilon 0.9489497217402242\n",
      "state terminated\n",
      "episode 263, reward -441.0, memory_length 2000, epsilon 0.9487599527734054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 264, reward -72.0, memory_length 2000, epsilon 0.9485702217565849\n",
      "state terminated\n",
      "episode 265, reward -235.0, memory_length 2000, epsilon 0.9483805286821734\n",
      "state terminated\n",
      "episode 266, reward -17.0, memory_length 2000, epsilon 0.948190873542583\n",
      "state terminated\n",
      "episode 267, reward -184.0, memory_length 2000, epsilon 0.9480012563302278\n",
      "state terminated\n",
      "episode 268, reward -20.0, memory_length 2000, epsilon 0.947811677037523\n",
      "state terminated\n",
      "episode 269, reward -171.0, memory_length 2000, epsilon 0.9476221356568854\n",
      "state terminated\n",
      "episode 270, reward 125.0, memory_length 2000, epsilon 0.9474326321807333\n",
      "state terminated\n",
      "episode 271, reward -108.0, memory_length 2000, epsilon 0.9472431666014866\n",
      "state terminated\n",
      "episode 272, reward 219.0, memory_length 2000, epsilon 0.9470537389115666\n",
      "state terminated\n",
      "episode 273, reward 72.0, memory_length 2000, epsilon 0.9468643491033965\n",
      "state terminated\n",
      "episode 274, reward -9.0, memory_length 2000, epsilon 0.9466749971694004\n",
      "state terminated\n",
      "episode 275, reward -117.0, memory_length 2000, epsilon 0.9464856831020043\n",
      "state terminated\n",
      "episode 276, reward -80.0, memory_length 2000, epsilon 0.9462964068936356\n",
      "state terminated\n",
      "episode 277, reward -194.0, memory_length 2000, epsilon 0.9461071685367235\n",
      "state terminated\n",
      "episode 278, reward 93.0, memory_length 2000, epsilon 0.945917968023698\n",
      "state terminated\n",
      "episode 279, reward -37.0, memory_length 2000, epsilon 0.9457288053469916\n",
      "state terminated\n",
      "episode 280, reward -231.0, memory_length 2000, epsilon 0.9455396804990374\n",
      "state terminated\n",
      "episode 281, reward -23.0, memory_length 2000, epsilon 0.9453505934722706\n",
      "state terminated\n",
      "episode 282, reward -294.0, memory_length 2000, epsilon 0.9451615442591275\n",
      "state terminated\n",
      "episode 283, reward 292.0, memory_length 2000, epsilon 0.9449725328520465\n",
      "state terminated\n",
      "episode 284, reward 126.0, memory_length 2000, epsilon 0.9447835592434668\n",
      "state terminated\n",
      "episode 285, reward -284.0, memory_length 2000, epsilon 0.9445946234258297\n",
      "state terminated\n",
      "episode 286, reward -14.0, memory_length 2000, epsilon 0.9444057253915776\n",
      "state terminated\n",
      "episode 287, reward -249.0, memory_length 2000, epsilon 0.9442168651331546\n",
      "state terminated\n",
      "episode 288, reward 126.0, memory_length 2000, epsilon 0.9440280426430064\n",
      "state terminated\n",
      "episode 289, reward -249.0, memory_length 2000, epsilon 0.94383925791358\n",
      "state terminated\n",
      "episode 290, reward -156.0, memory_length 2000, epsilon 0.9436505109373241\n",
      "state terminated\n",
      "episode 291, reward -114.0, memory_length 2000, epsilon 0.9434618017066888\n",
      "state terminated\n",
      "episode 292, reward 39.0, memory_length 2000, epsilon 0.9432731302141256\n",
      "state terminated\n",
      "episode 293, reward -72.0, memory_length 2000, epsilon 0.9430844964520878\n",
      "state terminated\n",
      "episode 294, reward 74.0, memory_length 2000, epsilon 0.94289590041303\n",
      "state terminated\n",
      "episode 295, reward -188.0, memory_length 2000, epsilon 0.9427073420894081\n",
      "state terminated\n",
      "episode 296, reward 324.0, memory_length 2000, epsilon 0.9425188214736803\n",
      "state terminated\n",
      "episode 297, reward 83.0, memory_length 2000, epsilon 0.9423303385583053\n",
      "state terminated\n",
      "episode 298, reward -76.0, memory_length 2000, epsilon 0.9421418933357442\n",
      "state terminated\n",
      "episode 299, reward -357.0, memory_length 2000, epsilon 0.9419534857984587\n",
      "state terminated\n",
      "episode 300, reward 164.0, memory_length 2000, epsilon 0.9417651159389129\n",
      "state terminated\n",
      "episode 301, reward -74.0, memory_length 2000, epsilon 0.9415767837495718\n",
      "state terminated\n",
      "episode 302, reward 311.0, memory_length 2000, epsilon 0.9413884892229022\n",
      "state terminated\n",
      "episode 303, reward 376.0, memory_length 2000, epsilon 0.9412002323513723\n",
      "state terminated\n",
      "episode 304, reward 180.0, memory_length 2000, epsilon 0.9410120131274518\n",
      "state terminated\n",
      "episode 305, reward 161.0, memory_length 2000, epsilon 0.9408238315436119\n",
      "state terminated\n",
      "episode 306, reward -8.0, memory_length 2000, epsilon 0.9406356875923255\n",
      "state terminated\n",
      "episode 307, reward 53.0, memory_length 2000, epsilon 0.9404475812660668\n",
      "state terminated\n",
      "episode 308, reward -60.0, memory_length 2000, epsilon 0.9402595125573113\n",
      "state terminated\n",
      "episode 309, reward -234.0, memory_length 2000, epsilon 0.9400714814585365\n",
      "state terminated\n",
      "episode 310, reward 147.0, memory_length 2000, epsilon 0.939883487962221\n",
      "state terminated\n",
      "episode 311, reward -65.0, memory_length 2000, epsilon 0.9396955320608452\n",
      "state terminated\n",
      "episode 312, reward -105.0, memory_length 2000, epsilon 0.9395076137468908\n",
      "state terminated\n",
      "episode 313, reward -248.0, memory_length 2000, epsilon 0.9393197330128411\n",
      "state terminated\n",
      "episode 314, reward -61.0, memory_length 2000, epsilon 0.9391318898511808\n",
      "state terminated\n",
      "episode 315, reward 1.0, memory_length 2000, epsilon 0.9389440842543963\n",
      "state terminated\n",
      "episode 316, reward 52.0, memory_length 2000, epsilon 0.9387563162149752\n",
      "state terminated\n",
      "episode 317, reward -81.0, memory_length 2000, epsilon 0.938568585725407\n",
      "state terminated\n",
      "episode 318, reward 309.0, memory_length 2000, epsilon 0.9383808927781824\n",
      "state terminated\n",
      "episode 319, reward -56.0, memory_length 2000, epsilon 0.9381932373657934\n",
      "state terminated\n",
      "episode 320, reward -114.0, memory_length 2000, epsilon 0.9380056194807341\n",
      "state terminated\n",
      "episode 321, reward 3.0, memory_length 2000, epsilon 0.9378180391154998\n",
      "state terminated\n",
      "episode 322, reward -19.0, memory_length 2000, epsilon 0.9376304962625872\n",
      "state terminated\n",
      "episode 323, reward 174.0, memory_length 2000, epsilon 0.9374429909144945\n",
      "state terminated\n",
      "episode 324, reward 401.0, memory_length 2000, epsilon 0.9372555230637216\n",
      "state terminated\n",
      "episode 325, reward -356.0, memory_length 2000, epsilon 0.9370680927027697\n",
      "state terminated\n",
      "episode 326, reward -327.0, memory_length 2000, epsilon 0.9368806998241416\n",
      "state terminated\n",
      "episode 327, reward 269.0, memory_length 2000, epsilon 0.9366933444203417\n",
      "state terminated\n",
      "episode 328, reward 223.0, memory_length 2000, epsilon 0.9365060264838756\n",
      "state terminated\n",
      "episode 329, reward 99.0, memory_length 2000, epsilon 0.9363187460072508\n",
      "state terminated\n",
      "episode 330, reward 28.0, memory_length 2000, epsilon 0.936131502982976\n",
      "state terminated\n",
      "episode 331, reward -213.0, memory_length 2000, epsilon 0.9359442974035613\n",
      "state terminated\n",
      "episode 332, reward -173.0, memory_length 2000, epsilon 0.9357571292615187\n",
      "state terminated\n",
      "episode 333, reward 171.0, memory_length 2000, epsilon 0.9355699985493613\n",
      "state terminated\n",
      "episode 334, reward 26.0, memory_length 2000, epsilon 0.9353829052596041\n",
      "state terminated\n",
      "episode 335, reward -84.0, memory_length 2000, epsilon 0.9351958493847632\n",
      "state terminated\n",
      "episode 336, reward 226.0, memory_length 2000, epsilon 0.9350088309173564\n",
      "state terminated\n",
      "episode 337, reward -68.0, memory_length 2000, epsilon 0.9348218498499029\n",
      "state terminated\n",
      "episode 338, reward 219.0, memory_length 2000, epsilon 0.9346349061749235\n",
      "state terminated\n",
      "episode 339, reward -222.0, memory_length 2000, epsilon 0.9344479998849405\n",
      "state terminated\n",
      "episode 340, reward -45.0, memory_length 2000, epsilon 0.9342611309724778\n",
      "state terminated\n",
      "episode 341, reward 246.0, memory_length 2000, epsilon 0.9340742994300604\n",
      "state terminated\n",
      "episode 342, reward 9.0, memory_length 2000, epsilon 0.9338875052502149\n",
      "state terminated\n",
      "episode 343, reward 257.0, memory_length 2000, epsilon 0.9337007484254698\n",
      "state terminated\n",
      "episode 344, reward -127.0, memory_length 2000, epsilon 0.9335140289483549\n",
      "state terminated\n",
      "episode 345, reward 103.0, memory_length 2000, epsilon 0.9333273468114012\n",
      "state terminated\n",
      "episode 346, reward -478.0, memory_length 2000, epsilon 0.9331407020071415\n",
      "state terminated\n",
      "episode 347, reward 118.0, memory_length 2000, epsilon 0.93295409452811\n",
      "state terminated\n",
      "episode 348, reward -198.0, memory_length 2000, epsilon 0.9327675243668423\n",
      "state terminated\n",
      "episode 349, reward -142.0, memory_length 2000, epsilon 0.9325809915158759\n",
      "state terminated\n",
      "episode 350, reward -97.0, memory_length 2000, epsilon 0.9323944959677493\n",
      "state terminated\n",
      "episode 351, reward -16.0, memory_length 2000, epsilon 0.9322080377150024\n",
      "state terminated\n",
      "episode 352, reward -111.0, memory_length 2000, epsilon 0.9320216167501774\n",
      "state terminated\n",
      "episode 353, reward 8.0, memory_length 2000, epsilon 0.931835233065817\n",
      "state terminated\n",
      "episode 354, reward 103.0, memory_length 2000, epsilon 0.9316488866544661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 355, reward -13.0, memory_length 2000, epsilon 0.9314625775086708\n",
      "state terminated\n",
      "episode 356, reward 41.0, memory_length 2000, epsilon 0.9312763056209787\n",
      "state terminated\n",
      "episode 357, reward 295.0, memory_length 2000, epsilon 0.931090070983939\n",
      "state terminated\n",
      "episode 358, reward -147.0, memory_length 2000, epsilon 0.9309038735901023\n",
      "state terminated\n",
      "episode 359, reward 208.0, memory_length 2000, epsilon 0.9307177134320206\n",
      "state terminated\n",
      "episode 360, reward -288.0, memory_length 2000, epsilon 0.9305315905022477\n",
      "state terminated\n",
      "episode 361, reward -105.0, memory_length 2000, epsilon 0.9303455047933383\n",
      "state terminated\n",
      "episode 362, reward 148.0, memory_length 2000, epsilon 0.9301594562978494\n",
      "state terminated\n",
      "episode 363, reward -69.0, memory_length 2000, epsilon 0.9299734450083388\n",
      "state terminated\n",
      "episode 364, reward -81.0, memory_length 2000, epsilon 0.9297874709173661\n",
      "state terminated\n",
      "episode 365, reward -90.0, memory_length 2000, epsilon 0.9296015340174925\n",
      "state terminated\n",
      "episode 366, reward -160.0, memory_length 2000, epsilon 0.9294156343012803\n",
      "state terminated\n",
      "episode 367, reward 72.0, memory_length 2000, epsilon 0.9292297717612935\n",
      "state terminated\n",
      "episode 368, reward 463.0, memory_length 2000, epsilon 0.9290439463900978\n",
      "state terminated\n",
      "episode 369, reward 29.0, memory_length 2000, epsilon 0.9288581581802601\n",
      "state terminated\n",
      "episode 370, reward 207.0, memory_length 2000, epsilon 0.9286724071243488\n",
      "state terminated\n",
      "episode 371, reward 18.0, memory_length 2000, epsilon 0.9284866932149339\n",
      "state terminated\n",
      "episode 372, reward 19.0, memory_length 2000, epsilon 0.9283010164445868\n",
      "state terminated\n",
      "episode 373, reward 157.0, memory_length 2000, epsilon 0.9281153768058806\n",
      "state terminated\n",
      "episode 374, reward 287.0, memory_length 2000, epsilon 0.9279297742913896\n",
      "state terminated\n",
      "episode 375, reward -4.0, memory_length 2000, epsilon 0.9277442088936896\n",
      "state terminated\n",
      "episode 376, reward 36.0, memory_length 2000, epsilon 0.9275586806053582\n",
      "state terminated\n",
      "episode 377, reward -243.0, memory_length 2000, epsilon 0.927373189418974\n",
      "state terminated\n",
      "episode 378, reward 300.0, memory_length 2000, epsilon 0.9271877353271175\n",
      "state terminated\n",
      "episode 379, reward -37.0, memory_length 2000, epsilon 0.9270023183223707\n",
      "state terminated\n",
      "episode 380, reward -147.0, memory_length 2000, epsilon 0.9268169383973166\n",
      "state terminated\n",
      "episode 381, reward 13.0, memory_length 2000, epsilon 0.9266315955445402\n",
      "state terminated\n",
      "episode 382, reward -183.0, memory_length 2000, epsilon 0.9264462897566278\n",
      "state terminated\n",
      "episode 383, reward 252.0, memory_length 2000, epsilon 0.926261021026167\n",
      "state terminated\n",
      "episode 384, reward 202.0, memory_length 2000, epsilon 0.9260757893457474\n",
      "state terminated\n",
      "episode 385, reward -344.0, memory_length 2000, epsilon 0.9258905947079593\n",
      "state terminated\n",
      "episode 386, reward 162.0, memory_length 2000, epsilon 0.9257054371053952\n",
      "state terminated\n",
      "episode 387, reward 60.0, memory_length 2000, epsilon 0.9255203165306486\n",
      "state terminated\n",
      "episode 388, reward -6.0, memory_length 2000, epsilon 0.9253352329763149\n",
      "state terminated\n",
      "episode 389, reward 375.0, memory_length 2000, epsilon 0.9251501864349906\n",
      "state terminated\n",
      "episode 390, reward -140.0, memory_length 2000, epsilon 0.9249651768992738\n",
      "state terminated\n",
      "episode 391, reward 92.0, memory_length 2000, epsilon 0.9247802043617643\n",
      "state terminated\n",
      "episode 392, reward 107.0, memory_length 2000, epsilon 0.9245952688150632\n",
      "state terminated\n",
      "episode 393, reward 65.0, memory_length 2000, epsilon 0.9244103702517728\n",
      "state terminated\n",
      "episode 394, reward 40.0, memory_length 2000, epsilon 0.9242255086644973\n",
      "state terminated\n",
      "episode 395, reward -43.0, memory_length 2000, epsilon 0.9240406840458423\n",
      "state terminated\n",
      "episode 396, reward -19.0, memory_length 2000, epsilon 0.9238558963884148\n",
      "state terminated\n",
      "episode 397, reward 20.0, memory_length 2000, epsilon 0.9236711456848234\n",
      "state terminated\n",
      "episode 398, reward 53.0, memory_length 2000, epsilon 0.9234864319276779\n",
      "state terminated\n",
      "episode 399, reward -73.0, memory_length 2000, epsilon 0.9233017551095897\n",
      "state terminated\n",
      "episode 400, reward 242.0, memory_length 2000, epsilon 0.9231171152231719\n",
      "state terminated\n",
      "episode 401, reward -5.0, memory_length 2000, epsilon 0.9229325122610388\n",
      "state terminated\n",
      "episode 402, reward 126.0, memory_length 2000, epsilon 0.9227479462158064\n",
      "state terminated\n",
      "episode 403, reward -207.0, memory_length 2000, epsilon 0.9225634170800919\n",
      "state terminated\n",
      "episode 404, reward 188.0, memory_length 2000, epsilon 0.9223789248465142\n",
      "state terminated\n",
      "episode 405, reward 121.0, memory_length 2000, epsilon 0.9221944695076936\n",
      "state terminated\n",
      "episode 406, reward 47.0, memory_length 2000, epsilon 0.922010051056252\n",
      "state terminated\n",
      "episode 407, reward 159.0, memory_length 2000, epsilon 0.9218256694848124\n",
      "state terminated\n",
      "episode 408, reward -118.0, memory_length 2000, epsilon 0.9216413247859999\n",
      "state terminated\n",
      "episode 409, reward 187.0, memory_length 2000, epsilon 0.9214570169524404\n",
      "state terminated\n",
      "episode 410, reward 216.0, memory_length 2000, epsilon 0.9212727459767618\n",
      "state terminated\n",
      "episode 411, reward -13.0, memory_length 2000, epsilon 0.9210885118515929\n",
      "state terminated\n",
      "episode 412, reward 6.0, memory_length 2000, epsilon 0.9209043145695648\n",
      "state terminated\n",
      "episode 413, reward 34.0, memory_length 2000, epsilon 0.9207201541233094\n",
      "state terminated\n",
      "episode 414, reward 252.0, memory_length 2000, epsilon 0.9205360305054603\n",
      "state terminated\n",
      "episode 415, reward -225.0, memory_length 2000, epsilon 0.9203519437086525\n",
      "state terminated\n",
      "episode 416, reward -48.0, memory_length 2000, epsilon 0.9201678937255225\n",
      "state terminated\n",
      "episode 417, reward 67.0, memory_length 2000, epsilon 0.9199838805487086\n",
      "state terminated\n",
      "episode 418, reward -29.0, memory_length 2000, epsilon 0.9197999041708498\n",
      "state terminated\n",
      "episode 419, reward 287.0, memory_length 2000, epsilon 0.9196159645845874\n",
      "state terminated\n",
      "episode 420, reward 413.0, memory_length 2000, epsilon 0.9194320617825638\n",
      "state terminated\n",
      "episode 421, reward 229.0, memory_length 2000, epsilon 0.9192481957574226\n",
      "state terminated\n",
      "episode 422, reward -131.0, memory_length 2000, epsilon 0.9190643665018094\n",
      "state terminated\n",
      "episode 423, reward 453.0, memory_length 2000, epsilon 0.9188805740083711\n",
      "state terminated\n",
      "episode 424, reward -86.0, memory_length 2000, epsilon 0.9186968182697558\n",
      "state terminated\n",
      "episode 425, reward -146.0, memory_length 2000, epsilon 0.9185130992786134\n",
      "state terminated\n",
      "episode 426, reward -383.0, memory_length 2000, epsilon 0.918329417027595\n",
      "state terminated\n",
      "episode 427, reward 241.0, memory_length 2000, epsilon 0.9181457715093534\n",
      "state terminated\n",
      "episode 428, reward -68.0, memory_length 2000, epsilon 0.9179621627165429\n",
      "state terminated\n",
      "episode 429, reward 191.0, memory_length 2000, epsilon 0.917778590641819\n",
      "state terminated\n",
      "episode 430, reward 287.0, memory_length 2000, epsilon 0.9175950552778387\n",
      "state terminated\n",
      "episode 431, reward -131.0, memory_length 2000, epsilon 0.9174115566172609\n",
      "state terminated\n",
      "episode 432, reward 39.0, memory_length 2000, epsilon 0.9172280946527455\n",
      "state terminated\n",
      "episode 433, reward -74.0, memory_length 2000, epsilon 0.917044669376954\n",
      "state terminated\n",
      "episode 434, reward 747.0, memory_length 2000, epsilon 0.9168612807825492\n",
      "state terminated\n",
      "episode 435, reward -55.0, memory_length 2000, epsilon 0.9166779288621959\n",
      "state terminated\n",
      "episode 436, reward -37.0, memory_length 2000, epsilon 0.9164946136085599\n",
      "state terminated\n",
      "episode 437, reward 141.0, memory_length 2000, epsilon 0.9163113350143086\n",
      "state terminated\n",
      "episode 438, reward 85.0, memory_length 2000, epsilon 0.9161280930721107\n",
      "state terminated\n",
      "episode 439, reward 299.0, memory_length 2000, epsilon 0.9159448877746368\n",
      "state terminated\n",
      "episode 440, reward -262.0, memory_length 2000, epsilon 0.9157617191145584\n",
      "state terminated\n",
      "episode 441, reward -185.0, memory_length 2000, epsilon 0.915578587084549\n",
      "state terminated\n",
      "episode 442, reward 201.0, memory_length 2000, epsilon 0.9153954916772831\n",
      "state terminated\n",
      "episode 443, reward 69.0, memory_length 2000, epsilon 0.915212432885437\n",
      "state terminated\n",
      "episode 444, reward 28.0, memory_length 2000, epsilon 0.9150294107016883\n",
      "state terminated\n",
      "episode 445, reward 222.0, memory_length 2000, epsilon 0.9148464251187162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 446, reward -182.0, memory_length 2000, epsilon 0.9146634761292013\n",
      "state terminated\n",
      "episode 447, reward 136.0, memory_length 2000, epsilon 0.9144805637258255\n",
      "state terminated\n",
      "episode 448, reward 130.0, memory_length 2000, epsilon 0.9142976879012723\n",
      "state terminated\n",
      "episode 449, reward -140.0, memory_length 2000, epsilon 0.9141148486482269\n",
      "state terminated\n",
      "episode 450, reward 387.0, memory_length 2000, epsilon 0.9139320459593755\n",
      "state terminated\n",
      "episode 451, reward 282.0, memory_length 2000, epsilon 0.913749279827406\n",
      "state terminated\n",
      "episode 452, reward -89.0, memory_length 2000, epsilon 0.9135665502450079\n",
      "state terminated\n",
      "episode 453, reward 66.0, memory_length 2000, epsilon 0.9133838572048719\n",
      "state terminated\n",
      "episode 454, reward 99.0, memory_length 2000, epsilon 0.9132012006996902\n",
      "state terminated\n",
      "episode 455, reward 63.0, memory_length 2000, epsilon 0.9130185807221568\n",
      "state terminated\n",
      "episode 456, reward 94.0, memory_length 2000, epsilon 0.9128359972649667\n",
      "state terminated\n",
      "episode 457, reward 220.0, memory_length 2000, epsilon 0.9126534503208166\n",
      "state terminated\n",
      "episode 458, reward 309.0, memory_length 2000, epsilon 0.9124709398824047\n",
      "state terminated\n",
      "episode 459, reward 385.0, memory_length 2000, epsilon 0.9122884659424304\n",
      "state terminated\n",
      "episode 460, reward 43.0, memory_length 2000, epsilon 0.9121060284935949\n",
      "state terminated\n",
      "episode 461, reward -40.0, memory_length 2000, epsilon 0.9119236275286008\n",
      "state terminated\n",
      "episode 462, reward 273.0, memory_length 2000, epsilon 0.9117412630401518\n",
      "state terminated\n",
      "episode 463, reward -101.0, memory_length 2000, epsilon 0.9115589350209534\n",
      "state terminated\n",
      "episode 464, reward -125.0, memory_length 2000, epsilon 0.9113766434637125\n",
      "state terminated\n",
      "episode 465, reward -10.0, memory_length 2000, epsilon 0.9111943883611375\n",
      "state terminated\n",
      "episode 466, reward 127.0, memory_length 2000, epsilon 0.9110121697059382\n",
      "state terminated\n",
      "episode 467, reward -6.0, memory_length 2000, epsilon 0.9108299874908259\n",
      "state terminated\n",
      "episode 468, reward -78.0, memory_length 2000, epsilon 0.9106478417085131\n",
      "state terminated\n",
      "episode 469, reward 171.0, memory_length 2000, epsilon 0.910465732351714\n",
      "state terminated\n",
      "episode 470, reward 213.0, memory_length 2000, epsilon 0.9102836594131446\n",
      "state terminated\n",
      "episode 471, reward -135.0, memory_length 2000, epsilon 0.9101016228855215\n",
      "state terminated\n",
      "episode 472, reward 28.0, memory_length 2000, epsilon 0.9099196227615634\n",
      "state terminated\n",
      "episode 473, reward 195.0, memory_length 2000, epsilon 0.9097376590339904\n",
      "state terminated\n",
      "episode 474, reward 399.0, memory_length 2000, epsilon 0.9095557316955238\n",
      "state terminated\n",
      "episode 475, reward 297.0, memory_length 2000, epsilon 0.9093738407388867\n",
      "state terminated\n",
      "episode 476, reward 126.0, memory_length 2000, epsilon 0.9091919861568033\n",
      "state terminated\n",
      "episode 477, reward -100.0, memory_length 2000, epsilon 0.9090101679419995\n",
      "state terminated\n",
      "episode 478, reward 243.0, memory_length 2000, epsilon 0.9088283860872026\n",
      "state terminated\n",
      "episode 479, reward -258.0, memory_length 2000, epsilon 0.9086466405851411\n",
      "state terminated\n",
      "episode 480, reward -50.0, memory_length 2000, epsilon 0.9084649314285455\n",
      "state terminated\n",
      "episode 481, reward -136.0, memory_length 2000, epsilon 0.9082832586101471\n",
      "state terminated\n",
      "episode 482, reward -14.0, memory_length 2000, epsilon 0.9081016221226794\n",
      "state terminated\n",
      "episode 483, reward 9.0, memory_length 2000, epsilon 0.9079200219588766\n",
      "state terminated\n",
      "episode 484, reward 254.0, memory_length 2000, epsilon 0.9077384581114747\n",
      "state terminated\n",
      "episode 485, reward 130.0, memory_length 2000, epsilon 0.9075569305732114\n",
      "state terminated\n",
      "episode 486, reward 316.0, memory_length 2000, epsilon 0.9073754393368253\n",
      "state terminated\n",
      "episode 487, reward 45.0, memory_length 2000, epsilon 0.9071939843950569\n",
      "state terminated\n",
      "episode 488, reward 0.0, memory_length 2000, epsilon 0.9070125657406481\n",
      "state terminated\n",
      "episode 489, reward 55.0, memory_length 2000, epsilon 0.9068311833663419\n",
      "state terminated\n",
      "episode 490, reward -1.0, memory_length 2000, epsilon 0.9066498372648834\n",
      "state terminated\n",
      "episode 491, reward 395.0, memory_length 2000, epsilon 0.9064685274290184\n",
      "state terminated\n",
      "episode 492, reward -1.0, memory_length 2000, epsilon 0.9062872538514944\n",
      "state terminated\n",
      "episode 493, reward -168.0, memory_length 2000, epsilon 0.9061060165250611\n",
      "state terminated\n",
      "episode 494, reward 213.0, memory_length 2000, epsilon 0.9059248154424683\n",
      "state terminated\n",
      "episode 495, reward 28.0, memory_length 2000, epsilon 0.9057436505964682\n",
      "state terminated\n",
      "episode 496, reward 183.0, memory_length 2000, epsilon 0.9055625219798143\n",
      "state terminated\n",
      "episode 497, reward -37.0, memory_length 2000, epsilon 0.9053814295852616\n",
      "state terminated\n",
      "episode 498, reward 157.0, memory_length 2000, epsilon 0.9052003734055659\n",
      "state terminated\n",
      "episode 499, reward 350.0, memory_length 2000, epsilon 0.9050193534334854\n",
      "state terminated\n",
      "episode 500, reward 147.0, memory_length 2000, epsilon 0.9048383696617791\n",
      "state terminated\n",
      "episode 501, reward -177.0, memory_length 2000, epsilon 0.9046574220832079\n",
      "state terminated\n",
      "episode 502, reward 416.0, memory_length 2000, epsilon 0.9044765106905336\n",
      "state terminated\n",
      "episode 503, reward 409.0, memory_length 2000, epsilon 0.9042956354765198\n",
      "state terminated\n",
      "episode 504, reward -110.0, memory_length 2000, epsilon 0.9041147964339316\n",
      "state terminated\n",
      "episode 505, reward 64.0, memory_length 2000, epsilon 0.9039339935555353\n",
      "state terminated\n",
      "episode 506, reward -276.0, memory_length 2000, epsilon 0.9037532268340989\n",
      "state terminated\n",
      "episode 507, reward 138.0, memory_length 2000, epsilon 0.9035724962623916\n",
      "state terminated\n",
      "episode 508, reward 156.0, memory_length 2000, epsilon 0.9033918018331843\n",
      "state terminated\n",
      "episode 509, reward -150.0, memory_length 2000, epsilon 0.9032111435392493\n",
      "state terminated\n",
      "episode 510, reward -143.0, memory_length 2000, epsilon 0.90303052137336\n",
      "state terminated\n",
      "episode 511, reward -117.0, memory_length 2000, epsilon 0.9028499353282919\n",
      "state terminated\n",
      "episode 512, reward 16.0, memory_length 2000, epsilon 0.9026693853968213\n",
      "state terminated\n",
      "episode 513, reward 145.0, memory_length 2000, epsilon 0.9024888715717261\n",
      "state terminated\n",
      "episode 514, reward 78.0, memory_length 2000, epsilon 0.9023083938457859\n",
      "state terminated\n",
      "episode 515, reward 201.0, memory_length 2000, epsilon 0.9021279522117817\n",
      "state terminated\n",
      "episode 516, reward 79.0, memory_length 2000, epsilon 0.9019475466624955\n",
      "state terminated\n",
      "episode 517, reward -111.0, memory_length 2000, epsilon 0.9017671771907114\n",
      "state terminated\n",
      "episode 518, reward 207.0, memory_length 2000, epsilon 0.9015868437892146\n",
      "state terminated\n",
      "episode 519, reward 259.0, memory_length 2000, epsilon 0.9014065464507915\n",
      "state terminated\n",
      "episode 520, reward 39.0, memory_length 2000, epsilon 0.9012262851682306\n",
      "state terminated\n",
      "episode 521, reward 87.0, memory_length 2000, epsilon 0.9010460599343211\n",
      "state terminated\n",
      "episode 522, reward 84.0, memory_length 2000, epsilon 0.9008658707418541\n",
      "state terminated\n",
      "episode 523, reward 123.0, memory_length 2000, epsilon 0.900685717583622\n",
      "state terminated\n",
      "episode 524, reward -20.0, memory_length 2000, epsilon 0.9005056004524188\n",
      "state terminated\n",
      "episode 525, reward 83.0, memory_length 2000, epsilon 0.9003255193410398\n",
      "state terminated\n",
      "episode 526, reward 467.0, memory_length 2000, epsilon 0.9001454742422816\n",
      "state terminated\n",
      "episode 527, reward 373.0, memory_length 2000, epsilon 0.8999654651489425\n",
      "state terminated\n",
      "episode 528, reward 92.0, memory_length 2000, epsilon 0.8997854920538221\n",
      "state terminated\n",
      "episode 529, reward 119.0, memory_length 2000, epsilon 0.8996055549497216\n",
      "state terminated\n",
      "episode 530, reward 274.0, memory_length 2000, epsilon 0.8994256538294433\n",
      "state terminated\n",
      "episode 531, reward 19.0, memory_length 2000, epsilon 0.8992457886857913\n",
      "state terminated\n",
      "episode 532, reward 346.0, memory_length 2000, epsilon 0.899065959511571\n",
      "state terminated\n",
      "episode 533, reward 112.0, memory_length 2000, epsilon 0.8988861662995893\n",
      "state terminated\n",
      "episode 534, reward 336.0, memory_length 2000, epsilon 0.8987064090426542\n",
      "state terminated\n",
      "episode 535, reward 437.0, memory_length 2000, epsilon 0.8985266877335756\n",
      "state terminated\n",
      "episode 536, reward 54.0, memory_length 2000, epsilon 0.8983470023651647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 537, reward 92.0, memory_length 2000, epsilon 0.8981673529302341\n",
      "state terminated\n",
      "episode 538, reward 468.0, memory_length 2000, epsilon 0.8979877394215975\n",
      "state terminated\n",
      "episode 539, reward 220.0, memory_length 2000, epsilon 0.8978081618320708\n",
      "state terminated\n",
      "episode 540, reward 321.0, memory_length 2000, epsilon 0.8976286201544705\n",
      "state terminated\n",
      "episode 541, reward 16.0, memory_length 2000, epsilon 0.8974491143816153\n",
      "state terminated\n",
      "episode 542, reward 262.0, memory_length 2000, epsilon 0.8972696445063247\n",
      "state terminated\n",
      "episode 543, reward 228.0, memory_length 2000, epsilon 0.8970902105214201\n",
      "state terminated\n",
      "episode 544, reward 143.0, memory_length 2000, epsilon 0.896910812419724\n",
      "state terminated\n",
      "episode 545, reward -198.0, memory_length 2000, epsilon 0.8967314501940604\n",
      "state terminated\n",
      "episode 546, reward 133.0, memory_length 2000, epsilon 0.896552123837255\n",
      "state terminated\n",
      "episode 547, reward -108.0, memory_length 2000, epsilon 0.8963728333421348\n",
      "state terminated\n",
      "episode 548, reward 20.0, memory_length 2000, epsilon 0.8961935787015279\n",
      "state terminated\n",
      "episode 549, reward 188.0, memory_length 2000, epsilon 0.8960143599082643\n",
      "state terminated\n",
      "episode 550, reward 171.0, memory_length 2000, epsilon 0.8958351769551752\n",
      "state terminated\n",
      "episode 551, reward 186.0, memory_length 2000, epsilon 0.8956560298350934\n",
      "state terminated\n",
      "episode 552, reward -31.0, memory_length 2000, epsilon 0.8954769185408529\n",
      "state terminated\n",
      "episode 553, reward -135.0, memory_length 2000, epsilon 0.8952978430652891\n",
      "state terminated\n",
      "episode 554, reward 49.0, memory_length 2000, epsilon 0.8951188034012393\n",
      "state terminated\n",
      "episode 555, reward 265.0, memory_length 2000, epsilon 0.8949397995415417\n",
      "state terminated\n",
      "episode 556, reward 138.0, memory_length 2000, epsilon 0.8947608314790363\n",
      "state terminated\n",
      "episode 557, reward -153.0, memory_length 2000, epsilon 0.8945818992065641\n",
      "state terminated\n",
      "episode 558, reward 240.0, memory_length 2000, epsilon 0.8944030027169682\n",
      "state terminated\n",
      "episode 559, reward 156.0, memory_length 2000, epsilon 0.8942241420030923\n",
      "state terminated\n",
      "episode 560, reward 193.0, memory_length 2000, epsilon 0.8940453170577822\n",
      "state terminated\n",
      "episode 561, reward -37.0, memory_length 2000, epsilon 0.8938665278738851\n",
      "state terminated\n",
      "episode 562, reward 168.0, memory_length 2000, epsilon 0.8936877744442491\n",
      "state terminated\n",
      "episode 563, reward 115.0, memory_length 2000, epsilon 0.8935090567617242\n",
      "state terminated\n",
      "episode 564, reward 286.0, memory_length 2000, epsilon 0.8933303748191618\n",
      "state terminated\n",
      "episode 565, reward 36.0, memory_length 2000, epsilon 0.8931517286094144\n",
      "state terminated\n",
      "episode 566, reward 175.0, memory_length 2000, epsilon 0.8929731181253363\n",
      "state terminated\n",
      "episode 567, reward 504.0, memory_length 2000, epsilon 0.892794543359783\n",
      "state terminated\n",
      "episode 568, reward -96.0, memory_length 2000, epsilon 0.8926160043056116\n",
      "state terminated\n",
      "episode 569, reward -146.0, memory_length 2000, epsilon 0.8924375009556804\n",
      "state terminated\n",
      "episode 570, reward 219.0, memory_length 2000, epsilon 0.8922590333028495\n",
      "state terminated\n",
      "episode 571, reward -109.0, memory_length 2000, epsilon 0.89208060133998\n",
      "state terminated\n",
      "episode 572, reward -226.0, memory_length 2000, epsilon 0.8919022050599347\n",
      "state terminated\n",
      "episode 573, reward 297.0, memory_length 2000, epsilon 0.8917238444555776\n",
      "state terminated\n",
      "episode 574, reward 517.0, memory_length 2000, epsilon 0.8915455195197746\n",
      "state terminated\n",
      "episode 575, reward 117.0, memory_length 2000, epsilon 0.8913672302453922\n",
      "state terminated\n",
      "episode 576, reward 169.0, memory_length 2000, epsilon 0.8911889766252994\n",
      "state terminated\n",
      "episode 577, reward 260.0, memory_length 2000, epsilon 0.8910107586523657\n",
      "state terminated\n",
      "episode 578, reward -66.0, memory_length 2000, epsilon 0.8908325763194624\n",
      "state terminated\n",
      "episode 579, reward -100.0, memory_length 2000, epsilon 0.8906544296194624\n",
      "state terminated\n",
      "episode 580, reward 256.0, memory_length 2000, epsilon 0.8904763185452397\n",
      "state terminated\n",
      "episode 581, reward -37.0, memory_length 2000, epsilon 0.8902982430896696\n",
      "state terminated\n",
      "episode 582, reward 182.0, memory_length 2000, epsilon 0.8901202032456296\n",
      "state terminated\n",
      "episode 583, reward -451.0, memory_length 2000, epsilon 0.8899421990059978\n",
      "state terminated\n",
      "episode 584, reward 337.0, memory_length 2000, epsilon 0.8897642303636542\n",
      "state terminated\n",
      "episode 585, reward -257.0, memory_length 2000, epsilon 0.8895862973114796\n",
      "state terminated\n",
      "episode 586, reward -106.0, memory_length 2000, epsilon 0.8894083998423573\n",
      "state terminated\n",
      "episode 587, reward 85.0, memory_length 2000, epsilon 0.8892305379491711\n",
      "state terminated\n",
      "episode 588, reward 126.0, memory_length 2000, epsilon 0.8890527116248064\n",
      "state terminated\n",
      "episode 589, reward -110.0, memory_length 2000, epsilon 0.8888749208621503\n",
      "state terminated\n",
      "episode 590, reward 225.0, memory_length 2000, epsilon 0.8886971656540912\n",
      "state terminated\n",
      "episode 591, reward 72.0, memory_length 2000, epsilon 0.8885194459935188\n",
      "state terminated\n",
      "episode 592, reward 411.0, memory_length 2000, epsilon 0.8883417618733245\n",
      "state terminated\n",
      "episode 593, reward 122.0, memory_length 2000, epsilon 0.8881641132864005\n",
      "state terminated\n",
      "episode 594, reward 81.0, memory_length 2000, epsilon 0.8879865002256415\n",
      "state terminated\n",
      "episode 595, reward -11.0, memory_length 2000, epsilon 0.8878089226839425\n",
      "state terminated\n",
      "episode 596, reward 354.0, memory_length 2000, epsilon 0.8876313806542004\n",
      "state terminated\n",
      "episode 597, reward 85.0, memory_length 2000, epsilon 0.8874538741293138\n",
      "state terminated\n",
      "episode 598, reward 62.0, memory_length 2000, epsilon 0.8872764031021821\n",
      "state terminated\n",
      "episode 599, reward -109.0, memory_length 2000, epsilon 0.8870989675657068\n",
      "state terminated\n",
      "episode 600, reward 198.0, memory_length 2000, epsilon 0.8869215675127903\n",
      "state terminated\n",
      "episode 601, reward 35.0, memory_length 2000, epsilon 0.8867442029363367\n",
      "state terminated\n",
      "episode 602, reward 315.0, memory_length 2000, epsilon 0.8865668738292513\n",
      "state terminated\n",
      "episode 603, reward 151.0, memory_length 2000, epsilon 0.8863895801844408\n",
      "state terminated\n",
      "episode 604, reward -28.0, memory_length 2000, epsilon 0.8862123219948137\n",
      "state terminated\n",
      "episode 605, reward 191.0, memory_length 2000, epsilon 0.8860350992532796\n",
      "state terminated\n",
      "episode 606, reward 49.0, memory_length 2000, epsilon 0.8858579119527497\n",
      "state terminated\n",
      "episode 607, reward 327.0, memory_length 2000, epsilon 0.8856807600861363\n",
      "state terminated\n",
      "episode 608, reward 40.0, memory_length 2000, epsilon 0.8855036436463534\n",
      "state terminated\n",
      "episode 609, reward 200.0, memory_length 2000, epsilon 0.8853265626263164\n",
      "state terminated\n",
      "episode 610, reward 288.0, memory_length 2000, epsilon 0.8851495170189421\n",
      "state terminated\n",
      "episode 611, reward 494.0, memory_length 2000, epsilon 0.8849725068171485\n",
      "state terminated\n",
      "episode 612, reward 99.0, memory_length 2000, epsilon 0.8847955320138553\n",
      "state terminated\n",
      "episode 613, reward -146.0, memory_length 2000, epsilon 0.8846185926019836\n",
      "state terminated\n",
      "episode 614, reward 101.0, memory_length 2000, epsilon 0.8844416885744555\n",
      "state terminated\n",
      "episode 615, reward -77.0, memory_length 2000, epsilon 0.8842648199241953\n",
      "state terminated\n",
      "episode 616, reward 364.0, memory_length 2000, epsilon 0.8840879866441278\n",
      "state terminated\n",
      "episode 617, reward 285.0, memory_length 2000, epsilon 0.88391118872718\n",
      "state terminated\n",
      "episode 618, reward 262.0, memory_length 2000, epsilon 0.88373442616628\n",
      "state terminated\n",
      "episode 619, reward 353.0, memory_length 2000, epsilon 0.883557698954357\n",
      "state terminated\n",
      "episode 620, reward 153.0, memory_length 2000, epsilon 0.8833810070843421\n",
      "state terminated\n",
      "episode 621, reward 373.0, memory_length 2000, epsilon 0.8832043505491676\n",
      "state terminated\n",
      "episode 622, reward -146.0, memory_length 2000, epsilon 0.8830277293417672\n",
      "state terminated\n",
      "episode 623, reward 150.0, memory_length 2000, epsilon 0.8828511434550761\n",
      "state terminated\n",
      "episode 624, reward 0.0, memory_length 2000, epsilon 0.882674592882031\n",
      "state terminated\n",
      "episode 625, reward 326.0, memory_length 2000, epsilon 0.8824980776155696\n",
      "state terminated\n",
      "episode 626, reward 209.0, memory_length 2000, epsilon 0.8823215976486314\n",
      "state terminated\n",
      "episode 627, reward -135.0, memory_length 2000, epsilon 0.8821451529741572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 628, reward -93.0, memory_length 2000, epsilon 0.8819687435850894\n",
      "state terminated\n",
      "episode 629, reward 6.0, memory_length 2000, epsilon 0.8817923694743713\n",
      "state terminated\n",
      "episode 630, reward 387.0, memory_length 2000, epsilon 0.8816160306349482\n",
      "state terminated\n",
      "episode 631, reward 189.0, memory_length 2000, epsilon 0.8814397270597664\n",
      "state terminated\n",
      "episode 632, reward 258.0, memory_length 2000, epsilon 0.8812634587417738\n",
      "state terminated\n",
      "episode 633, reward -123.0, memory_length 2000, epsilon 0.8810872256739197\n",
      "state terminated\n",
      "episode 634, reward 610.0, memory_length 2000, epsilon 0.8809110278491548\n",
      "state terminated\n",
      "episode 635, reward 4.0, memory_length 2000, epsilon 0.880734865260431\n",
      "state terminated\n",
      "episode 636, reward 245.0, memory_length 2000, epsilon 0.8805587379007019\n",
      "state terminated\n",
      "episode 637, reward 205.0, memory_length 2000, epsilon 0.8803826457629226\n",
      "state terminated\n",
      "episode 638, reward 298.0, memory_length 2000, epsilon 0.8802065888400491\n",
      "state terminated\n",
      "episode 639, reward 443.0, memory_length 2000, epsilon 0.8800305671250394\n",
      "state terminated\n",
      "episode 640, reward 109.0, memory_length 2000, epsilon 0.8798545806108523\n",
      "state terminated\n",
      "episode 641, reward 156.0, memory_length 2000, epsilon 0.8796786292904488\n",
      "state terminated\n",
      "episode 642, reward 359.0, memory_length 2000, epsilon 0.8795027131567904\n",
      "state terminated\n",
      "episode 643, reward 160.0, memory_length 2000, epsilon 0.8793268322028407\n",
      "state terminated\n",
      "episode 644, reward 45.0, memory_length 2000, epsilon 0.8791509864215645\n",
      "state terminated\n",
      "episode 645, reward 355.0, memory_length 2000, epsilon 0.8789751758059277\n",
      "state terminated\n",
      "episode 646, reward 57.0, memory_length 2000, epsilon 0.8787994003488981\n",
      "state terminated\n",
      "episode 647, reward 353.0, memory_length 2000, epsilon 0.8786236600434447\n",
      "state terminated\n",
      "episode 648, reward 201.0, memory_length 2000, epsilon 0.8784479548825378\n",
      "state terminated\n",
      "episode 649, reward 310.0, memory_length 2000, epsilon 0.8782722848591492\n",
      "state terminated\n",
      "episode 650, reward 40.0, memory_length 2000, epsilon 0.8780966499662521\n",
      "state terminated\n",
      "episode 651, reward 290.0, memory_length 2000, epsilon 0.8779210501968211\n",
      "state terminated\n",
      "episode 652, reward 220.0, memory_length 2000, epsilon 0.8777454855438322\n",
      "state terminated\n",
      "episode 653, reward 171.0, memory_length 2000, epsilon 0.877569956000263\n",
      "state terminated\n",
      "episode 654, reward 270.0, memory_length 2000, epsilon 0.8773944615590921\n",
      "state terminated\n",
      "episode 655, reward 486.0, memory_length 2000, epsilon 0.8772190022132996\n",
      "state terminated\n",
      "episode 656, reward 479.0, memory_length 2000, epsilon 0.8770435779558674\n",
      "state terminated\n",
      "episode 657, reward 35.0, memory_length 2000, epsilon 0.8768681887797786\n",
      "state terminated\n",
      "episode 658, reward 341.0, memory_length 2000, epsilon 0.8766928346780173\n",
      "state terminated\n",
      "episode 659, reward 188.0, memory_length 2000, epsilon 0.8765175156435695\n",
      "state terminated\n",
      "episode 660, reward 280.0, memory_length 2000, epsilon 0.8763422316694225\n",
      "state terminated\n",
      "episode 661, reward 262.0, memory_length 2000, epsilon 0.8761669827485649\n",
      "state terminated\n",
      "episode 662, reward 241.0, memory_length 2000, epsilon 0.8759917688739867\n",
      "state terminated\n",
      "episode 663, reward 162.0, memory_length 2000, epsilon 0.8758165900386793\n",
      "state terminated\n",
      "episode 664, reward 212.0, memory_length 2000, epsilon 0.8756414462356357\n",
      "state terminated\n",
      "episode 665, reward 502.0, memory_length 2000, epsilon 0.87546633745785\n",
      "state terminated\n",
      "episode 666, reward 163.0, memory_length 2000, epsilon 0.8752912636983179\n",
      "state terminated\n",
      "episode 667, reward 139.0, memory_length 2000, epsilon 0.8751162249500366\n",
      "state terminated\n",
      "episode 668, reward 17.0, memory_length 2000, epsilon 0.8749412212060045\n",
      "state terminated\n",
      "episode 669, reward 63.0, memory_length 2000, epsilon 0.8747662524592211\n",
      "state terminated\n",
      "episode 670, reward 390.0, memory_length 2000, epsilon 0.8745913187026879\n",
      "state terminated\n",
      "episode 671, reward 222.0, memory_length 2000, epsilon 0.8744164199294078\n",
      "state terminated\n",
      "episode 672, reward 189.0, memory_length 2000, epsilon 0.8742415561323845\n",
      "state terminated\n",
      "episode 673, reward 333.0, memory_length 2000, epsilon 0.8740667273046235\n",
      "state terminated\n",
      "episode 674, reward 177.0, memory_length 2000, epsilon 0.8738919334391319\n",
      "state terminated\n",
      "episode 675, reward 359.0, memory_length 2000, epsilon 0.8737171745289175\n",
      "state terminated\n",
      "episode 676, reward 59.0, memory_length 2000, epsilon 0.8735424505669903\n",
      "state terminated\n",
      "episode 677, reward 291.0, memory_length 2000, epsilon 0.8733677615463614\n",
      "state terminated\n",
      "episode 678, reward 414.0, memory_length 2000, epsilon 0.8731931074600429\n",
      "state terminated\n",
      "episode 679, reward 61.0, memory_length 2000, epsilon 0.8730184883010488\n",
      "state terminated\n",
      "episode 680, reward 562.0, memory_length 2000, epsilon 0.8728439040623944\n",
      "state terminated\n",
      "episode 681, reward 501.0, memory_length 2000, epsilon 0.8726693547370964\n",
      "state terminated\n",
      "episode 682, reward 175.0, memory_length 2000, epsilon 0.8724948403181725\n",
      "state terminated\n",
      "episode 683, reward 301.0, memory_length 2000, epsilon 0.8723203607986424\n",
      "state terminated\n",
      "episode 684, reward 252.0, memory_length 2000, epsilon 0.8721459161715269\n",
      "state terminated\n",
      "episode 685, reward 553.0, memory_length 2000, epsilon 0.8719715064298481\n",
      "state terminated\n",
      "episode 686, reward 352.0, memory_length 2000, epsilon 0.8717971315666296\n",
      "state terminated\n",
      "episode 687, reward -79.0, memory_length 2000, epsilon 0.8716227915748967\n",
      "state terminated\n",
      "episode 688, reward -221.0, memory_length 2000, epsilon 0.8714484864476755\n",
      "state terminated\n",
      "episode 689, reward 148.0, memory_length 2000, epsilon 0.8712742161779937\n",
      "state terminated\n",
      "episode 690, reward -275.0, memory_length 2000, epsilon 0.8710999807588808\n",
      "state terminated\n",
      "episode 691, reward 436.0, memory_length 2000, epsilon 0.8709257801833673\n",
      "state terminated\n",
      "episode 692, reward 126.0, memory_length 2000, epsilon 0.8707516144444851\n",
      "state terminated\n",
      "episode 693, reward 388.0, memory_length 2000, epsilon 0.8705774835352675\n",
      "state terminated\n",
      "episode 694, reward 5.0, memory_length 2000, epsilon 0.8704033874487495\n",
      "state terminated\n",
      "episode 695, reward 288.0, memory_length 2000, epsilon 0.870229326177967\n",
      "state terminated\n",
      "episode 696, reward 101.0, memory_length 2000, epsilon 0.8700552997159576\n",
      "state terminated\n",
      "episode 697, reward 62.0, memory_length 2000, epsilon 0.8698813080557606\n",
      "state terminated\n",
      "episode 698, reward 189.0, memory_length 2000, epsilon 0.8697073511904158\n",
      "state terminated\n",
      "episode 699, reward -167.0, memory_length 2000, epsilon 0.8695334291129652\n",
      "state terminated\n",
      "episode 700, reward 180.0, memory_length 2000, epsilon 0.8693595418164518\n",
      "state terminated\n",
      "episode 701, reward 188.0, memory_length 2000, epsilon 0.8691856892939203\n",
      "state terminated\n",
      "episode 702, reward 30.0, memory_length 2000, epsilon 0.8690118715384164\n",
      "state terminated\n",
      "episode 703, reward 40.0, memory_length 2000, epsilon 0.8688380885429876\n",
      "state terminated\n",
      "episode 704, reward 126.0, memory_length 2000, epsilon 0.8686643403006823\n",
      "state terminated\n",
      "episode 705, reward -8.0, memory_length 2000, epsilon 0.8684906268045509\n",
      "state terminated\n",
      "episode 706, reward -43.0, memory_length 2000, epsilon 0.8683169480476446\n",
      "state terminated\n",
      "episode 707, reward 141.0, memory_length 2000, epsilon 0.8681433040230163\n",
      "state terminated\n",
      "episode 708, reward 17.0, memory_length 2000, epsilon 0.8679696947237203\n",
      "state terminated\n",
      "episode 709, reward 250.0, memory_length 2000, epsilon 0.8677961201428123\n",
      "state terminated\n",
      "episode 710, reward 352.0, memory_length 2000, epsilon 0.8676225802733492\n",
      "state terminated\n",
      "episode 711, reward 339.0, memory_length 2000, epsilon 0.8674490751083893\n",
      "state terminated\n",
      "episode 712, reward 169.0, memory_length 2000, epsilon 0.8672756046409926\n",
      "state terminated\n",
      "episode 713, reward 161.0, memory_length 2000, epsilon 0.8671021688642202\n",
      "state terminated\n",
      "episode 714, reward 331.0, memory_length 2000, epsilon 0.8669287677711347\n",
      "state terminated\n",
      "episode 715, reward 121.0, memory_length 2000, epsilon 0.8667554013547999\n",
      "state terminated\n",
      "episode 716, reward 335.0, memory_length 2000, epsilon 0.8665820696082814\n",
      "state terminated\n",
      "episode 717, reward 93.0, memory_length 2000, epsilon 0.8664087725246459\n",
      "state terminated\n",
      "episode 718, reward 98.0, memory_length 2000, epsilon 0.8662355100969612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 719, reward 85.0, memory_length 2000, epsilon 0.8660622823182971\n",
      "state terminated\n",
      "episode 720, reward 124.0, memory_length 2000, epsilon 0.8658890891817244\n",
      "state terminated\n",
      "episode 721, reward 136.0, memory_length 2000, epsilon 0.8657159306803154\n",
      "state terminated\n",
      "episode 722, reward 284.0, memory_length 2000, epsilon 0.8655428068071438\n",
      "state terminated\n",
      "episode 723, reward 335.0, memory_length 2000, epsilon 0.8653697175552845\n",
      "state terminated\n",
      "episode 724, reward 117.0, memory_length 2000, epsilon 0.8651966629178139\n",
      "state terminated\n",
      "episode 725, reward 286.0, memory_length 2000, epsilon 0.8650236428878102\n",
      "state terminated\n",
      "episode 726, reward 172.0, memory_length 2000, epsilon 0.8648506574583522\n",
      "state terminated\n",
      "episode 727, reward 143.0, memory_length 2000, epsilon 0.8646777066225205\n",
      "state terminated\n",
      "episode 728, reward 354.0, memory_length 2000, epsilon 0.8645047903733973\n",
      "state terminated\n",
      "episode 729, reward 173.0, memory_length 2000, epsilon 0.8643319087040658\n",
      "state terminated\n",
      "episode 730, reward 180.0, memory_length 2000, epsilon 0.8641590616076108\n",
      "state terminated\n",
      "episode 731, reward 278.0, memory_length 2000, epsilon 0.8639862490771185\n",
      "state terminated\n",
      "episode 732, reward 519.0, memory_length 2000, epsilon 0.8638134711056762\n",
      "state terminated\n",
      "episode 733, reward 117.0, memory_length 2000, epsilon 0.8636407276863727\n",
      "state terminated\n",
      "episode 734, reward 249.0, memory_length 2000, epsilon 0.8634680188122985\n",
      "state terminated\n",
      "episode 735, reward 336.0, memory_length 2000, epsilon 0.8632953444765452\n",
      "state terminated\n",
      "episode 736, reward 351.0, memory_length 2000, epsilon 0.8631227046722059\n",
      "state terminated\n",
      "episode 737, reward 444.0, memory_length 2000, epsilon 0.8629500993923748\n",
      "state terminated\n",
      "episode 738, reward 592.0, memory_length 2000, epsilon 0.8627775286301478\n",
      "state terminated\n",
      "episode 739, reward 237.0, memory_length 2000, epsilon 0.862604992378622\n",
      "state terminated\n",
      "episode 740, reward 592.0, memory_length 2000, epsilon 0.862432490630896\n",
      "state terminated\n",
      "episode 741, reward -215.0, memory_length 2000, epsilon 0.8622600233800698\n",
      "state terminated\n",
      "episode 742, reward 85.0, memory_length 2000, epsilon 0.8620875906192447\n",
      "state terminated\n",
      "episode 743, reward 89.0, memory_length 2000, epsilon 0.8619151923415233\n",
      "state terminated\n",
      "episode 744, reward 418.0, memory_length 2000, epsilon 0.8617428285400097\n",
      "state terminated\n",
      "episode 745, reward 378.0, memory_length 2000, epsilon 0.8615704992078093\n",
      "state terminated\n",
      "episode 746, reward 112.0, memory_length 2000, epsilon 0.861398204338029\n",
      "state terminated\n",
      "episode 747, reward 301.0, memory_length 2000, epsilon 0.8612259439237769\n",
      "state terminated\n",
      "episode 748, reward -152.0, memory_length 2000, epsilon 0.8610537179581629\n",
      "state terminated\n",
      "episode 749, reward 400.0, memory_length 2000, epsilon 0.8608815264342976\n",
      "state terminated\n",
      "episode 750, reward 387.0, memory_length 2000, epsilon 0.8607093693452935\n",
      "state terminated\n",
      "episode 751, reward 299.0, memory_length 2000, epsilon 0.8605372466842643\n",
      "state terminated\n",
      "episode 752, reward 364.0, memory_length 2000, epsilon 0.8603651584443252\n",
      "state terminated\n",
      "episode 753, reward 66.0, memory_length 2000, epsilon 0.8601931046185923\n",
      "state terminated\n",
      "episode 754, reward -38.0, memory_length 2000, epsilon 0.8600210852001838\n",
      "state terminated\n",
      "episode 755, reward 158.0, memory_length 2000, epsilon 0.8598491001822189\n",
      "state terminated\n",
      "episode 756, reward 208.0, memory_length 2000, epsilon 0.859677149557818\n",
      "state terminated\n",
      "episode 757, reward 322.0, memory_length 2000, epsilon 0.8595052333201033\n",
      "state terminated\n",
      "episode 758, reward 126.0, memory_length 2000, epsilon 0.859333351462198\n",
      "state terminated\n",
      "episode 759, reward 220.0, memory_length 2000, epsilon 0.8591615039772269\n",
      "state terminated\n",
      "episode 760, reward 67.0, memory_length 2000, epsilon 0.858989690858316\n",
      "state terminated\n",
      "episode 761, reward 444.0, memory_length 2000, epsilon 0.8588179120985929\n",
      "state terminated\n",
      "episode 762, reward 359.0, memory_length 2000, epsilon 0.8586461676911865\n",
      "state terminated\n",
      "episode 763, reward 245.0, memory_length 2000, epsilon 0.8584744576292268\n",
      "state terminated\n",
      "episode 764, reward 247.0, memory_length 2000, epsilon 0.8583027819058455\n",
      "state terminated\n",
      "episode 765, reward 430.0, memory_length 2000, epsilon 0.8581311405141757\n",
      "state terminated\n",
      "episode 766, reward 58.0, memory_length 2000, epsilon 0.8579595334473515\n",
      "state terminated\n",
      "episode 767, reward 380.0, memory_length 2000, epsilon 0.8577879606985089\n",
      "state terminated\n",
      "episode 768, reward 16.0, memory_length 2000, epsilon 0.8576164222607847\n",
      "state terminated\n",
      "episode 769, reward 261.0, memory_length 2000, epsilon 0.8574449181273175\n",
      "state terminated\n",
      "episode 770, reward 187.0, memory_length 2000, epsilon 0.8572734482912474\n",
      "state terminated\n",
      "episode 771, reward 615.0, memory_length 2000, epsilon 0.8571020127457151\n",
      "state terminated\n",
      "episode 772, reward 180.0, memory_length 2000, epsilon 0.8569306114838635\n",
      "state terminated\n",
      "episode 773, reward 73.0, memory_length 2000, epsilon 0.8567592444988364\n",
      "state terminated\n",
      "episode 774, reward 479.0, memory_length 2000, epsilon 0.8565879117837792\n",
      "state terminated\n",
      "episode 775, reward 388.0, memory_length 2000, epsilon 0.8564166133318387\n",
      "state terminated\n",
      "episode 776, reward 393.0, memory_length 2000, epsilon 0.8562453491361628\n",
      "state terminated\n",
      "episode 777, reward 506.0, memory_length 2000, epsilon 0.856074119189901\n",
      "state terminated\n",
      "episode 778, reward 342.0, memory_length 2000, epsilon 0.8559029234862039\n",
      "state terminated\n",
      "episode 779, reward 81.0, memory_length 2000, epsilon 0.8557317620182241\n",
      "state terminated\n",
      "episode 780, reward 337.0, memory_length 2000, epsilon 0.8555606347791147\n",
      "state terminated\n",
      "episode 781, reward 47.0, memory_length 2000, epsilon 0.8553895417620309\n",
      "state terminated\n",
      "episode 782, reward 414.0, memory_length 2000, epsilon 0.8552184829601289\n",
      "state terminated\n",
      "episode 783, reward 0.0, memory_length 2000, epsilon 0.8550474583665664\n",
      "state terminated\n",
      "episode 784, reward 436.0, memory_length 2000, epsilon 0.8548764679745022\n",
      "state terminated\n",
      "episode 785, reward 133.0, memory_length 2000, epsilon 0.8547055117770969\n",
      "state terminated\n",
      "episode 786, reward 549.0, memory_length 2000, epsilon 0.8545345897675122\n",
      "state terminated\n",
      "episode 787, reward 349.0, memory_length 2000, epsilon 0.8543637019389111\n",
      "state terminated\n",
      "episode 788, reward 382.0, memory_length 2000, epsilon 0.8541928482844583\n",
      "state terminated\n",
      "episode 789, reward 525.0, memory_length 2000, epsilon 0.8540220287973196\n",
      "state terminated\n",
      "episode 790, reward 480.0, memory_length 2000, epsilon 0.853851243470662\n",
      "state terminated\n",
      "episode 791, reward 247.0, memory_length 2000, epsilon 0.8536804922976543\n",
      "state terminated\n",
      "episode 792, reward 314.0, memory_length 2000, epsilon 0.8535097752714665\n",
      "state terminated\n",
      "episode 793, reward 292.0, memory_length 2000, epsilon 0.8533390923852697\n",
      "state terminated\n",
      "episode 794, reward 530.0, memory_length 2000, epsilon 0.8531684436322369\n",
      "state terminated\n",
      "episode 795, reward 220.0, memory_length 2000, epsilon 0.8529978290055418\n",
      "state terminated\n",
      "episode 796, reward -119.0, memory_length 2000, epsilon 0.85282724849836\n",
      "state terminated\n",
      "episode 797, reward 458.0, memory_length 2000, epsilon 0.8526567021038682\n",
      "state terminated\n",
      "episode 798, reward 578.0, memory_length 2000, epsilon 0.8524861898152447\n",
      "state terminated\n",
      "episode 799, reward 231.0, memory_length 2000, epsilon 0.8523157116256689\n",
      "state terminated\n",
      "episode 800, reward 473.0, memory_length 2000, epsilon 0.8521452675283216\n",
      "state terminated\n",
      "episode 801, reward 213.0, memory_length 2000, epsilon 0.8519748575163852\n",
      "state terminated\n",
      "episode 802, reward 315.0, memory_length 2000, epsilon 0.8518044815830431\n",
      "state terminated\n",
      "episode 803, reward 473.0, memory_length 2000, epsilon 0.8516341397214806\n",
      "state terminated\n",
      "episode 804, reward -63.0, memory_length 2000, epsilon 0.8514638319248836\n",
      "state terminated\n",
      "episode 805, reward 87.0, memory_length 2000, epsilon 0.85129355818644\n",
      "state terminated\n",
      "episode 806, reward 184.0, memory_length 2000, epsilon 0.851123318499339\n",
      "state terminated\n",
      "episode 807, reward 429.0, memory_length 2000, epsilon 0.8509531128567707\n",
      "state terminated\n",
      "episode 808, reward 152.0, memory_length 2000, epsilon 0.8507829412519271\n",
      "state terminated\n",
      "episode 809, reward 396.0, memory_length 2000, epsilon 0.8506128036780012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 810, reward 268.0, memory_length 2000, epsilon 0.8504427001281876\n",
      "state terminated\n",
      "episode 811, reward 366.0, memory_length 2000, epsilon 0.8502726305956821\n",
      "state terminated\n",
      "episode 812, reward 217.0, memory_length 2000, epsilon 0.8501025950736819\n",
      "state terminated\n",
      "episode 813, reward 870.0, memory_length 2000, epsilon 0.8499325935553858\n",
      "state terminated\n",
      "episode 814, reward 462.0, memory_length 2000, epsilon 0.8497626260339933\n",
      "state terminated\n",
      "episode 815, reward 453.0, memory_length 2000, epsilon 0.8495926925027061\n",
      "state terminated\n",
      "episode 816, reward 184.0, memory_length 2000, epsilon 0.8494227929547267\n",
      "state terminated\n",
      "episode 817, reward 522.0, memory_length 2000, epsilon 0.8492529273832591\n",
      "state terminated\n",
      "episode 818, reward 311.0, memory_length 2000, epsilon 0.8490830957815088\n",
      "state terminated\n",
      "episode 819, reward 324.0, memory_length 2000, epsilon 0.8489132981426823\n",
      "state terminated\n",
      "episode 820, reward 357.0, memory_length 2000, epsilon 0.848743534459988\n",
      "state terminated\n",
      "episode 821, reward 278.0, memory_length 2000, epsilon 0.848573804726635\n",
      "state terminated\n",
      "episode 822, reward 203.0, memory_length 2000, epsilon 0.8484041089358344\n",
      "state terminated\n",
      "episode 823, reward -54.0, memory_length 2000, epsilon 0.8482344470807983\n",
      "state terminated\n",
      "episode 824, reward 176.0, memory_length 2000, epsilon 0.8480648191547402\n",
      "state terminated\n",
      "episode 825, reward -66.0, memory_length 2000, epsilon 0.847895225150875\n",
      "state terminated\n",
      "episode 826, reward 453.0, memory_length 2000, epsilon 0.8477256650624188\n",
      "state terminated\n",
      "episode 827, reward 367.0, memory_length 2000, epsilon 0.8475561388825894\n",
      "state terminated\n",
      "episode 828, reward 216.0, memory_length 2000, epsilon 0.8473866466046057\n",
      "state terminated\n",
      "episode 829, reward 241.0, memory_length 2000, epsilon 0.8472171882216879\n",
      "state terminated\n",
      "episode 830, reward 7.0, memory_length 2000, epsilon 0.8470477637270577\n",
      "state terminated\n",
      "episode 831, reward 499.0, memory_length 2000, epsilon 0.8468783731139383\n",
      "state terminated\n",
      "episode 832, reward 505.0, memory_length 2000, epsilon 0.8467090163755538\n",
      "state terminated\n",
      "episode 833, reward 364.0, memory_length 2000, epsilon 0.8465396935051303\n",
      "state terminated\n",
      "episode 834, reward 384.0, memory_length 2000, epsilon 0.8463704044958944\n",
      "state terminated\n",
      "episode 835, reward 156.0, memory_length 2000, epsilon 0.8462011493410748\n",
      "state terminated\n",
      "episode 836, reward 256.0, memory_length 2000, epsilon 0.8460319280339015\n",
      "state terminated\n",
      "episode 837, reward 201.0, memory_length 2000, epsilon 0.8458627405676052\n",
      "state terminated\n",
      "episode 838, reward 434.0, memory_length 2000, epsilon 0.8456935869354189\n",
      "state terminated\n",
      "episode 839, reward 468.0, memory_length 2000, epsilon 0.8455244671305759\n",
      "state terminated\n",
      "episode 840, reward 398.0, memory_length 2000, epsilon 0.8453553811463119\n",
      "state terminated\n",
      "episode 841, reward 347.0, memory_length 2000, epsilon 0.8451863289758632\n",
      "state terminated\n",
      "episode 842, reward -56.0, memory_length 2000, epsilon 0.8450173106124678\n",
      "state terminated\n",
      "episode 843, reward 421.0, memory_length 2000, epsilon 0.8448483260493648\n",
      "state terminated\n",
      "episode 844, reward 477.0, memory_length 2000, epsilon 0.8446793752797951\n",
      "state terminated\n",
      "episode 845, reward 301.0, memory_length 2000, epsilon 0.8445104582970004\n",
      "state terminated\n",
      "episode 846, reward 287.0, memory_length 2000, epsilon 0.8443415750942243\n",
      "state terminated\n",
      "episode 847, reward -55.0, memory_length 2000, epsilon 0.8441727256647112\n",
      "state terminated\n",
      "episode 848, reward 88.0, memory_length 2000, epsilon 0.8440039100017073\n",
      "state terminated\n",
      "episode 849, reward 457.0, memory_length 2000, epsilon 0.8438351280984598\n",
      "state terminated\n",
      "episode 850, reward 497.0, memory_length 2000, epsilon 0.8436663799482177\n",
      "state terminated\n",
      "episode 851, reward 634.0, memory_length 2000, epsilon 0.8434976655442309\n",
      "state terminated\n",
      "episode 852, reward 188.0, memory_length 2000, epsilon 0.8433289848797507\n",
      "state terminated\n",
      "episode 853, reward 375.0, memory_length 2000, epsilon 0.84316033794803\n",
      "state terminated\n",
      "episode 854, reward 487.0, memory_length 2000, epsilon 0.8429917247423231\n",
      "state terminated\n",
      "episode 855, reward 289.0, memory_length 2000, epsilon 0.8428231452558852\n",
      "state terminated\n",
      "episode 856, reward 608.0, memory_length 2000, epsilon 0.8426545994819732\n",
      "state terminated\n",
      "episode 857, reward 164.0, memory_length 2000, epsilon 0.8424860874138453\n",
      "state terminated\n",
      "episode 858, reward 447.0, memory_length 2000, epsilon 0.842317609044761\n",
      "state terminated\n",
      "episode 859, reward 189.0, memory_length 2000, epsilon 0.8421491643679813\n",
      "state terminated\n",
      "episode 860, reward -226.0, memory_length 2000, epsilon 0.8419807533767683\n",
      "state terminated\n",
      "episode 861, reward 468.0, memory_length 2000, epsilon 0.8418123760643853\n",
      "state terminated\n",
      "episode 862, reward 295.0, memory_length 2000, epsilon 0.8416440324240977\n",
      "state terminated\n",
      "episode 863, reward 241.0, memory_length 2000, epsilon 0.8414757224491713\n",
      "state terminated\n",
      "episode 864, reward 260.0, memory_length 2000, epsilon 0.841307446132874\n",
      "state terminated\n",
      "episode 865, reward 431.0, memory_length 2000, epsilon 0.8411392034684748\n",
      "state terminated\n",
      "episode 866, reward 322.0, memory_length 2000, epsilon 0.8409709944492437\n",
      "state terminated\n",
      "episode 867, reward 159.0, memory_length 2000, epsilon 0.8408028190684526\n",
      "state terminated\n",
      "episode 868, reward 193.0, memory_length 2000, epsilon 0.8406346773193742\n",
      "state terminated\n",
      "episode 869, reward 596.0, memory_length 2000, epsilon 0.8404665691952831\n",
      "state terminated\n",
      "episode 870, reward 224.0, memory_length 2000, epsilon 0.8402984946894548\n",
      "state terminated\n",
      "episode 871, reward 165.0, memory_length 2000, epsilon 0.8401304537951665\n",
      "state terminated\n",
      "episode 872, reward 432.0, memory_length 2000, epsilon 0.8399624465056964\n",
      "state terminated\n",
      "episode 873, reward 211.0, memory_length 2000, epsilon 0.8397944728143243\n",
      "state terminated\n",
      "episode 874, reward 388.0, memory_length 2000, epsilon 0.8396265327143313\n",
      "state terminated\n",
      "episode 875, reward 144.0, memory_length 2000, epsilon 0.8394586261989997\n",
      "state terminated\n",
      "episode 876, reward 369.0, memory_length 2000, epsilon 0.8392907532616132\n",
      "state terminated\n",
      "episode 877, reward 27.0, memory_length 2000, epsilon 0.8391229138954569\n",
      "state terminated\n",
      "episode 878, reward 436.0, memory_length 2000, epsilon 0.8389551080938173\n",
      "state terminated\n",
      "episode 879, reward 301.0, memory_length 2000, epsilon 0.8387873358499822\n",
      "state terminated\n",
      "episode 880, reward 297.0, memory_length 2000, epsilon 0.8386195971572405\n",
      "state terminated\n",
      "episode 881, reward 489.0, memory_length 2000, epsilon 0.838451892008883\n",
      "state terminated\n",
      "episode 882, reward 437.0, memory_length 2000, epsilon 0.8382842203982012\n",
      "state terminated\n",
      "episode 883, reward 647.0, memory_length 2000, epsilon 0.8381165823184884\n",
      "state terminated\n",
      "episode 884, reward 323.0, memory_length 2000, epsilon 0.8379489777630389\n",
      "state terminated\n",
      "episode 885, reward 340.0, memory_length 2000, epsilon 0.8377814067251486\n",
      "state terminated\n",
      "episode 886, reward 344.0, memory_length 2000, epsilon 0.8376138691981148\n",
      "state terminated\n",
      "episode 887, reward 663.0, memory_length 2000, epsilon 0.8374463651752357\n",
      "state terminated\n",
      "episode 888, reward 252.0, memory_length 2000, epsilon 0.8372788946498115\n",
      "state terminated\n",
      "episode 889, reward 550.0, memory_length 2000, epsilon 0.8371114576151432\n",
      "state terminated\n",
      "episode 890, reward 480.0, memory_length 2000, epsilon 0.8369440540645331\n",
      "state terminated\n",
      "episode 891, reward 411.0, memory_length 2000, epsilon 0.8367766839912855\n",
      "state terminated\n",
      "episode 892, reward 216.0, memory_length 2000, epsilon 0.8366093473887053\n",
      "state terminated\n",
      "episode 893, reward 235.0, memory_length 2000, epsilon 0.8364420442500992\n",
      "state terminated\n",
      "episode 894, reward 97.0, memory_length 2000, epsilon 0.8362747745687747\n",
      "state terminated\n",
      "episode 895, reward 430.0, memory_length 2000, epsilon 0.8361075383380415\n",
      "state terminated\n",
      "episode 896, reward 287.0, memory_length 2000, epsilon 0.83594033555121\n",
      "state terminated\n",
      "episode 897, reward 153.0, memory_length 2000, epsilon 0.8357731662015919\n",
      "state terminated\n",
      "episode 898, reward 342.0, memory_length 2000, epsilon 0.8356060302825007\n",
      "state terminated\n",
      "episode 899, reward 138.0, memory_length 2000, epsilon 0.8354389277872507\n",
      "state terminated\n",
      "episode 900, reward 207.0, memory_length 2000, epsilon 0.8352718587091579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 901, reward 39.0, memory_length 2000, epsilon 0.8351048230415397\n",
      "state terminated\n",
      "episode 902, reward 250.0, memory_length 2000, epsilon 0.8349378207777144\n",
      "state terminated\n",
      "episode 903, reward 471.0, memory_length 2000, epsilon 0.8347708519110021\n",
      "state terminated\n",
      "episode 904, reward 646.0, memory_length 2000, epsilon 0.8346039164347239\n",
      "state terminated\n",
      "episode 905, reward 234.0, memory_length 2000, epsilon 0.8344370143422026\n",
      "state terminated\n",
      "episode 906, reward 162.0, memory_length 2000, epsilon 0.8342701456267619\n",
      "state terminated\n",
      "episode 907, reward 283.0, memory_length 2000, epsilon 0.8341033102817272\n",
      "state terminated\n",
      "episode 908, reward 691.0, memory_length 2000, epsilon 0.833936508300425\n",
      "state terminated\n",
      "episode 909, reward 160.0, memory_length 2000, epsilon 0.8337697396761832\n",
      "state terminated\n",
      "episode 910, reward 319.0, memory_length 2000, epsilon 0.8336030044023311\n",
      "state terminated\n",
      "episode 911, reward 340.0, memory_length 2000, epsilon 0.8334363024721994\n",
      "state terminated\n",
      "episode 912, reward 603.0, memory_length 2000, epsilon 0.8332696338791198\n",
      "state terminated\n",
      "episode 913, reward 510.0, memory_length 2000, epsilon 0.8331029986164257\n",
      "state terminated\n",
      "episode 914, reward 401.0, memory_length 2000, epsilon 0.8329363966774516\n",
      "state terminated\n",
      "episode 915, reward 353.0, memory_length 2000, epsilon 0.8327698280555336\n",
      "state terminated\n",
      "episode 916, reward 539.0, memory_length 2000, epsilon 0.8326032927440087\n",
      "state terminated\n",
      "episode 917, reward 386.0, memory_length 2000, epsilon 0.8324367907362157\n",
      "state terminated\n",
      "episode 918, reward 610.0, memory_length 2000, epsilon 0.8322703220254944\n",
      "state terminated\n",
      "episode 919, reward 193.0, memory_length 2000, epsilon 0.8321038866051861\n",
      "state terminated\n",
      "episode 920, reward 488.0, memory_length 2000, epsilon 0.8319374844686335\n",
      "state terminated\n",
      "episode 921, reward 529.0, memory_length 2000, epsilon 0.8317711156091803\n",
      "state terminated\n",
      "episode 922, reward 448.0, memory_length 2000, epsilon 0.8316047800201717\n",
      "state terminated\n",
      "episode 923, reward 480.0, memory_length 2000, epsilon 0.8314384776949546\n",
      "state terminated\n",
      "episode 924, reward 233.0, memory_length 2000, epsilon 0.8312722086268766\n",
      "state terminated\n",
      "episode 925, reward 656.0, memory_length 2000, epsilon 0.8311059728092871\n",
      "state terminated\n",
      "episode 926, reward 405.0, memory_length 2000, epsilon 0.8309397702355367\n",
      "state terminated\n",
      "episode 927, reward 295.0, memory_length 2000, epsilon 0.8307736008989771\n",
      "state terminated\n",
      "episode 928, reward 183.0, memory_length 2000, epsilon 0.8306074647929617\n",
      "state terminated\n",
      "episode 929, reward 272.0, memory_length 2000, epsilon 0.830441361910845\n",
      "state terminated\n",
      "episode 930, reward 378.0, memory_length 2000, epsilon 0.8302752922459828\n",
      "state terminated\n",
      "episode 931, reward 564.0, memory_length 2000, epsilon 0.8301092557917326\n",
      "state terminated\n",
      "episode 932, reward 840.0, memory_length 2000, epsilon 0.8299432525414526\n",
      "state terminated\n",
      "episode 933, reward 214.0, memory_length 2000, epsilon 0.8297772824885029\n",
      "state terminated\n",
      "episode 934, reward 180.0, memory_length 2000, epsilon 0.8296113456262445\n",
      "state terminated\n",
      "episode 935, reward 377.0, memory_length 2000, epsilon 0.82944544194804\n",
      "state terminated\n",
      "episode 936, reward 137.0, memory_length 2000, epsilon 0.8292795714472534\n",
      "state terminated\n",
      "episode 937, reward 587.0, memory_length 2000, epsilon 0.8291137341172498\n",
      "state terminated\n",
      "episode 938, reward 576.0, memory_length 2000, epsilon 0.8289479299513955\n",
      "state terminated\n",
      "episode 939, reward 346.0, memory_length 2000, epsilon 0.8287821589430586\n",
      "state terminated\n",
      "episode 940, reward 310.0, memory_length 2000, epsilon 0.8286164210856083\n",
      "state terminated\n",
      "episode 941, reward 515.0, memory_length 2000, epsilon 0.8284507163724149\n",
      "state terminated\n",
      "episode 942, reward 450.0, memory_length 2000, epsilon 0.8282850447968502\n",
      "state terminated\n",
      "episode 943, reward 302.0, memory_length 2000, epsilon 0.8281194063522874\n",
      "state terminated\n",
      "episode 944, reward 342.0, memory_length 2000, epsilon 0.8279538010321009\n",
      "state terminated\n",
      "episode 945, reward 60.0, memory_length 2000, epsilon 0.8277882288296666\n",
      "state terminated\n",
      "episode 946, reward 351.0, memory_length 2000, epsilon 0.8276226897383616\n",
      "state terminated\n",
      "episode 947, reward 53.0, memory_length 2000, epsilon 0.8274571837515643\n",
      "state terminated\n",
      "episode 948, reward 241.0, memory_length 2000, epsilon 0.8272917108626545\n",
      "state terminated\n",
      "episode 949, reward 342.0, memory_length 2000, epsilon 0.8271262710650132\n",
      "state terminated\n",
      "episode 950, reward 297.0, memory_length 2000, epsilon 0.8269608643520229\n",
      "state terminated\n",
      "episode 951, reward 459.0, memory_length 2000, epsilon 0.8267954907170673\n",
      "state terminated\n",
      "episode 952, reward 544.0, memory_length 2000, epsilon 0.8266301501535313\n",
      "state terminated\n",
      "episode 953, reward 438.0, memory_length 2000, epsilon 0.8264648426548015\n",
      "state terminated\n",
      "episode 954, reward 504.0, memory_length 2000, epsilon 0.8262995682142654\n",
      "state terminated\n",
      "episode 955, reward 463.0, memory_length 2000, epsilon 0.8261343268253123\n",
      "state terminated\n",
      "episode 956, reward 602.0, memory_length 2000, epsilon 0.8259691184813324\n",
      "state terminated\n",
      "episode 957, reward 225.0, memory_length 2000, epsilon 0.8258039431757171\n",
      "state terminated\n",
      "episode 958, reward 325.0, memory_length 2000, epsilon 0.8256388009018599\n",
      "state terminated\n",
      "episode 959, reward 65.0, memory_length 2000, epsilon 0.8254736916531549\n",
      "state terminated\n",
      "episode 960, reward 603.0, memory_length 2000, epsilon 0.8253086154229974\n",
      "state terminated\n",
      "episode 961, reward 737.0, memory_length 2000, epsilon 0.8251435722047847\n",
      "state terminated\n",
      "episode 962, reward 157.0, memory_length 2000, epsilon 0.8249785619919152\n",
      "state terminated\n",
      "episode 963, reward 234.0, memory_length 2000, epsilon 0.8248135847777882\n",
      "state terminated\n",
      "episode 964, reward 640.0, memory_length 2000, epsilon 0.8246486405558046\n",
      "state terminated\n",
      "episode 965, reward 115.0, memory_length 2000, epsilon 0.8244837293193668\n",
      "state terminated\n",
      "episode 966, reward 522.0, memory_length 2000, epsilon 0.8243188510618783\n",
      "state terminated\n",
      "episode 967, reward 378.0, memory_length 2000, epsilon 0.8241540057767439\n",
      "state terminated\n",
      "episode 968, reward 557.0, memory_length 2000, epsilon 0.8239891934573698\n",
      "state terminated\n",
      "episode 969, reward 475.0, memory_length 2000, epsilon 0.8238244140971637\n",
      "state terminated\n",
      "episode 970, reward 40.0, memory_length 2000, epsilon 0.8236596676895341\n",
      "state terminated\n",
      "episode 971, reward 189.0, memory_length 2000, epsilon 0.8234949542278914\n",
      "state terminated\n",
      "episode 972, reward -91.0, memory_length 2000, epsilon 0.823330273705647\n",
      "state terminated\n",
      "episode 973, reward 208.0, memory_length 2000, epsilon 0.8231656261162136\n",
      "state terminated\n",
      "episode 974, reward 378.0, memory_length 2000, epsilon 0.8230010114530054\n",
      "state terminated\n",
      "episode 975, reward 133.0, memory_length 2000, epsilon 0.8228364297094378\n",
      "state terminated\n",
      "episode 976, reward 327.0, memory_length 2000, epsilon 0.8226718808789274\n",
      "state terminated\n",
      "episode 977, reward 312.0, memory_length 2000, epsilon 0.8225073649548925\n",
      "state terminated\n",
      "episode 978, reward 292.0, memory_length 2000, epsilon 0.8223428819307522\n",
      "state terminated\n",
      "episode 979, reward 648.0, memory_length 2000, epsilon 0.8221784317999273\n",
      "state terminated\n",
      "episode 980, reward 640.0, memory_length 2000, epsilon 0.8220140145558398\n",
      "state terminated\n",
      "episode 981, reward 538.0, memory_length 2000, epsilon 0.8218496301919129\n",
      "state terminated\n",
      "episode 982, reward 160.0, memory_length 2000, epsilon 0.8216852787015714\n",
      "state terminated\n",
      "episode 983, reward 123.0, memory_length 2000, epsilon 0.8215209600782412\n",
      "state terminated\n",
      "episode 984, reward 476.0, memory_length 2000, epsilon 0.8213566743153494\n",
      "state terminated\n",
      "episode 985, reward 702.0, memory_length 2000, epsilon 0.8211924214063249\n",
      "state terminated\n",
      "episode 986, reward 167.0, memory_length 2000, epsilon 0.8210282013445971\n",
      "state terminated\n",
      "episode 987, reward 630.0, memory_length 2000, epsilon 0.8208640141235976\n",
      "state terminated\n",
      "episode 988, reward 391.0, memory_length 2000, epsilon 0.8206998597367586\n",
      "state terminated\n",
      "episode 989, reward 103.0, memory_length 2000, epsilon 0.8205357381775144\n",
      "state terminated\n",
      "episode 990, reward 539.0, memory_length 2000, epsilon 0.8203716494392996\n",
      "state terminated\n",
      "episode 991, reward 282.0, memory_length 2000, epsilon 0.820207593515551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 992, reward 593.0, memory_length 2000, epsilon 0.8200435703997062\n",
      "state terminated\n",
      "episode 993, reward 171.0, memory_length 2000, epsilon 0.8198795800852043\n",
      "state terminated\n",
      "episode 994, reward -42.0, memory_length 2000, epsilon 0.8197156225654858\n",
      "state terminated\n",
      "episode 995, reward 296.0, memory_length 2000, epsilon 0.8195516978339923\n",
      "state terminated\n",
      "episode 996, reward 326.0, memory_length 2000, epsilon 0.8193878058841668\n",
      "state terminated\n",
      "episode 997, reward 223.0, memory_length 2000, epsilon 0.8192239467094536\n",
      "state terminated\n",
      "episode 998, reward 629.0, memory_length 2000, epsilon 0.8190601203032984\n",
      "state terminated\n",
      "episode 999, reward 261.0, memory_length 2000, epsilon 0.8188963266591482\n",
      "state terminated\n",
      "episode 1000, reward 283.0, memory_length 2000, epsilon 0.8187325657704511\n",
      "Total time taken  6562.746367931366\n",
      "state terminated\n",
      "episode 1001, reward 499.0, memory_length 2000, epsilon 0.8185688376306567\n",
      "state terminated\n",
      "episode 1002, reward 305.0, memory_length 2000, epsilon 0.8184051422332159\n",
      "state terminated\n",
      "episode 1003, reward 655.0, memory_length 2000, epsilon 0.8182414795715811\n",
      "state terminated\n",
      "episode 1004, reward 188.0, memory_length 2000, epsilon 0.8180778496392054\n",
      "state terminated\n",
      "episode 1005, reward 335.0, memory_length 2000, epsilon 0.8179142524295439\n",
      "state terminated\n",
      "episode 1006, reward 556.0, memory_length 2000, epsilon 0.8177506879360524\n",
      "state terminated\n",
      "episode 1007, reward 472.0, memory_length 2000, epsilon 0.8175871561521888\n",
      "state terminated\n",
      "episode 1008, reward 154.0, memory_length 2000, epsilon 0.8174236570714114\n",
      "state terminated\n",
      "episode 1009, reward 157.0, memory_length 2000, epsilon 0.8172601906871804\n",
      "state terminated\n",
      "episode 1010, reward 462.0, memory_length 2000, epsilon 0.8170967569929571\n",
      "state terminated\n",
      "episode 1011, reward 214.0, memory_length 2000, epsilon 0.8169333559822044\n",
      "state terminated\n",
      "episode 1012, reward 517.0, memory_length 2000, epsilon 0.8167699876483858\n",
      "state terminated\n",
      "episode 1013, reward 417.0, memory_length 2000, epsilon 0.816606651984967\n",
      "state terminated\n",
      "episode 1014, reward 463.0, memory_length 2000, epsilon 0.8164433489854143\n",
      "state terminated\n",
      "episode 1015, reward 468.0, memory_length 2000, epsilon 0.8162800786431956\n",
      "state terminated\n",
      "episode 1016, reward 153.0, memory_length 2000, epsilon 0.8161168409517803\n",
      "state terminated\n",
      "episode 1017, reward 663.0, memory_length 2000, epsilon 0.8159536359046387\n",
      "state terminated\n",
      "episode 1018, reward 286.0, memory_length 2000, epsilon 0.8157904634952426\n",
      "state terminated\n",
      "episode 1019, reward -10.0, memory_length 2000, epsilon 0.8156273237170651\n",
      "state terminated\n",
      "episode 1020, reward 630.0, memory_length 2000, epsilon 0.8154642165635808\n",
      "state terminated\n",
      "episode 1021, reward 489.0, memory_length 2000, epsilon 0.8153011420282651\n",
      "state terminated\n",
      "episode 1022, reward 650.0, memory_length 2000, epsilon 0.8151381001045954\n",
      "state terminated\n",
      "episode 1023, reward 512.0, memory_length 2000, epsilon 0.8149750907860497\n",
      "state terminated\n",
      "episode 1024, reward 432.0, memory_length 2000, epsilon 0.8148121140661078\n",
      "state terminated\n",
      "episode 1025, reward 747.0, memory_length 2000, epsilon 0.8146491699382504\n",
      "state terminated\n",
      "episode 1026, reward 413.0, memory_length 2000, epsilon 0.81448625839596\n",
      "state terminated\n",
      "episode 1027, reward 781.0, memory_length 2000, epsilon 0.81432337943272\n",
      "state terminated\n",
      "episode 1028, reward 377.0, memory_length 2000, epsilon 0.8141605330420155\n",
      "state terminated\n",
      "episode 1029, reward 453.0, memory_length 2000, epsilon 0.8139977192173322\n",
      "state terminated\n",
      "episode 1030, reward 377.0, memory_length 2000, epsilon 0.8138349379521579\n",
      "state terminated\n",
      "episode 1031, reward 459.0, memory_length 2000, epsilon 0.8136721892399812\n",
      "state terminated\n",
      "episode 1032, reward 386.0, memory_length 2000, epsilon 0.8135094730742921\n",
      "state terminated\n",
      "episode 1033, reward 660.0, memory_length 2000, epsilon 0.8133467894485822\n",
      "state terminated\n",
      "episode 1034, reward 408.0, memory_length 2000, epsilon 0.8131841383563437\n",
      "state terminated\n",
      "episode 1035, reward 594.0, memory_length 2000, epsilon 0.8130215197910712\n",
      "state terminated\n",
      "episode 1036, reward 670.0, memory_length 2000, epsilon 0.8128589337462593\n",
      "state terminated\n",
      "episode 1037, reward 155.0, memory_length 2000, epsilon 0.812696380215405\n",
      "state terminated\n",
      "episode 1038, reward 633.0, memory_length 2000, epsilon 0.812533859192006\n",
      "state terminated\n",
      "episode 1039, reward 418.0, memory_length 2000, epsilon 0.8123713706695614\n",
      "state terminated\n",
      "episode 1040, reward 460.0, memory_length 2000, epsilon 0.8122089146415719\n",
      "state terminated\n",
      "episode 1041, reward 262.0, memory_length 2000, epsilon 0.812046491101539\n",
      "state terminated\n",
      "episode 1042, reward 422.0, memory_length 2000, epsilon 0.8118841000429659\n",
      "state terminated\n",
      "episode 1043, reward 382.0, memory_length 2000, epsilon 0.8117217414593568\n",
      "state terminated\n",
      "episode 1044, reward 621.0, memory_length 2000, epsilon 0.8115594153442176\n",
      "state terminated\n",
      "episode 1045, reward 468.0, memory_length 2000, epsilon 0.8113971216910549\n",
      "state terminated\n",
      "episode 1046, reward 456.0, memory_length 2000, epsilon 0.8112348604933775\n",
      "state terminated\n",
      "episode 1047, reward 655.0, memory_length 2000, epsilon 0.8110726317446944\n",
      "state terminated\n",
      "episode 1048, reward 536.0, memory_length 2000, epsilon 0.8109104354385167\n",
      "state terminated\n",
      "episode 1049, reward 594.0, memory_length 2000, epsilon 0.8107482715683565\n",
      "state terminated\n",
      "episode 1050, reward 27.0, memory_length 2000, epsilon 0.8105861401277273\n",
      "state terminated\n",
      "episode 1051, reward 162.0, memory_length 2000, epsilon 0.810424041110144\n",
      "state terminated\n",
      "episode 1052, reward 174.0, memory_length 2000, epsilon 0.8102619745091222\n",
      "state terminated\n",
      "episode 1053, reward 261.0, memory_length 2000, epsilon 0.8100999403181797\n",
      "state terminated\n",
      "episode 1054, reward 432.0, memory_length 2000, epsilon 0.8099379385308347\n",
      "state terminated\n",
      "episode 1055, reward 400.0, memory_length 2000, epsilon 0.8097759691406075\n",
      "state terminated\n",
      "episode 1056, reward 757.0, memory_length 2000, epsilon 0.8096140321410191\n",
      "state terminated\n",
      "episode 1057, reward 594.0, memory_length 2000, epsilon 0.809452127525592\n",
      "state terminated\n",
      "episode 1058, reward 246.0, memory_length 2000, epsilon 0.8092902552878504\n",
      "state terminated\n",
      "episode 1059, reward 660.0, memory_length 2000, epsilon 0.8091284154213189\n",
      "state terminated\n",
      "episode 1060, reward 535.0, memory_length 2000, epsilon 0.8089666079195241\n",
      "state terminated\n",
      "episode 1061, reward 396.0, memory_length 2000, epsilon 0.8088048327759938\n",
      "state terminated\n",
      "episode 1062, reward 750.0, memory_length 2000, epsilon 0.8086430899842569\n",
      "state terminated\n",
      "episode 1063, reward 684.0, memory_length 2000, epsilon 0.8084813795378438\n",
      "state terminated\n",
      "episode 1064, reward 890.0, memory_length 2000, epsilon 0.8083197014302859\n",
      "state terminated\n",
      "episode 1065, reward 659.0, memory_length 2000, epsilon 0.8081580556551162\n",
      "state terminated\n",
      "episode 1066, reward 767.0, memory_length 2000, epsilon 0.8079964422058689\n",
      "state terminated\n",
      "episode 1067, reward 569.0, memory_length 2000, epsilon 0.8078348610760793\n",
      "state terminated\n",
      "episode 1068, reward 454.0, memory_length 2000, epsilon 0.8076733122592842\n",
      "state terminated\n",
      "episode 1069, reward 237.0, memory_length 2000, epsilon 0.8075117957490217\n",
      "state terminated\n",
      "episode 1070, reward 378.0, memory_length 2000, epsilon 0.8073503115388312\n",
      "state terminated\n",
      "episode 1071, reward 865.0, memory_length 2000, epsilon 0.8071888596222534\n",
      "state terminated\n",
      "episode 1072, reward 402.0, memory_length 2000, epsilon 0.8070274399928299\n",
      "state terminated\n",
      "episode 1073, reward 696.0, memory_length 2000, epsilon 0.806866052644104\n",
      "state terminated\n",
      "episode 1074, reward 548.0, memory_length 2000, epsilon 0.8067046975696206\n",
      "state terminated\n",
      "episode 1075, reward 520.0, memory_length 2000, epsilon 0.8065433747629251\n",
      "state terminated\n",
      "episode 1076, reward 526.0, memory_length 2000, epsilon 0.8063820842175647\n",
      "state terminated\n",
      "episode 1077, reward 286.0, memory_length 2000, epsilon 0.8062208259270877\n",
      "state terminated\n",
      "episode 1078, reward 490.0, memory_length 2000, epsilon 0.8060595998850439\n",
      "state terminated\n",
      "episode 1079, reward 135.0, memory_length 2000, epsilon 0.8058984060849842\n",
      "state terminated\n",
      "episode 1080, reward 531.0, memory_length 2000, epsilon 0.8057372445204609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1081, reward 69.0, memory_length 2000, epsilon 0.8055761151850275\n",
      "state terminated\n",
      "episode 1082, reward 389.0, memory_length 2000, epsilon 0.8054150180722387\n",
      "state terminated\n",
      "episode 1083, reward 494.0, memory_length 2000, epsilon 0.8052539531756508\n",
      "state terminated\n",
      "episode 1084, reward 642.0, memory_length 2000, epsilon 0.8050929204888212\n",
      "state terminated\n",
      "episode 1085, reward 370.0, memory_length 2000, epsilon 0.8049319200053084\n",
      "state terminated\n",
      "episode 1086, reward 432.0, memory_length 2000, epsilon 0.8047709517186725\n",
      "state terminated\n",
      "episode 1087, reward 406.0, memory_length 2000, epsilon 0.8046100156224749\n",
      "state terminated\n",
      "episode 1088, reward 369.0, memory_length 2000, epsilon 0.804449111710278\n",
      "state terminated\n",
      "episode 1089, reward 492.0, memory_length 2000, epsilon 0.8042882399756457\n",
      "state terminated\n",
      "episode 1090, reward 397.0, memory_length 2000, epsilon 0.8041274004121429\n",
      "state terminated\n",
      "episode 1091, reward 653.0, memory_length 2000, epsilon 0.8039665930133365\n",
      "state terminated\n",
      "episode 1092, reward 306.0, memory_length 2000, epsilon 0.8038058177727937\n",
      "state terminated\n",
      "episode 1093, reward 504.0, memory_length 2000, epsilon 0.8036450746840839\n",
      "state terminated\n",
      "episode 1094, reward 463.0, memory_length 2000, epsilon 0.8034843637407771\n",
      "state terminated\n",
      "episode 1095, reward 721.0, memory_length 2000, epsilon 0.803323684936445\n",
      "state terminated\n",
      "episode 1096, reward 419.0, memory_length 2000, epsilon 0.8031630382646603\n",
      "state terminated\n",
      "episode 1097, reward 363.0, memory_length 2000, epsilon 0.8030024237189973\n",
      "state terminated\n",
      "episode 1098, reward 557.0, memory_length 2000, epsilon 0.8028418412930315\n",
      "state terminated\n",
      "episode 1099, reward 297.0, memory_length 2000, epsilon 0.8026812909803392\n",
      "state terminated\n",
      "episode 1100, reward 551.0, memory_length 2000, epsilon 0.8025207727744988\n",
      "state terminated\n",
      "episode 1101, reward 642.0, memory_length 2000, epsilon 0.8023602866690894\n",
      "state terminated\n",
      "episode 1102, reward 24.0, memory_length 2000, epsilon 0.8021998326576916\n",
      "state terminated\n",
      "episode 1103, reward 762.0, memory_length 2000, epsilon 0.8020394107338872\n",
      "state terminated\n",
      "episode 1104, reward 468.0, memory_length 2000, epsilon 0.8018790208912593\n",
      "state terminated\n",
      "episode 1105, reward 822.0, memory_length 2000, epsilon 0.8017186631233923\n",
      "state terminated\n",
      "episode 1106, reward 216.0, memory_length 2000, epsilon 0.8015583374238721\n",
      "state terminated\n",
      "episode 1107, reward 270.0, memory_length 2000, epsilon 0.8013980437862853\n",
      "state terminated\n",
      "episode 1108, reward 576.0, memory_length 2000, epsilon 0.8012377822042205\n",
      "state terminated\n",
      "episode 1109, reward 611.0, memory_length 2000, epsilon 0.801077552671267\n",
      "state terminated\n",
      "episode 1110, reward 423.0, memory_length 2000, epsilon 0.8009173551810158\n",
      "state terminated\n",
      "episode 1111, reward 282.0, memory_length 2000, epsilon 0.8007571897270589\n",
      "state terminated\n",
      "episode 1112, reward 224.0, memory_length 2000, epsilon 0.8005970563029897\n",
      "state terminated\n",
      "episode 1113, reward 196.0, memory_length 2000, epsilon 0.8004369549024029\n",
      "state terminated\n",
      "episode 1114, reward 243.0, memory_length 2000, epsilon 0.8002768855188942\n",
      "state terminated\n",
      "episode 1115, reward 301.0, memory_length 2000, epsilon 0.8001168481460612\n",
      "state terminated\n",
      "episode 1116, reward 254.0, memory_length 2000, epsilon 0.7999568427775022\n",
      "state terminated\n",
      "episode 1117, reward 498.0, memory_length 2000, epsilon 0.7997968694068169\n",
      "state terminated\n",
      "episode 1118, reward 340.0, memory_length 2000, epsilon 0.7996369280276067\n",
      "state terminated\n",
      "episode 1119, reward 165.0, memory_length 2000, epsilon 0.7994770186334736\n",
      "state terminated\n",
      "episode 1120, reward 296.0, memory_length 2000, epsilon 0.7993171412180213\n",
      "state terminated\n",
      "episode 1121, reward 513.0, memory_length 2000, epsilon 0.799157295774855\n",
      "state terminated\n",
      "episode 1122, reward 432.0, memory_length 2000, epsilon 0.7989974822975804\n",
      "state terminated\n",
      "episode 1123, reward 195.0, memory_length 2000, epsilon 0.7988377007798053\n",
      "state terminated\n",
      "episode 1124, reward 853.0, memory_length 2000, epsilon 0.7986779512151383\n",
      "state terminated\n",
      "episode 1125, reward 389.0, memory_length 2000, epsilon 0.7985182335971894\n",
      "state terminated\n",
      "episode 1126, reward 669.0, memory_length 2000, epsilon 0.7983585479195701\n",
      "state terminated\n",
      "episode 1127, reward 506.0, memory_length 2000, epsilon 0.7981988941758927\n",
      "state terminated\n",
      "episode 1128, reward 724.0, memory_length 2000, epsilon 0.7980392723597712\n",
      "state terminated\n",
      "episode 1129, reward 372.0, memory_length 2000, epsilon 0.7978796824648207\n",
      "state terminated\n",
      "episode 1130, reward 750.0, memory_length 2000, epsilon 0.7977201244846576\n",
      "state terminated\n",
      "episode 1131, reward 426.0, memory_length 2000, epsilon 0.7975605984128996\n",
      "state terminated\n",
      "episode 1132, reward 385.0, memory_length 2000, epsilon 0.7974011042431656\n",
      "state terminated\n",
      "episode 1133, reward 284.0, memory_length 2000, epsilon 0.797241641969076\n",
      "state terminated\n",
      "episode 1134, reward 449.0, memory_length 2000, epsilon 0.7970822115842521\n",
      "state terminated\n",
      "episode 1135, reward 592.0, memory_length 2000, epsilon 0.7969228130823167\n",
      "state terminated\n",
      "episode 1136, reward 641.0, memory_length 2000, epsilon 0.796763446456894\n",
      "state terminated\n",
      "episode 1137, reward 291.0, memory_length 2000, epsilon 0.7966041117016093\n",
      "state terminated\n",
      "episode 1138, reward 175.0, memory_length 2000, epsilon 0.7964448088100892\n",
      "state terminated\n",
      "episode 1139, reward 579.0, memory_length 2000, epsilon 0.7962855377759614\n",
      "state terminated\n",
      "episode 1140, reward 485.0, memory_length 2000, epsilon 0.7961262985928554\n",
      "state terminated\n",
      "episode 1141, reward 639.0, memory_length 2000, epsilon 0.7959670912544012\n",
      "state terminated\n",
      "episode 1142, reward 704.0, memory_length 2000, epsilon 0.795807915754231\n",
      "state terminated\n",
      "episode 1143, reward 538.0, memory_length 2000, epsilon 0.7956487720859775\n",
      "state terminated\n",
      "episode 1144, reward 589.0, memory_length 2000, epsilon 0.7954896602432749\n",
      "state terminated\n",
      "episode 1145, reward 671.0, memory_length 2000, epsilon 0.7953305802197589\n",
      "state terminated\n",
      "episode 1146, reward 278.0, memory_length 2000, epsilon 0.7951715320090662\n",
      "state terminated\n",
      "episode 1147, reward 241.0, memory_length 2000, epsilon 0.7950125156048349\n",
      "state terminated\n",
      "episode 1148, reward 301.0, memory_length 2000, epsilon 0.7948535310007042\n",
      "state terminated\n",
      "episode 1149, reward 889.0, memory_length 2000, epsilon 0.7946945781903151\n",
      "state terminated\n",
      "episode 1150, reward 308.0, memory_length 2000, epsilon 0.794535657167309\n",
      "state terminated\n",
      "episode 1151, reward 777.0, memory_length 2000, epsilon 0.7943767679253293\n",
      "state terminated\n",
      "episode 1152, reward 10.0, memory_length 2000, epsilon 0.7942179104580205\n",
      "state terminated\n",
      "episode 1153, reward 461.0, memory_length 2000, epsilon 0.7940590847590283\n",
      "state terminated\n",
      "episode 1154, reward 828.0, memory_length 2000, epsilon 0.7939002908219994\n",
      "state terminated\n",
      "episode 1155, reward 666.0, memory_length 2000, epsilon 0.7937415286405823\n",
      "state terminated\n",
      "episode 1156, reward 706.0, memory_length 2000, epsilon 0.7935827982084266\n",
      "state terminated\n",
      "episode 1157, reward 220.0, memory_length 2000, epsilon 0.7934240995191828\n",
      "state terminated\n",
      "episode 1158, reward 695.0, memory_length 2000, epsilon 0.7932654325665032\n",
      "state terminated\n",
      "episode 1159, reward 326.0, memory_length 2000, epsilon 0.7931067973440409\n",
      "state terminated\n",
      "episode 1160, reward 548.0, memory_length 2000, epsilon 0.7929481938454506\n",
      "state terminated\n",
      "episode 1161, reward 771.0, memory_length 2000, epsilon 0.7927896220643882\n",
      "state terminated\n",
      "episode 1162, reward 769.0, memory_length 2000, epsilon 0.7926310819945107\n",
      "state terminated\n",
      "episode 1163, reward 561.0, memory_length 2000, epsilon 0.7924725736294767\n",
      "state terminated\n",
      "episode 1164, reward 849.0, memory_length 2000, epsilon 0.7923140969629457\n",
      "state terminated\n",
      "episode 1165, reward 585.0, memory_length 2000, epsilon 0.7921556519885787\n",
      "state terminated\n",
      "episode 1166, reward 613.0, memory_length 2000, epsilon 0.7919972387000379\n",
      "state terminated\n",
      "episode 1167, reward 180.0, memory_length 2000, epsilon 0.7918388570909867\n",
      "state terminated\n",
      "episode 1168, reward 234.0, memory_length 2000, epsilon 0.79168050715509\n",
      "state terminated\n",
      "episode 1169, reward 75.0, memory_length 2000, epsilon 0.7915221888860137\n",
      "state terminated\n",
      "episode 1170, reward 776.0, memory_length 2000, epsilon 0.7913639022774249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1171, reward 799.0, memory_length 2000, epsilon 0.7912056473229924\n",
      "state terminated\n",
      "episode 1172, reward 849.0, memory_length 2000, epsilon 0.7910474240163858\n",
      "state terminated\n",
      "episode 1173, reward 835.0, memory_length 2000, epsilon 0.7908892323512764\n",
      "state terminated\n",
      "episode 1174, reward 443.0, memory_length 2000, epsilon 0.7907310723213363\n",
      "state terminated\n",
      "episode 1175, reward 508.0, memory_length 2000, epsilon 0.7905729439202392\n",
      "state terminated\n",
      "episode 1176, reward 508.0, memory_length 2000, epsilon 0.7904148471416601\n",
      "state terminated\n",
      "episode 1177, reward 504.0, memory_length 2000, epsilon 0.7902567819792748\n",
      "state terminated\n",
      "episode 1178, reward 286.0, memory_length 2000, epsilon 0.790098748426761\n",
      "state terminated\n",
      "episode 1179, reward 57.0, memory_length 2000, epsilon 0.7899407464777972\n",
      "state terminated\n",
      "episode 1180, reward 711.0, memory_length 2000, epsilon 0.7897827761260634\n",
      "state terminated\n",
      "episode 1181, reward 281.0, memory_length 2000, epsilon 0.7896248373652407\n",
      "state terminated\n",
      "episode 1182, reward 170.0, memory_length 2000, epsilon 0.7894669301890117\n",
      "state terminated\n",
      "episode 1183, reward 168.0, memory_length 2000, epsilon 0.7893090545910599\n",
      "state terminated\n",
      "episode 1184, reward 528.0, memory_length 2000, epsilon 0.7891512105650704\n",
      "state terminated\n",
      "episode 1185, reward 216.0, memory_length 2000, epsilon 0.7889933981047295\n",
      "state terminated\n",
      "episode 1186, reward 282.0, memory_length 2000, epsilon 0.7888356172037245\n",
      "state terminated\n",
      "episode 1187, reward 414.0, memory_length 2000, epsilon 0.7886778678557445\n",
      "state terminated\n",
      "episode 1188, reward 710.0, memory_length 2000, epsilon 0.7885201500544792\n",
      "state terminated\n",
      "episode 1189, reward 418.0, memory_length 2000, epsilon 0.78836246379362\n",
      "state terminated\n",
      "episode 1190, reward 600.0, memory_length 2000, epsilon 0.7882048090668594\n",
      "state terminated\n",
      "episode 1191, reward 10.0, memory_length 2000, epsilon 0.7880471858678915\n",
      "state terminated\n",
      "episode 1192, reward 684.0, memory_length 2000, epsilon 0.7878895941904108\n",
      "state terminated\n",
      "episode 1193, reward 247.0, memory_length 2000, epsilon 0.7877320340281142\n",
      "state terminated\n",
      "episode 1194, reward 762.0, memory_length 2000, epsilon 0.787574505374699\n",
      "state terminated\n",
      "episode 1195, reward 638.0, memory_length 2000, epsilon 0.7874170082238642\n",
      "state terminated\n",
      "episode 1196, reward 506.0, memory_length 2000, epsilon 0.7872595425693097\n",
      "state terminated\n",
      "episode 1197, reward 526.0, memory_length 2000, epsilon 0.787102108404737\n",
      "state terminated\n",
      "episode 1198, reward 417.0, memory_length 2000, epsilon 0.7869447057238489\n",
      "state terminated\n",
      "episode 1199, reward 264.0, memory_length 2000, epsilon 0.7867873345203491\n",
      "state terminated\n",
      "episode 1200, reward 670.0, memory_length 2000, epsilon 0.7866299947879427\n",
      "state terminated\n",
      "episode 1201, reward 657.0, memory_length 2000, epsilon 0.7864726865203363\n",
      "state terminated\n",
      "episode 1202, reward 784.0, memory_length 2000, epsilon 0.7863154097112374\n",
      "state terminated\n",
      "episode 1203, reward 384.0, memory_length 2000, epsilon 0.7861581643543549\n",
      "state terminated\n",
      "episode 1204, reward 390.0, memory_length 2000, epsilon 0.7860009504433992\n",
      "state terminated\n",
      "episode 1205, reward 625.0, memory_length 2000, epsilon 0.7858437679720817\n",
      "state terminated\n",
      "episode 1206, reward 443.0, memory_length 2000, epsilon 0.7856866169341148\n",
      "state terminated\n",
      "episode 1207, reward 199.0, memory_length 2000, epsilon 0.7855294973232128\n",
      "state terminated\n",
      "episode 1208, reward 738.0, memory_length 2000, epsilon 0.7853724091330908\n",
      "state terminated\n",
      "episode 1209, reward 577.0, memory_length 2000, epsilon 0.7852153523574652\n",
      "state terminated\n",
      "episode 1210, reward 531.0, memory_length 2000, epsilon 0.785058326990054\n",
      "state terminated\n",
      "episode 1211, reward 467.0, memory_length 2000, epsilon 0.7849013330245758\n",
      "state terminated\n",
      "episode 1212, reward 326.0, memory_length 2000, epsilon 0.7847443704547511\n",
      "state terminated\n",
      "episode 1213, reward 675.0, memory_length 2000, epsilon 0.7845874392743013\n",
      "state terminated\n",
      "episode 1214, reward 919.0, memory_length 2000, epsilon 0.7844305394769491\n",
      "state terminated\n",
      "episode 1215, reward 567.0, memory_length 2000, epsilon 0.7842736710564188\n",
      "state terminated\n",
      "episode 1216, reward 643.0, memory_length 2000, epsilon 0.7841168340064353\n",
      "state terminated\n",
      "episode 1217, reward 747.0, memory_length 2000, epsilon 0.7839600283207252\n",
      "state terminated\n",
      "episode 1218, reward 511.0, memory_length 2000, epsilon 0.7838032539930164\n",
      "state terminated\n",
      "episode 1219, reward 117.0, memory_length 2000, epsilon 0.7836465110170379\n",
      "state terminated\n",
      "episode 1220, reward 612.0, memory_length 2000, epsilon 0.7834897993865199\n",
      "state terminated\n",
      "episode 1221, reward 987.0, memory_length 2000, epsilon 0.783333119095194\n",
      "state terminated\n",
      "episode 1222, reward 602.0, memory_length 2000, epsilon 0.7831764701367929\n",
      "state terminated\n",
      "episode 1223, reward 426.0, memory_length 2000, epsilon 0.7830198525050508\n",
      "state terminated\n",
      "episode 1224, reward 731.0, memory_length 2000, epsilon 0.7828632661937028\n",
      "state terminated\n",
      "episode 1225, reward 480.0, memory_length 2000, epsilon 0.7827067111964857\n",
      "state terminated\n",
      "episode 1226, reward 335.0, memory_length 2000, epsilon 0.7825501875071371\n",
      "state terminated\n",
      "episode 1227, reward 348.0, memory_length 2000, epsilon 0.7823936951193962\n",
      "state terminated\n",
      "episode 1228, reward 907.0, memory_length 2000, epsilon 0.782237234027003\n",
      "state terminated\n",
      "episode 1229, reward 477.0, memory_length 2000, epsilon 0.7820808042236994\n",
      "state terminated\n",
      "episode 1230, reward 532.0, memory_length 2000, epsilon 0.781924405703228\n",
      "state terminated\n",
      "episode 1231, reward 497.0, memory_length 2000, epsilon 0.781768038459333\n",
      "state terminated\n",
      "episode 1232, reward 404.0, memory_length 2000, epsilon 0.7816117024857596\n",
      "state terminated\n",
      "episode 1233, reward 430.0, memory_length 2000, epsilon 0.7814553977762544\n",
      "state terminated\n",
      "episode 1234, reward 508.0, memory_length 2000, epsilon 0.7812991243245652\n",
      "state terminated\n",
      "episode 1235, reward 445.0, memory_length 2000, epsilon 0.781142882124441\n",
      "state terminated\n",
      "episode 1236, reward 729.0, memory_length 2000, epsilon 0.7809866711696325\n",
      "state terminated\n",
      "episode 1237, reward 118.0, memory_length 2000, epsilon 0.7808304914538907\n",
      "state terminated\n",
      "episode 1238, reward 276.0, memory_length 2000, epsilon 0.7806743429709686\n",
      "state terminated\n",
      "episode 1239, reward 864.0, memory_length 2000, epsilon 0.7805182257146205\n",
      "state terminated\n",
      "episode 1240, reward 638.0, memory_length 2000, epsilon 0.7803621396786015\n",
      "state terminated\n",
      "episode 1241, reward 875.0, memory_length 2000, epsilon 0.7802060848566681\n",
      "state terminated\n",
      "episode 1242, reward 403.0, memory_length 2000, epsilon 0.7800500612425784\n",
      "state terminated\n",
      "episode 1243, reward 566.0, memory_length 2000, epsilon 0.779894068830091\n",
      "state terminated\n",
      "episode 1244, reward 648.0, memory_length 2000, epsilon 0.7797381076129666\n",
      "state terminated\n",
      "episode 1245, reward 341.0, memory_length 2000, epsilon 0.7795821775849666\n",
      "state terminated\n",
      "episode 1246, reward 616.0, memory_length 2000, epsilon 0.7794262787398538\n",
      "state terminated\n",
      "episode 1247, reward 540.0, memory_length 2000, epsilon 0.779270411071392\n",
      "state terminated\n",
      "episode 1248, reward 494.0, memory_length 2000, epsilon 0.7791145745733472\n",
      "state terminated\n",
      "episode 1249, reward 663.0, memory_length 2000, epsilon 0.7789587692394851\n",
      "state terminated\n",
      "episode 1250, reward 405.0, memory_length 2000, epsilon 0.7788029950635742\n",
      "state terminated\n",
      "episode 1251, reward 307.0, memory_length 2000, epsilon 0.7786472520393829\n",
      "state terminated\n",
      "episode 1252, reward 738.0, memory_length 2000, epsilon 0.778491540160682\n",
      "state terminated\n",
      "episode 1253, reward 153.0, memory_length 2000, epsilon 0.7783358594212427\n",
      "state terminated\n",
      "episode 1254, reward 438.0, memory_length 2000, epsilon 0.778180209814838\n",
      "state terminated\n",
      "episode 1255, reward 306.0, memory_length 2000, epsilon 0.7780245913352417\n",
      "state terminated\n",
      "episode 1256, reward 519.0, memory_length 2000, epsilon 0.7778690039762292\n",
      "state terminated\n",
      "episode 1257, reward 399.0, memory_length 2000, epsilon 0.7777134477315769\n",
      "state terminated\n",
      "episode 1258, reward 740.0, memory_length 2000, epsilon 0.7775579225950626\n",
      "state terminated\n",
      "episode 1259, reward 620.0, memory_length 2000, epsilon 0.7774024285604655\n",
      "state terminated\n",
      "episode 1260, reward 369.0, memory_length 2000, epsilon 0.7772469656215654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1261, reward 904.0, memory_length 2000, epsilon 0.7770915337721441\n",
      "state terminated\n",
      "episode 1262, reward 294.0, memory_length 2000, epsilon 0.7769361330059843\n",
      "state terminated\n",
      "episode 1263, reward 533.0, memory_length 2000, epsilon 0.77678076331687\n",
      "state terminated\n",
      "episode 1264, reward 468.0, memory_length 2000, epsilon 0.7766254246985863\n",
      "state terminated\n",
      "episode 1265, reward 472.0, memory_length 2000, epsilon 0.7764701171449195\n",
      "state terminated\n",
      "episode 1266, reward 918.0, memory_length 2000, epsilon 0.7763148406496577\n",
      "state terminated\n",
      "episode 1267, reward 638.0, memory_length 2000, epsilon 0.7761595952065896\n",
      "state terminated\n",
      "episode 1268, reward 476.0, memory_length 2000, epsilon 0.7760043808095054\n",
      "state terminated\n",
      "episode 1269, reward 739.0, memory_length 2000, epsilon 0.7758491974521965\n",
      "state terminated\n",
      "episode 1270, reward 757.0, memory_length 2000, epsilon 0.7756940451284555\n",
      "state terminated\n",
      "episode 1271, reward 502.0, memory_length 2000, epsilon 0.7755389238320766\n",
      "state terminated\n",
      "episode 1272, reward 450.0, memory_length 2000, epsilon 0.7753838335568546\n",
      "state terminated\n",
      "episode 1273, reward 638.0, memory_length 2000, epsilon 0.7752287742965861\n",
      "state terminated\n",
      "episode 1274, reward 391.0, memory_length 2000, epsilon 0.7750737460450687\n",
      "state terminated\n",
      "episode 1275, reward 954.0, memory_length 2000, epsilon 0.7749187487961013\n",
      "state terminated\n",
      "episode 1276, reward 486.0, memory_length 2000, epsilon 0.7747637825434839\n",
      "state terminated\n",
      "episode 1277, reward 467.0, memory_length 2000, epsilon 0.7746088472810179\n",
      "state terminated\n",
      "episode 1278, reward 604.0, memory_length 2000, epsilon 0.7744539430025059\n",
      "state terminated\n",
      "episode 1279, reward 255.0, memory_length 2000, epsilon 0.7742990697017517\n",
      "state terminated\n",
      "episode 1280, reward 764.0, memory_length 2000, epsilon 0.7741442273725605\n",
      "state terminated\n",
      "episode 1281, reward 859.0, memory_length 2000, epsilon 0.7739894160087383\n",
      "state terminated\n",
      "episode 1282, reward 625.0, memory_length 2000, epsilon 0.7738346356040929\n",
      "state terminated\n",
      "episode 1283, reward 298.0, memory_length 2000, epsilon 0.7736798861524332\n",
      "state terminated\n",
      "episode 1284, reward 621.0, memory_length 2000, epsilon 0.7735251676475688\n",
      "state terminated\n",
      "episode 1285, reward 723.0, memory_length 2000, epsilon 0.7733704800833114\n",
      "state terminated\n",
      "episode 1286, reward 400.0, memory_length 2000, epsilon 0.7732158234534733\n",
      "state terminated\n",
      "episode 1287, reward 639.0, memory_length 2000, epsilon 0.7730611977518681\n",
      "state terminated\n",
      "episode 1288, reward 368.0, memory_length 2000, epsilon 0.7729066029723111\n",
      "state terminated\n",
      "episode 1289, reward 376.0, memory_length 2000, epsilon 0.7727520391086182\n",
      "state terminated\n",
      "episode 1290, reward 679.0, memory_length 2000, epsilon 0.772597506154607\n",
      "state terminated\n",
      "episode 1291, reward 1042.0, memory_length 2000, epsilon 0.7724430041040962\n",
      "state terminated\n",
      "episode 1292, reward 714.0, memory_length 2000, epsilon 0.7722885329509055\n",
      "state terminated\n",
      "episode 1293, reward 850.0, memory_length 2000, epsilon 0.7721340926888562\n",
      "state terminated\n",
      "episode 1294, reward 1035.0, memory_length 2000, epsilon 0.7719796833117709\n",
      "state terminated\n",
      "episode 1295, reward 156.0, memory_length 2000, epsilon 0.771825304813473\n",
      "state terminated\n",
      "episode 1296, reward 348.0, memory_length 2000, epsilon 0.7716709571877874\n",
      "state terminated\n",
      "episode 1297, reward 226.0, memory_length 2000, epsilon 0.7715166404285402\n",
      "state terminated\n",
      "episode 1298, reward 423.0, memory_length 2000, epsilon 0.7713623545295586\n",
      "state terminated\n",
      "episode 1299, reward 378.0, memory_length 2000, epsilon 0.7712080994846714\n",
      "state terminated\n",
      "episode 1300, reward 780.0, memory_length 2000, epsilon 0.7710538752877082\n",
      "state terminated\n",
      "episode 1301, reward 503.0, memory_length 2000, epsilon 0.7708996819325002\n",
      "state terminated\n",
      "episode 1302, reward 473.0, memory_length 2000, epsilon 0.7707455194128795\n",
      "state terminated\n",
      "episode 1303, reward 432.0, memory_length 2000, epsilon 0.7705913877226798\n",
      "state terminated\n",
      "episode 1304, reward 927.0, memory_length 2000, epsilon 0.7704372868557355\n",
      "state terminated\n",
      "episode 1305, reward 247.0, memory_length 2000, epsilon 0.770283216805883\n",
      "state terminated\n",
      "episode 1306, reward 504.0, memory_length 2000, epsilon 0.7701291775669591\n",
      "state terminated\n",
      "episode 1307, reward 144.0, memory_length 2000, epsilon 0.7699751691328026\n",
      "state terminated\n",
      "episode 1308, reward 915.0, memory_length 2000, epsilon 0.7698211914972528\n",
      "state terminated\n",
      "episode 1309, reward 791.0, memory_length 2000, epsilon 0.7696672446541508\n",
      "state terminated\n",
      "episode 1310, reward 598.0, memory_length 2000, epsilon 0.7695133285973388\n",
      "state terminated\n",
      "episode 1311, reward 743.0, memory_length 2000, epsilon 0.7693594433206599\n",
      "state terminated\n",
      "episode 1312, reward 682.0, memory_length 2000, epsilon 0.7692055888179589\n",
      "state terminated\n",
      "episode 1313, reward 612.0, memory_length 2000, epsilon 0.7690517650830815\n",
      "state terminated\n",
      "episode 1314, reward 524.0, memory_length 2000, epsilon 0.7688979721098749\n",
      "state terminated\n",
      "episode 1315, reward 495.0, memory_length 2000, epsilon 0.7687442098921872\n",
      "state terminated\n",
      "episode 1316, reward 153.0, memory_length 2000, epsilon 0.7685904784238681\n",
      "state terminated\n",
      "episode 1317, reward 444.0, memory_length 2000, epsilon 0.7684367776987681\n",
      "state terminated\n",
      "episode 1318, reward 295.0, memory_length 2000, epsilon 0.7682831077107394\n",
      "state terminated\n",
      "episode 1319, reward 737.0, memory_length 2000, epsilon 0.7681294684536351\n",
      "state terminated\n",
      "episode 1320, reward 832.0, memory_length 2000, epsilon 0.7679758599213096\n",
      "state terminated\n",
      "episode 1321, reward 577.0, memory_length 2000, epsilon 0.7678222821076187\n",
      "state terminated\n",
      "episode 1322, reward 454.0, memory_length 2000, epsilon 0.767668735006419\n",
      "state terminated\n",
      "episode 1323, reward 621.0, memory_length 2000, epsilon 0.7675152186115689\n",
      "state terminated\n",
      "episode 1324, reward 490.0, memory_length 2000, epsilon 0.7673617329169278\n",
      "state terminated\n",
      "episode 1325, reward 625.0, memory_length 2000, epsilon 0.7672082779163559\n",
      "state terminated\n",
      "episode 1326, reward 493.0, memory_length 2000, epsilon 0.7670548536037153\n",
      "state terminated\n",
      "episode 1327, reward 577.0, memory_length 2000, epsilon 0.766901459972869\n",
      "state terminated\n",
      "episode 1328, reward 875.0, memory_length 2000, epsilon 0.7667480970176812\n",
      "state terminated\n",
      "episode 1329, reward 394.0, memory_length 2000, epsilon 0.7665947647320173\n",
      "state terminated\n",
      "episode 1330, reward 689.0, memory_length 2000, epsilon 0.7664414631097441\n",
      "state terminated\n",
      "episode 1331, reward 637.0, memory_length 2000, epsilon 0.7662881921447295\n",
      "state terminated\n",
      "episode 1332, reward 441.0, memory_length 2000, epsilon 0.7661349518308428\n",
      "state terminated\n",
      "episode 1333, reward 1000.0, memory_length 2000, epsilon 0.7659817421619542\n",
      "state terminated\n",
      "episode 1334, reward 711.0, memory_length 2000, epsilon 0.7658285631319354\n",
      "state terminated\n",
      "episode 1335, reward 395.0, memory_length 2000, epsilon 0.7656754147346593\n",
      "state terminated\n",
      "episode 1336, reward 508.0, memory_length 2000, epsilon 0.7655222969639998\n",
      "state terminated\n",
      "episode 1337, reward 815.0, memory_length 2000, epsilon 0.7653692098138323\n",
      "state terminated\n",
      "episode 1338, reward 633.0, memory_length 2000, epsilon 0.7652161532780334\n",
      "state terminated\n",
      "episode 1339, reward 576.0, memory_length 2000, epsilon 0.7650631273504805\n",
      "state terminated\n",
      "episode 1340, reward 594.0, memory_length 2000, epsilon 0.7649101320250529\n",
      "state terminated\n",
      "episode 1341, reward 917.0, memory_length 2000, epsilon 0.7647571672956308\n",
      "state terminated\n",
      "episode 1342, reward 666.0, memory_length 2000, epsilon 0.7646042331560954\n",
      "state terminated\n",
      "episode 1343, reward 529.0, memory_length 2000, epsilon 0.7644513296003294\n",
      "state terminated\n",
      "episode 1344, reward 692.0, memory_length 2000, epsilon 0.7642984566222167\n",
      "state terminated\n",
      "episode 1345, reward 506.0, memory_length 2000, epsilon 0.7641456142156424\n",
      "state terminated\n",
      "episode 1346, reward 588.0, memory_length 2000, epsilon 0.7639928023744929\n",
      "state terminated\n",
      "episode 1347, reward 655.0, memory_length 2000, epsilon 0.7638400210926554\n",
      "state terminated\n",
      "episode 1348, reward 512.0, memory_length 2000, epsilon 0.7636872703640188\n",
      "state terminated\n",
      "episode 1349, reward 262.0, memory_length 2000, epsilon 0.7635345501824733\n",
      "state terminated\n",
      "episode 1350, reward 701.0, memory_length 2000, epsilon 0.7633818605419098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1351, reward 588.0, memory_length 2000, epsilon 0.7632292014362209\n",
      "state terminated\n",
      "episode 1352, reward 754.0, memory_length 2000, epsilon 0.7630765728593\n",
      "state terminated\n",
      "episode 1353, reward 395.0, memory_length 2000, epsilon 0.7629239748050424\n",
      "state terminated\n",
      "episode 1354, reward 620.0, memory_length 2000, epsilon 0.7627714072673436\n",
      "state terminated\n",
      "episode 1355, reward 854.0, memory_length 2000, epsilon 0.7626188702401013\n",
      "state terminated\n",
      "episode 1356, reward 760.0, memory_length 2000, epsilon 0.7624663637172139\n",
      "state terminated\n",
      "episode 1357, reward 540.0, memory_length 2000, epsilon 0.7623138876925812\n",
      "state terminated\n",
      "episode 1358, reward 832.0, memory_length 2000, epsilon 0.7621614421601041\n",
      "state terminated\n",
      "episode 1359, reward 831.0, memory_length 2000, epsilon 0.7620090271136848\n",
      "state terminated\n",
      "episode 1360, reward 535.0, memory_length 2000, epsilon 0.7618566425472266\n",
      "state terminated\n",
      "episode 1361, reward 265.0, memory_length 2000, epsilon 0.7617042884546342\n",
      "state terminated\n",
      "episode 1362, reward 1053.0, memory_length 2000, epsilon 0.7615519648298136\n",
      "state terminated\n",
      "episode 1363, reward 555.0, memory_length 2000, epsilon 0.7613996716666717\n",
      "state terminated\n",
      "episode 1364, reward 777.0, memory_length 2000, epsilon 0.7612474089591166\n",
      "state terminated\n",
      "episode 1365, reward 572.0, memory_length 2000, epsilon 0.761095176701058\n",
      "state terminated\n",
      "episode 1366, reward 189.0, memory_length 2000, epsilon 0.7609429748864066\n",
      "state terminated\n",
      "episode 1367, reward 877.0, memory_length 2000, epsilon 0.7607908035090742\n",
      "state terminated\n",
      "episode 1368, reward 785.0, memory_length 2000, epsilon 0.7606386625629742\n",
      "state terminated\n",
      "episode 1369, reward 286.0, memory_length 2000, epsilon 0.7604865520420208\n",
      "state terminated\n",
      "episode 1370, reward 905.0, memory_length 2000, epsilon 0.7603344719401295\n",
      "state terminated\n",
      "episode 1371, reward 790.0, memory_length 2000, epsilon 0.7601824222512171\n",
      "state terminated\n",
      "episode 1372, reward 831.0, memory_length 2000, epsilon 0.7600304029692019\n",
      "state terminated\n",
      "episode 1373, reward 507.0, memory_length 2000, epsilon 0.7598784140880027\n",
      "state terminated\n",
      "episode 1374, reward 388.0, memory_length 2000, epsilon 0.7597264556015404\n",
      "state terminated\n",
      "episode 1375, reward 803.0, memory_length 2000, epsilon 0.7595745275037362\n",
      "state terminated\n",
      "episode 1376, reward 693.0, memory_length 2000, epsilon 0.7594226297885134\n",
      "state terminated\n",
      "episode 1377, reward 574.0, memory_length 2000, epsilon 0.7592707624497956\n",
      "state terminated\n",
      "episode 1378, reward 658.0, memory_length 2000, epsilon 0.7591189254815086\n",
      "state terminated\n",
      "episode 1379, reward 984.0, memory_length 2000, epsilon 0.7589671188775788\n",
      "state terminated\n",
      "episode 1380, reward 766.0, memory_length 2000, epsilon 0.7588153426319337\n",
      "state terminated\n",
      "episode 1381, reward 59.0, memory_length 2000, epsilon 0.7586635967385026\n",
      "state terminated\n",
      "episode 1382, reward 934.0, memory_length 2000, epsilon 0.7585118811912153\n",
      "state terminated\n",
      "episode 1383, reward 819.0, memory_length 2000, epsilon 0.7583601959840034\n",
      "state terminated\n",
      "episode 1384, reward 562.0, memory_length 2000, epsilon 0.7582085411107995\n",
      "state terminated\n",
      "episode 1385, reward 574.0, memory_length 2000, epsilon 0.7580569165655372\n",
      "state terminated\n",
      "episode 1386, reward 882.0, memory_length 2000, epsilon 0.7579053223421517\n",
      "state terminated\n",
      "episode 1387, reward 576.0, memory_length 2000, epsilon 0.7577537584345793\n",
      "state terminated\n",
      "episode 1388, reward 247.0, memory_length 2000, epsilon 0.7576022248367573\n",
      "state terminated\n",
      "episode 1389, reward 884.0, memory_length 2000, epsilon 0.7574507215426244\n",
      "state terminated\n",
      "episode 1390, reward 682.0, memory_length 2000, epsilon 0.7572992485461204\n",
      "state terminated\n",
      "episode 1391, reward 526.0, memory_length 2000, epsilon 0.7571478058411865\n",
      "state terminated\n",
      "episode 1392, reward 684.0, memory_length 2000, epsilon 0.7569963934217648\n",
      "state terminated\n",
      "episode 1393, reward 387.0, memory_length 2000, epsilon 0.756845011281799\n",
      "state terminated\n",
      "episode 1394, reward 603.0, memory_length 2000, epsilon 0.7566936594152339\n",
      "state terminated\n",
      "episode 1395, reward 724.0, memory_length 2000, epsilon 0.7565423378160152\n",
      "state terminated\n",
      "episode 1396, reward 851.0, memory_length 2000, epsilon 0.7563910464780902\n",
      "state terminated\n",
      "episode 1397, reward 524.0, memory_length 2000, epsilon 0.7562397853954069\n",
      "state terminated\n",
      "episode 1398, reward 333.0, memory_length 2000, epsilon 0.7560885545619154\n",
      "state terminated\n",
      "episode 1399, reward 584.0, memory_length 2000, epsilon 0.7559373539715659\n",
      "state terminated\n",
      "episode 1400, reward 553.0, memory_length 2000, epsilon 0.7557861836183108\n",
      "state terminated\n",
      "episode 1401, reward 867.0, memory_length 2000, epsilon 0.7556350434961033\n",
      "state terminated\n",
      "episode 1402, reward 368.0, memory_length 2000, epsilon 0.7554839335988974\n",
      "state terminated\n",
      "episode 1403, reward 760.0, memory_length 2000, epsilon 0.7553328539206491\n",
      "state terminated\n",
      "episode 1404, reward 868.0, memory_length 2000, epsilon 0.755181804455315\n",
      "state terminated\n",
      "episode 1405, reward 676.0, memory_length 2000, epsilon 0.7550307851968532\n",
      "state terminated\n",
      "episode 1406, reward 978.0, memory_length 2000, epsilon 0.7548797961392228\n",
      "state terminated\n",
      "episode 1407, reward 432.0, memory_length 2000, epsilon 0.7547288372763845\n",
      "state terminated\n",
      "episode 1408, reward 986.0, memory_length 2000, epsilon 0.7545779086022997\n",
      "state terminated\n",
      "episode 1409, reward 809.0, memory_length 2000, epsilon 0.7544270101109315\n",
      "state terminated\n",
      "episode 1410, reward 354.0, memory_length 2000, epsilon 0.7542761417962436\n",
      "state terminated\n",
      "episode 1411, reward 553.0, memory_length 2000, epsilon 0.7541253036522015\n",
      "state terminated\n",
      "episode 1412, reward 427.0, memory_length 2000, epsilon 0.7539744956727716\n",
      "state terminated\n",
      "episode 1413, reward 489.0, memory_length 2000, epsilon 0.7538237178519218\n",
      "state terminated\n",
      "episode 1414, reward 877.0, memory_length 2000, epsilon 0.7536729701836209\n",
      "state terminated\n",
      "episode 1415, reward 668.0, memory_length 2000, epsilon 0.7535222526618386\n",
      "state terminated\n",
      "episode 1416, reward 629.0, memory_length 2000, epsilon 0.7533715652805466\n",
      "state terminated\n",
      "episode 1417, reward 863.0, memory_length 2000, epsilon 0.7532209080337173\n",
      "state terminated\n",
      "episode 1418, reward 481.0, memory_length 2000, epsilon 0.7530702809153247\n",
      "state terminated\n",
      "episode 1419, reward 639.0, memory_length 2000, epsilon 0.7529196839193432\n",
      "state terminated\n",
      "episode 1420, reward 418.0, memory_length 2000, epsilon 0.7527691170397491\n",
      "state terminated\n",
      "episode 1421, reward 593.0, memory_length 2000, epsilon 0.75261858027052\n",
      "state terminated\n",
      "episode 1422, reward 615.0, memory_length 2000, epsilon 0.7524680736056341\n",
      "state terminated\n",
      "episode 1423, reward 1204.0, memory_length 2000, epsilon 0.7523175970390711\n",
      "state terminated\n",
      "episode 1424, reward 1130.0, memory_length 2000, epsilon 0.7521671505648122\n",
      "state terminated\n",
      "episode 1425, reward 821.0, memory_length 2000, epsilon 0.7520167341768395\n",
      "state terminated\n",
      "episode 1426, reward 720.0, memory_length 2000, epsilon 0.7518663478691362\n",
      "state terminated\n",
      "episode 1427, reward 985.0, memory_length 2000, epsilon 0.7517159916356869\n",
      "state terminated\n",
      "episode 1428, reward 535.0, memory_length 2000, epsilon 0.7515656654704772\n",
      "state terminated\n",
      "episode 1429, reward 864.0, memory_length 2000, epsilon 0.7514153693674945\n",
      "state terminated\n",
      "episode 1430, reward 569.0, memory_length 2000, epsilon 0.7512651033207266\n",
      "state terminated\n",
      "episode 1431, reward 792.0, memory_length 2000, epsilon 0.7511148673241628\n",
      "state terminated\n",
      "episode 1432, reward 610.0, memory_length 2000, epsilon 0.750964661371794\n",
      "state terminated\n",
      "episode 1433, reward 730.0, memory_length 2000, epsilon 0.7508144854576115\n",
      "state terminated\n",
      "episode 1434, reward 332.0, memory_length 2000, epsilon 0.7506643395756087\n",
      "state terminated\n",
      "episode 1435, reward 718.0, memory_length 2000, epsilon 0.7505142237197796\n",
      "state terminated\n",
      "episode 1436, reward 801.0, memory_length 2000, epsilon 0.7503641378841195\n",
      "state terminated\n",
      "episode 1437, reward 486.0, memory_length 2000, epsilon 0.750214082062625\n",
      "state terminated\n",
      "episode 1438, reward 1008.0, memory_length 2000, epsilon 0.7500640562492938\n",
      "state terminated\n",
      "episode 1439, reward 697.0, memory_length 2000, epsilon 0.7499140604381251\n",
      "state terminated\n",
      "episode 1440, reward 646.0, memory_length 2000, epsilon 0.7497640946231189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1441, reward 410.0, memory_length 2000, epsilon 0.7496141587982765\n",
      "state terminated\n",
      "episode 1442, reward 459.0, memory_length 2000, epsilon 0.7494642529576007\n",
      "state terminated\n",
      "episode 1443, reward 540.0, memory_length 2000, epsilon 0.749314377095095\n",
      "state terminated\n",
      "episode 1444, reward 657.0, memory_length 2000, epsilon 0.7491645312047645\n",
      "state terminated\n",
      "episode 1445, reward 574.0, memory_length 2000, epsilon 0.7490147152806153\n",
      "state terminated\n",
      "episode 1446, reward 569.0, memory_length 2000, epsilon 0.7488649293166549\n",
      "state terminated\n",
      "episode 1447, reward 421.0, memory_length 2000, epsilon 0.7487151733068917\n",
      "state terminated\n",
      "episode 1448, reward 495.0, memory_length 2000, epsilon 0.7485654472453356\n",
      "state terminated\n",
      "episode 1449, reward 602.0, memory_length 2000, epsilon 0.7484157511259975\n",
      "state terminated\n",
      "episode 1450, reward 867.0, memory_length 2000, epsilon 0.7482660849428894\n",
      "state terminated\n",
      "episode 1451, reward 577.0, memory_length 2000, epsilon 0.7481164486900249\n",
      "state terminated\n",
      "episode 1452, reward 939.0, memory_length 2000, epsilon 0.7479668423614184\n",
      "state terminated\n",
      "episode 1453, reward 885.0, memory_length 2000, epsilon 0.7478172659510858\n",
      "state terminated\n",
      "episode 1454, reward 410.0, memory_length 2000, epsilon 0.7476677194530439\n",
      "state terminated\n",
      "episode 1455, reward 567.0, memory_length 2000, epsilon 0.7475182028613108\n",
      "state terminated\n",
      "episode 1456, reward 772.0, memory_length 2000, epsilon 0.7473687161699061\n",
      "state terminated\n",
      "episode 1457, reward 693.0, memory_length 2000, epsilon 0.7472192593728499\n",
      "state terminated\n",
      "episode 1458, reward 656.0, memory_length 2000, epsilon 0.7470698324641643\n",
      "state terminated\n",
      "episode 1459, reward 541.0, memory_length 2000, epsilon 0.746920435437872\n",
      "state terminated\n",
      "episode 1460, reward 870.0, memory_length 2000, epsilon 0.7467710682879973\n",
      "state terminated\n",
      "episode 1461, reward 732.0, memory_length 2000, epsilon 0.7466217310085654\n",
      "state terminated\n",
      "episode 1462, reward 752.0, memory_length 2000, epsilon 0.746472423593603\n",
      "state terminated\n",
      "episode 1463, reward 678.0, memory_length 2000, epsilon 0.7463231460371376\n",
      "state terminated\n",
      "episode 1464, reward 621.0, memory_length 2000, epsilon 0.7461738983331979\n",
      "state terminated\n",
      "episode 1465, reward 547.0, memory_length 2000, epsilon 0.7460246804758144\n",
      "state terminated\n",
      "episode 1466, reward 395.0, memory_length 2000, epsilon 0.7458754924590183\n",
      "state terminated\n",
      "episode 1467, reward 673.0, memory_length 2000, epsilon 0.745726334276842\n",
      "state terminated\n",
      "episode 1468, reward 741.0, memory_length 2000, epsilon 0.745577205923319\n",
      "state terminated\n",
      "episode 1469, reward 615.0, memory_length 2000, epsilon 0.7454281073924843\n",
      "state terminated\n",
      "episode 1470, reward 595.0, memory_length 2000, epsilon 0.7452790386783741\n",
      "state terminated\n",
      "episode 1471, reward 629.0, memory_length 2000, epsilon 0.7451299997750257\n",
      "state terminated\n",
      "episode 1472, reward 868.0, memory_length 2000, epsilon 0.7449809906764772\n",
      "state terminated\n",
      "episode 1473, reward 507.0, memory_length 2000, epsilon 0.7448320113767685\n",
      "state terminated\n",
      "episode 1474, reward 495.0, memory_length 2000, epsilon 0.7446830618699403\n",
      "state terminated\n",
      "episode 1475, reward 785.0, memory_length 2000, epsilon 0.7445341421500347\n",
      "state terminated\n",
      "episode 1476, reward 930.0, memory_length 2000, epsilon 0.7443852522110949\n",
      "state terminated\n",
      "episode 1477, reward 382.0, memory_length 2000, epsilon 0.7442363920471653\n",
      "state terminated\n",
      "episode 1478, reward 504.0, memory_length 2000, epsilon 0.7440875616522914\n",
      "state terminated\n",
      "episode 1479, reward 603.0, memory_length 2000, epsilon 0.7439387610205201\n",
      "state terminated\n",
      "episode 1480, reward 584.0, memory_length 2000, epsilon 0.7437899901458994\n",
      "state terminated\n",
      "episode 1481, reward 857.0, memory_length 2000, epsilon 0.7436412490224783\n",
      "state terminated\n",
      "episode 1482, reward 945.0, memory_length 2000, epsilon 0.7434925376443073\n",
      "state terminated\n",
      "episode 1483, reward 459.0, memory_length 2000, epsilon 0.7433438560054381\n",
      "state terminated\n",
      "episode 1484, reward 758.0, memory_length 2000, epsilon 0.743195204099923\n",
      "state terminated\n",
      "episode 1485, reward 722.0, memory_length 2000, epsilon 0.7430465819218162\n",
      "state terminated\n",
      "episode 1486, reward 731.0, memory_length 2000, epsilon 0.7428979894651728\n",
      "state terminated\n",
      "episode 1487, reward 591.0, memory_length 2000, epsilon 0.7427494267240491\n",
      "state terminated\n",
      "episode 1488, reward 650.0, memory_length 2000, epsilon 0.7426008936925026\n",
      "state terminated\n",
      "episode 1489, reward 792.0, memory_length 2000, epsilon 0.7424523903645919\n",
      "state terminated\n",
      "episode 1490, reward 720.0, memory_length 2000, epsilon 0.7423039167343769\n",
      "state terminated\n",
      "episode 1491, reward 693.0, memory_length 2000, epsilon 0.7421554727959186\n",
      "state terminated\n",
      "episode 1492, reward 808.0, memory_length 2000, epsilon 0.7420070585432795\n",
      "state terminated\n",
      "episode 1493, reward 562.0, memory_length 2000, epsilon 0.7418586739705227\n",
      "state terminated\n",
      "episode 1494, reward 449.0, memory_length 2000, epsilon 0.741710319071713\n",
      "state terminated\n",
      "episode 1495, reward 929.0, memory_length 2000, epsilon 0.7415619938409161\n",
      "state terminated\n",
      "episode 1496, reward 572.0, memory_length 2000, epsilon 0.7414136982721992\n",
      "state terminated\n",
      "episode 1497, reward 280.0, memory_length 2000, epsilon 0.7412654323596302\n",
      "state terminated\n",
      "episode 1498, reward 768.0, memory_length 2000, epsilon 0.7411171960972786\n",
      "state terminated\n",
      "episode 1499, reward 495.0, memory_length 2000, epsilon 0.740968989479215\n",
      "state terminated\n",
      "episode 1500, reward 553.0, memory_length 2000, epsilon 0.740820812499511\n",
      "state terminated\n",
      "episode 1501, reward 723.0, memory_length 2000, epsilon 0.7406726651522396\n",
      "state terminated\n",
      "episode 1502, reward 593.0, memory_length 2000, epsilon 0.740524547431475\n",
      "state terminated\n",
      "episode 1503, reward 559.0, memory_length 2000, epsilon 0.7403764593312924\n",
      "state terminated\n",
      "episode 1504, reward 851.0, memory_length 2000, epsilon 0.7402284008457682\n",
      "state terminated\n",
      "episode 1505, reward 728.0, memory_length 2000, epsilon 0.7400803719689801\n",
      "state terminated\n",
      "episode 1506, reward 846.0, memory_length 2000, epsilon 0.7399323726950071\n",
      "state terminated\n",
      "episode 1507, reward 673.0, memory_length 2000, epsilon 0.739784403017929\n",
      "state terminated\n",
      "episode 1508, reward 676.0, memory_length 2000, epsilon 0.7396364629318272\n",
      "state terminated\n",
      "episode 1509, reward 766.0, memory_length 2000, epsilon 0.7394885524307839\n",
      "state terminated\n",
      "episode 1510, reward 774.0, memory_length 2000, epsilon 0.739340671508883\n",
      "state terminated\n",
      "episode 1511, reward 711.0, memory_length 2000, epsilon 0.7391928201602088\n",
      "state terminated\n",
      "episode 1512, reward 899.0, memory_length 2000, epsilon 0.7390449983788477\n",
      "state terminated\n",
      "episode 1513, reward 837.0, memory_length 2000, epsilon 0.7388972061588865\n",
      "state terminated\n",
      "episode 1514, reward 630.0, memory_length 2000, epsilon 0.7387494434944137\n",
      "state terminated\n",
      "episode 1515, reward 783.0, memory_length 2000, epsilon 0.7386017103795188\n",
      "state terminated\n",
      "episode 1516, reward 747.0, memory_length 2000, epsilon 0.7384540068082924\n",
      "state terminated\n",
      "episode 1517, reward 561.0, memory_length 2000, epsilon 0.7383063327748264\n",
      "state terminated\n",
      "episode 1518, reward 703.0, memory_length 2000, epsilon 0.7381586882732136\n",
      "state terminated\n",
      "episode 1519, reward 566.0, memory_length 2000, epsilon 0.7380110732975486\n",
      "state terminated\n",
      "episode 1520, reward 949.0, memory_length 2000, epsilon 0.7378634878419266\n",
      "state terminated\n",
      "episode 1521, reward 618.0, memory_length 2000, epsilon 0.7377159319004443\n",
      "state terminated\n",
      "episode 1522, reward 823.0, memory_length 2000, epsilon 0.7375684054671993\n",
      "state terminated\n",
      "episode 1523, reward 858.0, memory_length 2000, epsilon 0.7374209085362905\n",
      "state terminated\n",
      "episode 1524, reward 1026.0, memory_length 2000, epsilon 0.7372734411018182\n",
      "state terminated\n",
      "episode 1525, reward 360.0, memory_length 2000, epsilon 0.7371260031578839\n",
      "state terminated\n",
      "episode 1526, reward 702.0, memory_length 2000, epsilon 0.7369785946985895\n",
      "state terminated\n",
      "episode 1527, reward 754.0, memory_length 2000, epsilon 0.7368312157180391\n",
      "state terminated\n",
      "episode 1528, reward 378.0, memory_length 2000, epsilon 0.7366838662103374\n",
      "state terminated\n",
      "episode 1529, reward 936.0, memory_length 2000, epsilon 0.7365365461695905\n",
      "state terminated\n",
      "episode 1530, reward 647.0, memory_length 2000, epsilon 0.7363892555899055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1531, reward 644.0, memory_length 2000, epsilon 0.7362419944653908\n",
      "state terminated\n",
      "episode 1532, reward 786.0, memory_length 2000, epsilon 0.7360947627901561\n",
      "state terminated\n",
      "episode 1533, reward 703.0, memory_length 2000, epsilon 0.7359475605583119\n",
      "state terminated\n",
      "episode 1534, reward 272.0, memory_length 2000, epsilon 0.7358003877639702\n",
      "state terminated\n",
      "episode 1535, reward 659.0, memory_length 2000, epsilon 0.7356532444012442\n",
      "state terminated\n",
      "episode 1536, reward 848.0, memory_length 2000, epsilon 0.7355061304642481\n",
      "state terminated\n",
      "episode 1537, reward 731.0, memory_length 2000, epsilon 0.7353590459470972\n",
      "state terminated\n",
      "episode 1538, reward 540.0, memory_length 2000, epsilon 0.7352119908439082\n",
      "state terminated\n",
      "episode 1539, reward 524.0, memory_length 2000, epsilon 0.735064965148799\n",
      "state terminated\n",
      "episode 1540, reward 495.0, memory_length 2000, epsilon 0.7349179688558887\n",
      "state terminated\n",
      "episode 1541, reward 100.0, memory_length 2000, epsilon 0.7347710019592969\n",
      "state terminated\n",
      "episode 1542, reward 441.0, memory_length 2000, epsilon 0.7346240644531455\n",
      "state terminated\n",
      "episode 1543, reward 841.0, memory_length 2000, epsilon 0.7344771563315567\n",
      "state terminated\n",
      "episode 1544, reward 900.0, memory_length 2000, epsilon 0.7343302775886543\n",
      "state terminated\n",
      "episode 1545, reward 603.0, memory_length 2000, epsilon 0.7341834282185631\n",
      "state terminated\n",
      "episode 1546, reward 983.0, memory_length 2000, epsilon 0.7340366082154092\n",
      "state terminated\n",
      "episode 1547, reward 672.0, memory_length 2000, epsilon 0.7338898175733195\n",
      "state terminated\n",
      "episode 1548, reward 1230.0, memory_length 2000, epsilon 0.7337430562864228\n",
      "state terminated\n",
      "episode 1549, reward 564.0, memory_length 2000, epsilon 0.7335963243488484\n",
      "state terminated\n",
      "episode 1550, reward 967.0, memory_length 2000, epsilon 0.7334496217547269\n",
      "state terminated\n",
      "episode 1551, reward 730.0, memory_length 2000, epsilon 0.7333029484981907\n",
      "state terminated\n",
      "episode 1552, reward 1084.0, memory_length 2000, epsilon 0.7331563045733723\n",
      "state terminated\n",
      "episode 1553, reward 783.0, memory_length 2000, epsilon 0.7330096899744063\n",
      "state terminated\n",
      "episode 1554, reward 684.0, memory_length 2000, epsilon 0.7328631046954278\n",
      "state terminated\n",
      "episode 1555, reward 175.0, memory_length 2000, epsilon 0.7327165487305738\n",
      "state terminated\n",
      "episode 1556, reward 499.0, memory_length 2000, epsilon 0.7325700220739818\n",
      "state terminated\n",
      "episode 1557, reward 954.0, memory_length 2000, epsilon 0.7324235247197907\n",
      "state terminated\n",
      "episode 1558, reward 850.0, memory_length 2000, epsilon 0.7322770566621407\n",
      "state terminated\n",
      "episode 1559, reward 494.0, memory_length 2000, epsilon 0.7321306178951731\n",
      "state terminated\n",
      "episode 1560, reward 517.0, memory_length 2000, epsilon 0.7319842084130304\n",
      "state terminated\n",
      "episode 1561, reward 787.0, memory_length 2000, epsilon 0.7318378282098559\n",
      "state terminated\n",
      "episode 1562, reward 558.0, memory_length 2000, epsilon 0.7316914772797949\n",
      "state terminated\n",
      "episode 1563, reward 641.0, memory_length 2000, epsilon 0.731545155616993\n",
      "state terminated\n",
      "episode 1564, reward 715.0, memory_length 2000, epsilon 0.7313988632155972\n",
      "state terminated\n",
      "episode 1565, reward 741.0, memory_length 2000, epsilon 0.7312526000697563\n",
      "state terminated\n",
      "episode 1566, reward 441.0, memory_length 2000, epsilon 0.7311063661736193\n",
      "state terminated\n",
      "episode 1567, reward 518.0, memory_length 2000, epsilon 0.7309601615213372\n",
      "state terminated\n",
      "episode 1568, reward 931.0, memory_length 2000, epsilon 0.7308139861070617\n",
      "state terminated\n",
      "episode 1569, reward 475.0, memory_length 2000, epsilon 0.7306678399249456\n",
      "state terminated\n",
      "episode 1570, reward 579.0, memory_length 2000, epsilon 0.7305217229691433\n",
      "state terminated\n",
      "episode 1571, reward 705.0, memory_length 2000, epsilon 0.7303756352338099\n",
      "state terminated\n",
      "episode 1572, reward 584.0, memory_length 2000, epsilon 0.7302295767131022\n",
      "state terminated\n",
      "episode 1573, reward 902.0, memory_length 2000, epsilon 0.7300835474011774\n",
      "state terminated\n",
      "episode 1574, reward 601.0, memory_length 2000, epsilon 0.7299375472921948\n",
      "state terminated\n",
      "episode 1575, reward 764.0, memory_length 2000, epsilon 0.7297915763803141\n",
      "state terminated\n",
      "episode 1576, reward 215.0, memory_length 2000, epsilon 0.7296456346596966\n",
      "state terminated\n",
      "episode 1577, reward 914.0, memory_length 2000, epsilon 0.7294997221245045\n",
      "state terminated\n",
      "episode 1578, reward 832.0, memory_length 2000, epsilon 0.7293538387689015\n",
      "state terminated\n",
      "episode 1579, reward 893.0, memory_length 2000, epsilon 0.729207984587052\n",
      "state terminated\n",
      "episode 1580, reward 674.0, memory_length 2000, epsilon 0.729062159573122\n",
      "state terminated\n",
      "episode 1581, reward 619.0, memory_length 2000, epsilon 0.7289163637212785\n",
      "state terminated\n",
      "episode 1582, reward 443.0, memory_length 2000, epsilon 0.7287705970256898\n",
      "state terminated\n",
      "episode 1583, reward 623.0, memory_length 2000, epsilon 0.728624859480525\n",
      "state terminated\n",
      "episode 1584, reward 1023.0, memory_length 2000, epsilon 0.7284791510799546\n",
      "state terminated\n",
      "episode 1585, reward 711.0, memory_length 2000, epsilon 0.7283334718181504\n",
      "state terminated\n",
      "episode 1586, reward 996.0, memory_length 2000, epsilon 0.7281878216892852\n",
      "state terminated\n",
      "episode 1587, reward 414.0, memory_length 2000, epsilon 0.7280422006875329\n",
      "state terminated\n",
      "episode 1588, reward 745.0, memory_length 2000, epsilon 0.7278966088070687\n",
      "state terminated\n",
      "episode 1589, reward 693.0, memory_length 2000, epsilon 0.727751046042069\n",
      "state terminated\n",
      "episode 1590, reward 671.0, memory_length 2000, epsilon 0.7276055123867113\n",
      "state terminated\n",
      "episode 1591, reward 724.0, memory_length 2000, epsilon 0.7274600078351742\n",
      "state terminated\n",
      "episode 1592, reward 490.0, memory_length 2000, epsilon 0.7273145323816373\n",
      "state terminated\n",
      "episode 1593, reward 947.0, memory_length 2000, epsilon 0.727169086020282\n",
      "state terminated\n",
      "episode 1594, reward 926.0, memory_length 2000, epsilon 0.7270236687452901\n",
      "state terminated\n",
      "episode 1595, reward 748.0, memory_length 2000, epsilon 0.7268782805508451\n",
      "state terminated\n",
      "episode 1596, reward 1159.0, memory_length 2000, epsilon 0.7267329214311316\n",
      "state terminated\n",
      "episode 1597, reward 695.0, memory_length 2000, epsilon 0.7265875913803348\n",
      "state terminated\n",
      "episode 1598, reward 876.0, memory_length 2000, epsilon 0.7264422903926419\n",
      "state terminated\n",
      "episode 1599, reward 844.0, memory_length 2000, epsilon 0.7262970184622405\n",
      "state terminated\n",
      "episode 1600, reward 611.0, memory_length 2000, epsilon 0.7261517755833202\n",
      "state terminated\n",
      "episode 1601, reward 693.0, memory_length 2000, epsilon 0.7260065617500708\n",
      "state terminated\n",
      "episode 1602, reward 687.0, memory_length 2000, epsilon 0.7258613769566841\n",
      "state terminated\n",
      "episode 1603, reward 810.0, memory_length 2000, epsilon 0.7257162211973526\n",
      "state terminated\n",
      "episode 1604, reward 1004.0, memory_length 2000, epsilon 0.72557109446627\n",
      "state terminated\n",
      "episode 1605, reward 580.0, memory_length 2000, epsilon 0.7254259967576312\n",
      "state terminated\n",
      "episode 1606, reward 485.0, memory_length 2000, epsilon 0.7252809280656325\n",
      "state terminated\n",
      "episode 1607, reward 1065.0, memory_length 2000, epsilon 0.725135888384471\n",
      "state terminated\n",
      "episode 1608, reward 822.0, memory_length 2000, epsilon 0.724990877708345\n",
      "state terminated\n",
      "episode 1609, reward 944.0, memory_length 2000, epsilon 0.7248458960314543\n",
      "state terminated\n",
      "episode 1610, reward 652.0, memory_length 2000, epsilon 0.7247009433479996\n",
      "state terminated\n",
      "episode 1611, reward 997.0, memory_length 2000, epsilon 0.7245560196521825\n",
      "state terminated\n",
      "episode 1612, reward 1003.0, memory_length 2000, epsilon 0.7244111249382065\n",
      "state terminated\n",
      "episode 1613, reward 981.0, memory_length 2000, epsilon 0.7242662592002757\n",
      "state terminated\n",
      "episode 1614, reward 546.0, memory_length 2000, epsilon 0.724121422432595\n",
      "state terminated\n",
      "episode 1615, reward 703.0, memory_length 2000, epsilon 0.7239766146293716\n",
      "state terminated\n",
      "episode 1616, reward 666.0, memory_length 2000, epsilon 0.7238318357848128\n",
      "state terminated\n",
      "episode 1617, reward 872.0, memory_length 2000, epsilon 0.7236870858931275\n",
      "state terminated\n",
      "episode 1618, reward 933.0, memory_length 2000, epsilon 0.7235423649485258\n",
      "state terminated\n",
      "episode 1619, reward 565.0, memory_length 2000, epsilon 0.7233976729452187\n",
      "state terminated\n",
      "episode 1620, reward 672.0, memory_length 2000, epsilon 0.7232530098774186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1621, reward 891.0, memory_length 2000, epsilon 0.7231083757393391\n",
      "state terminated\n",
      "episode 1622, reward 855.0, memory_length 2000, epsilon 0.7229637705251946\n",
      "state terminated\n",
      "episode 1623, reward 1020.0, memory_length 2000, epsilon 0.722819194229201\n",
      "state terminated\n",
      "episode 1624, reward 1205.0, memory_length 2000, epsilon 0.7226746468455754\n",
      "state terminated\n",
      "episode 1625, reward 515.0, memory_length 2000, epsilon 0.7225301283685358\n",
      "state terminated\n",
      "episode 1626, reward 720.0, memory_length 2000, epsilon 0.7223856387923013\n",
      "state terminated\n",
      "episode 1627, reward 661.0, memory_length 2000, epsilon 0.7222411781110925\n",
      "state terminated\n",
      "episode 1628, reward 882.0, memory_length 2000, epsilon 0.7220967463191309\n",
      "state terminated\n",
      "episode 1629, reward 724.0, memory_length 2000, epsilon 0.7219523434106393\n",
      "state terminated\n",
      "episode 1630, reward 405.0, memory_length 2000, epsilon 0.7218079693798415\n",
      "state terminated\n",
      "episode 1631, reward 522.0, memory_length 2000, epsilon 0.7216636242209625\n",
      "state terminated\n",
      "episode 1632, reward 890.0, memory_length 2000, epsilon 0.7215193079282286\n",
      "state terminated\n",
      "episode 1633, reward 647.0, memory_length 2000, epsilon 0.7213750204958672\n",
      "state terminated\n",
      "episode 1634, reward 1012.0, memory_length 2000, epsilon 0.7212307619181066\n",
      "state terminated\n",
      "episode 1635, reward 752.0, memory_length 2000, epsilon 0.7210865321891767\n",
      "state terminated\n",
      "episode 1636, reward 764.0, memory_length 2000, epsilon 0.7209423313033081\n",
      "state terminated\n",
      "episode 1637, reward 966.0, memory_length 2000, epsilon 0.7207981592547329\n",
      "state terminated\n",
      "episode 1638, reward 722.0, memory_length 2000, epsilon 0.7206540160376841\n",
      "state terminated\n",
      "episode 1639, reward 970.0, memory_length 2000, epsilon 0.7205099016463962\n",
      "state terminated\n",
      "episode 1640, reward 1068.0, memory_length 2000, epsilon 0.7203658160751043\n",
      "state terminated\n",
      "episode 1641, reward 844.0, memory_length 2000, epsilon 0.7202217593180452\n",
      "state terminated\n",
      "episode 1642, reward 837.0, memory_length 2000, epsilon 0.7200777313694565\n",
      "state terminated\n",
      "episode 1643, reward 1062.0, memory_length 2000, epsilon 0.7199337322235773\n",
      "state terminated\n",
      "episode 1644, reward 791.0, memory_length 2000, epsilon 0.7197897618746472\n",
      "state terminated\n",
      "episode 1645, reward 655.0, memory_length 2000, epsilon 0.7196458203169079\n",
      "state terminated\n",
      "episode 1646, reward 713.0, memory_length 2000, epsilon 0.7195019075446015\n",
      "state terminated\n",
      "episode 1647, reward 1017.0, memory_length 2000, epsilon 0.7193580235519713\n",
      "state terminated\n",
      "episode 1648, reward 978.0, memory_length 2000, epsilon 0.7192141683332623\n",
      "state terminated\n",
      "episode 1649, reward 531.0, memory_length 2000, epsilon 0.7190703418827202\n",
      "state terminated\n",
      "episode 1650, reward 890.0, memory_length 2000, epsilon 0.7189265441945918\n",
      "state terminated\n",
      "episode 1651, reward 828.0, memory_length 2000, epsilon 0.7187827752631253\n",
      "state terminated\n",
      "episode 1652, reward 823.0, memory_length 2000, epsilon 0.7186390350825699\n",
      "state terminated\n",
      "episode 1653, reward 655.0, memory_length 2000, epsilon 0.7184953236471759\n",
      "state terminated\n",
      "episode 1654, reward 500.0, memory_length 2000, epsilon 0.718351640951195\n",
      "state terminated\n",
      "episode 1655, reward 774.0, memory_length 2000, epsilon 0.7182079869888799\n",
      "state terminated\n",
      "episode 1656, reward 423.0, memory_length 2000, epsilon 0.7180643617544843\n",
      "state terminated\n",
      "episode 1657, reward 677.0, memory_length 2000, epsilon 0.7179207652422632\n",
      "state terminated\n",
      "episode 1658, reward 944.0, memory_length 2000, epsilon 0.717777197446473\n",
      "state terminated\n",
      "episode 1659, reward 853.0, memory_length 2000, epsilon 0.7176336583613706\n",
      "state terminated\n",
      "episode 1660, reward 643.0, memory_length 2000, epsilon 0.7174901479812147\n",
      "state terminated\n",
      "episode 1661, reward 904.0, memory_length 2000, epsilon 0.7173466663002648\n",
      "state terminated\n",
      "episode 1662, reward 993.0, memory_length 2000, epsilon 0.7172032133127817\n",
      "state terminated\n",
      "episode 1663, reward 886.0, memory_length 2000, epsilon 0.7170597890130272\n",
      "state terminated\n",
      "episode 1664, reward 705.0, memory_length 2000, epsilon 0.7169163933952644\n",
      "state terminated\n",
      "episode 1665, reward 1174.0, memory_length 2000, epsilon 0.7167730264537574\n",
      "state terminated\n",
      "episode 1666, reward 572.0, memory_length 2000, epsilon 0.7166296881827715\n",
      "state terminated\n",
      "episode 1667, reward 742.0, memory_length 2000, epsilon 0.7164863785765733\n",
      "state terminated\n",
      "episode 1668, reward 1071.0, memory_length 2000, epsilon 0.7163430976294303\n",
      "state terminated\n",
      "episode 1669, reward 889.0, memory_length 2000, epsilon 0.7161998453356113\n",
      "state terminated\n",
      "episode 1670, reward 1178.0, memory_length 2000, epsilon 0.7160566216893862\n",
      "state terminated\n",
      "episode 1671, reward 530.0, memory_length 2000, epsilon 0.715913426685026\n",
      "state terminated\n",
      "episode 1672, reward 1110.0, memory_length 2000, epsilon 0.715770260316803\n",
      "state terminated\n",
      "episode 1673, reward 544.0, memory_length 2000, epsilon 0.7156271225789907\n",
      "state terminated\n",
      "episode 1674, reward 927.0, memory_length 2000, epsilon 0.7154840134658631\n",
      "state terminated\n",
      "episode 1675, reward 916.0, memory_length 2000, epsilon 0.7153409329716963\n",
      "state terminated\n",
      "episode 1676, reward 720.0, memory_length 2000, epsilon 0.715197881090767\n",
      "state terminated\n",
      "episode 1677, reward 553.0, memory_length 2000, epsilon 0.7150548578173529\n",
      "state terminated\n",
      "episode 1678, reward 972.0, memory_length 2000, epsilon 0.7149118631457332\n",
      "state terminated\n",
      "episode 1679, reward 898.0, memory_length 2000, epsilon 0.7147688970701882\n",
      "state terminated\n",
      "episode 1680, reward 671.0, memory_length 2000, epsilon 0.7146259595849991\n",
      "state terminated\n",
      "episode 1681, reward 1136.0, memory_length 2000, epsilon 0.7144830506844485\n",
      "state terminated\n",
      "episode 1682, reward 966.0, memory_length 2000, epsilon 0.71434017036282\n",
      "state terminated\n",
      "episode 1683, reward 709.0, memory_length 2000, epsilon 0.7141973186143985\n",
      "state terminated\n",
      "episode 1684, reward 634.0, memory_length 2000, epsilon 0.7140544954334699\n",
      "state terminated\n",
      "episode 1685, reward 913.0, memory_length 2000, epsilon 0.713911700814321\n",
      "state terminated\n",
      "episode 1686, reward 871.0, memory_length 2000, epsilon 0.7137689347512404\n",
      "state terminated\n",
      "episode 1687, reward 1067.0, memory_length 2000, epsilon 0.7136261972385172\n",
      "state terminated\n",
      "episode 1688, reward 778.0, memory_length 2000, epsilon 0.7134834882704421\n",
      "state terminated\n",
      "episode 1689, reward 955.0, memory_length 2000, epsilon 0.7133408078413065\n",
      "state terminated\n",
      "episode 1690, reward 813.0, memory_length 2000, epsilon 0.7131981559454033\n",
      "state terminated\n",
      "episode 1691, reward 836.0, memory_length 2000, epsilon 0.7130555325770264\n",
      "state terminated\n",
      "episode 1692, reward 1021.0, memory_length 2000, epsilon 0.712912937730471\n",
      "state terminated\n",
      "episode 1693, reward 823.0, memory_length 2000, epsilon 0.7127703714000332\n",
      "state terminated\n",
      "episode 1694, reward 936.0, memory_length 2000, epsilon 0.7126278335800103\n",
      "state terminated\n",
      "episode 1695, reward 1089.0, memory_length 2000, epsilon 0.7124853242647009\n",
      "state terminated\n",
      "episode 1696, reward 947.0, memory_length 2000, epsilon 0.7123428434484045\n",
      "state terminated\n",
      "episode 1697, reward 602.0, memory_length 2000, epsilon 0.7122003911254219\n",
      "state terminated\n",
      "episode 1698, reward 794.0, memory_length 2000, epsilon 0.7120579672900551\n",
      "state terminated\n",
      "episode 1699, reward 477.0, memory_length 2000, epsilon 0.711915571936607\n",
      "state terminated\n",
      "episode 1700, reward 940.0, memory_length 2000, epsilon 0.711773205059382\n",
      "state terminated\n",
      "episode 1701, reward 570.0, memory_length 2000, epsilon 0.7116308666526853\n",
      "state terminated\n",
      "episode 1702, reward 900.0, memory_length 2000, epsilon 0.7114885567108233\n",
      "state terminated\n",
      "episode 1703, reward 882.0, memory_length 2000, epsilon 0.7113462752281037\n",
      "state terminated\n",
      "episode 1704, reward 588.0, memory_length 2000, epsilon 0.7112040221988352\n",
      "state terminated\n",
      "episode 1705, reward 872.0, memory_length 2000, epsilon 0.7110617976173277\n",
      "state terminated\n",
      "episode 1706, reward 796.0, memory_length 2000, epsilon 0.7109196014778921\n",
      "state terminated\n",
      "episode 1707, reward 1077.0, memory_length 2000, epsilon 0.7107774337748408\n",
      "state terminated\n",
      "episode 1708, reward 571.0, memory_length 2000, epsilon 0.7106352945024867\n",
      "state terminated\n",
      "episode 1709, reward 1025.0, memory_length 2000, epsilon 0.7104931836551447\n",
      "state terminated\n",
      "episode 1710, reward 1143.0, memory_length 2000, epsilon 0.7103511012271302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1711, reward 887.0, memory_length 2000, epsilon 0.7102090472127597\n",
      "state terminated\n",
      "episode 1712, reward 1041.0, memory_length 2000, epsilon 0.7100670216063512\n",
      "state terminated\n",
      "episode 1713, reward 606.0, memory_length 2000, epsilon 0.7099250244022236\n",
      "state terminated\n",
      "episode 1714, reward 1093.0, memory_length 2000, epsilon 0.7097830555946971\n",
      "state terminated\n",
      "episode 1715, reward 704.0, memory_length 2000, epsilon 0.709641115178093\n",
      "state terminated\n",
      "episode 1716, reward 1307.0, memory_length 2000, epsilon 0.7094992031467336\n",
      "state terminated\n",
      "episode 1717, reward 871.0, memory_length 2000, epsilon 0.7093573194949424\n",
      "state terminated\n",
      "episode 1718, reward 312.0, memory_length 2000, epsilon 0.7092154642170441\n",
      "state terminated\n",
      "episode 1719, reward 618.0, memory_length 2000, epsilon 0.7090736373073644\n",
      "state terminated\n",
      "episode 1720, reward 684.0, memory_length 2000, epsilon 0.7089318387602301\n",
      "state terminated\n",
      "episode 1721, reward 1135.0, memory_length 2000, epsilon 0.7087900685699698\n",
      "state terminated\n",
      "episode 1722, reward 810.0, memory_length 2000, epsilon 0.7086483267309122\n",
      "state terminated\n",
      "episode 1723, reward 752.0, memory_length 2000, epsilon 0.7085066132373877\n",
      "state terminated\n",
      "episode 1724, reward 773.0, memory_length 2000, epsilon 0.7083649280837279\n",
      "state terminated\n",
      "episode 1725, reward 578.0, memory_length 2000, epsilon 0.7082232712642653\n",
      "state terminated\n",
      "episode 1726, reward 650.0, memory_length 2000, epsilon 0.7080816427733336\n",
      "state terminated\n",
      "episode 1727, reward 815.0, memory_length 2000, epsilon 0.7079400426052678\n",
      "state terminated\n",
      "episode 1728, reward 704.0, memory_length 2000, epsilon 0.7077984707544037\n",
      "state terminated\n",
      "episode 1729, reward 1141.0, memory_length 2000, epsilon 0.7076569272150786\n",
      "state terminated\n",
      "episode 1730, reward 917.0, memory_length 2000, epsilon 0.7075154119816306\n",
      "state terminated\n",
      "episode 1731, reward 1215.0, memory_length 2000, epsilon 0.7073739250483992\n",
      "state terminated\n",
      "episode 1732, reward 1011.0, memory_length 2000, epsilon 0.7072324664097249\n",
      "state terminated\n",
      "episode 1733, reward 808.0, memory_length 2000, epsilon 0.7070910360599495\n",
      "state terminated\n",
      "episode 1734, reward 743.0, memory_length 2000, epsilon 0.7069496339934155\n",
      "state terminated\n",
      "episode 1735, reward 610.0, memory_length 2000, epsilon 0.7068082602044669\n",
      "state terminated\n",
      "episode 1736, reward 838.0, memory_length 2000, epsilon 0.7066669146874489\n",
      "state terminated\n",
      "episode 1737, reward 855.0, memory_length 2000, epsilon 0.7065255974367074\n",
      "state terminated\n",
      "episode 1738, reward 855.0, memory_length 2000, epsilon 0.7063843084465901\n",
      "state terminated\n",
      "episode 1739, reward 1061.0, memory_length 2000, epsilon 0.7062430477114452\n",
      "state terminated\n",
      "episode 1740, reward 1120.0, memory_length 2000, epsilon 0.7061018152256222\n",
      "state terminated\n",
      "episode 1741, reward 738.0, memory_length 2000, epsilon 0.7059606109834721\n",
      "state terminated\n",
      "episode 1742, reward 856.0, memory_length 2000, epsilon 0.7058194349793463\n",
      "state terminated\n",
      "episode 1743, reward 687.0, memory_length 2000, epsilon 0.7056782872075981\n",
      "state terminated\n",
      "episode 1744, reward 721.0, memory_length 2000, epsilon 0.7055371676625816\n",
      "state terminated\n",
      "episode 1745, reward 900.0, memory_length 2000, epsilon 0.7053960763386516\n",
      "state terminated\n",
      "episode 1746, reward 705.0, memory_length 2000, epsilon 0.705255013230165\n",
      "state terminated\n",
      "episode 1747, reward 994.0, memory_length 2000, epsilon 0.7051139783314789\n",
      "state terminated\n",
      "episode 1748, reward 561.0, memory_length 2000, epsilon 0.704972971636952\n",
      "state terminated\n",
      "episode 1749, reward 935.0, memory_length 2000, epsilon 0.7048319931409442\n",
      "state terminated\n",
      "episode 1750, reward 1010.0, memory_length 2000, epsilon 0.7046910428378163\n",
      "state terminated\n",
      "episode 1751, reward 639.0, memory_length 2000, epsilon 0.70455012072193\n",
      "state terminated\n",
      "episode 1752, reward 864.0, memory_length 2000, epsilon 0.7044092267876487\n",
      "state terminated\n",
      "episode 1753, reward 578.0, memory_length 2000, epsilon 0.7042683610293365\n",
      "state terminated\n",
      "episode 1754, reward 729.0, memory_length 2000, epsilon 0.7041275234413589\n",
      "state terminated\n",
      "episode 1755, reward 921.0, memory_length 2000, epsilon 0.7039867140180823\n",
      "state terminated\n",
      "episode 1756, reward 868.0, memory_length 2000, epsilon 0.7038459327538744\n",
      "state terminated\n",
      "episode 1757, reward 706.0, memory_length 2000, epsilon 0.7037051796431039\n",
      "state terminated\n",
      "episode 1758, reward 1201.0, memory_length 2000, epsilon 0.7035644546801406\n",
      "state terminated\n",
      "episode 1759, reward 980.0, memory_length 2000, epsilon 0.7034237578593557\n",
      "state terminated\n",
      "episode 1760, reward 688.0, memory_length 2000, epsilon 0.7032830891751212\n",
      "state terminated\n",
      "episode 1761, reward 840.0, memory_length 2000, epsilon 0.7031424486218102\n",
      "state terminated\n",
      "episode 1762, reward 841.0, memory_length 2000, epsilon 0.7030018361937974\n",
      "state terminated\n",
      "episode 1763, reward 837.0, memory_length 2000, epsilon 0.7028612518854581\n",
      "state terminated\n",
      "episode 1764, reward 850.0, memory_length 2000, epsilon 0.7027206956911689\n",
      "state terminated\n",
      "episode 1765, reward 671.0, memory_length 2000, epsilon 0.7025801676053076\n",
      "state terminated\n",
      "episode 1766, reward 628.0, memory_length 2000, epsilon 0.7024396676222533\n",
      "state terminated\n",
      "episode 1767, reward 778.0, memory_length 2000, epsilon 0.7022991957363858\n",
      "state terminated\n",
      "episode 1768, reward 589.0, memory_length 2000, epsilon 0.7021587519420859\n",
      "state terminated\n",
      "episode 1769, reward 912.0, memory_length 2000, epsilon 0.7020183362337366\n",
      "state terminated\n",
      "episode 1770, reward 855.0, memory_length 2000, epsilon 0.7018779486057204\n",
      "state terminated\n",
      "episode 1771, reward 879.0, memory_length 2000, epsilon 0.7017375890524226\n",
      "state terminated\n",
      "episode 1772, reward 819.0, memory_length 2000, epsilon 0.7015972575682282\n",
      "state terminated\n",
      "episode 1773, reward 928.0, memory_length 2000, epsilon 0.7014569541475243\n",
      "state terminated\n",
      "episode 1774, reward 945.0, memory_length 2000, epsilon 0.7013166787846987\n",
      "state terminated\n",
      "episode 1775, reward 1025.0, memory_length 2000, epsilon 0.7011764314741402\n",
      "state terminated\n",
      "episode 1776, reward 1038.0, memory_length 2000, epsilon 0.7010362122102393\n",
      "state terminated\n",
      "episode 1777, reward 1056.0, memory_length 2000, epsilon 0.7008960209873868\n",
      "state terminated\n",
      "episode 1778, reward 684.0, memory_length 2000, epsilon 0.7007558577999753\n",
      "state terminated\n",
      "episode 1779, reward 990.0, memory_length 2000, epsilon 0.7006157226423981\n",
      "state terminated\n",
      "episode 1780, reward 900.0, memory_length 2000, epsilon 0.70047561550905\n",
      "state terminated\n",
      "episode 1781, reward 360.0, memory_length 2000, epsilon 0.7003355363943267\n",
      "state terminated\n",
      "episode 1782, reward 642.0, memory_length 2000, epsilon 0.7001954852926248\n",
      "state terminated\n",
      "episode 1783, reward 646.0, memory_length 2000, epsilon 0.7000554621983424\n",
      "state terminated\n",
      "episode 1784, reward 630.0, memory_length 2000, epsilon 0.6999154671058786\n",
      "state terminated\n",
      "episode 1785, reward 842.0, memory_length 2000, epsilon 0.6997755000096336\n",
      "state terminated\n",
      "episode 1786, reward 835.0, memory_length 2000, epsilon 0.6996355609040088\n",
      "state terminated\n",
      "episode 1787, reward 900.0, memory_length 2000, epsilon 0.6994956497834064\n",
      "state terminated\n",
      "episode 1788, reward 1271.0, memory_length 2000, epsilon 0.6993557666422301\n",
      "state terminated\n",
      "episode 1789, reward 904.0, memory_length 2000, epsilon 0.6992159114748846\n",
      "state terminated\n",
      "episode 1790, reward 1016.0, memory_length 2000, epsilon 0.6990760842757755\n",
      "state terminated\n",
      "episode 1791, reward 400.0, memory_length 2000, epsilon 0.69893628503931\n",
      "state terminated\n",
      "episode 1792, reward 787.0, memory_length 2000, epsilon 0.698796513759896\n",
      "state terminated\n",
      "episode 1793, reward 664.0, memory_length 2000, epsilon 0.6986567704319426\n",
      "state terminated\n",
      "episode 1794, reward 840.0, memory_length 2000, epsilon 0.6985170550498602\n",
      "state terminated\n",
      "episode 1795, reward 666.0, memory_length 2000, epsilon 0.69837736760806\n",
      "state terminated\n",
      "episode 1796, reward 1064.0, memory_length 2000, epsilon 0.6982377081009546\n",
      "state terminated\n",
      "episode 1797, reward 970.0, memory_length 2000, epsilon 0.6980980765229577\n",
      "state terminated\n",
      "episode 1798, reward 408.0, memory_length 2000, epsilon 0.6979584728684839\n",
      "state terminated\n",
      "episode 1799, reward 729.0, memory_length 2000, epsilon 0.6978188971319492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1800, reward 427.0, memory_length 2000, epsilon 0.6976793493077703\n",
      "state terminated\n",
      "episode 1801, reward 768.0, memory_length 2000, epsilon 0.6975398293903656\n",
      "state terminated\n",
      "episode 1802, reward 519.0, memory_length 2000, epsilon 0.6974003373741541\n",
      "state terminated\n",
      "episode 1803, reward 846.0, memory_length 2000, epsilon 0.6972608732535562\n",
      "state terminated\n",
      "episode 1804, reward 889.0, memory_length 2000, epsilon 0.6971214370229933\n",
      "state terminated\n",
      "episode 1805, reward 970.0, memory_length 2000, epsilon 0.6969820286768881\n",
      "state terminated\n",
      "episode 1806, reward 723.0, memory_length 2000, epsilon 0.696842648209664\n",
      "state terminated\n",
      "episode 1807, reward 854.0, memory_length 2000, epsilon 0.696703295615746\n",
      "state terminated\n",
      "episode 1808, reward 943.0, memory_length 2000, epsilon 0.6965639708895598\n",
      "state terminated\n",
      "episode 1809, reward 903.0, memory_length 2000, epsilon 0.6964246740255327\n",
      "state terminated\n",
      "episode 1810, reward 751.0, memory_length 2000, epsilon 0.6962854050180924\n",
      "state terminated\n",
      "episode 1811, reward 669.0, memory_length 2000, epsilon 0.6961461638616687\n",
      "state terminated\n",
      "episode 1812, reward 960.0, memory_length 2000, epsilon 0.6960069505506915\n",
      "state terminated\n",
      "episode 1813, reward 945.0, memory_length 2000, epsilon 0.6958677650795925\n",
      "state terminated\n",
      "episode 1814, reward 814.0, memory_length 2000, epsilon 0.6957286074428041\n",
      "state terminated\n",
      "episode 1815, reward 820.0, memory_length 2000, epsilon 0.69558947763476\n",
      "state terminated\n",
      "episode 1816, reward 908.0, memory_length 2000, epsilon 0.6954503756498952\n",
      "state terminated\n",
      "episode 1817, reward 552.0, memory_length 2000, epsilon 0.6953113014826456\n",
      "state terminated\n",
      "episode 1818, reward 738.0, memory_length 2000, epsilon 0.695172255127448\n",
      "state terminated\n",
      "episode 1819, reward 912.0, memory_length 2000, epsilon 0.6950332365787408\n",
      "state terminated\n",
      "episode 1820, reward 640.0, memory_length 2000, epsilon 0.6948942458309632\n",
      "state terminated\n",
      "episode 1821, reward 837.0, memory_length 2000, epsilon 0.6947552828785554\n",
      "state terminated\n",
      "episode 1822, reward 522.0, memory_length 2000, epsilon 0.694616347715959\n",
      "state terminated\n",
      "episode 1823, reward 961.0, memory_length 2000, epsilon 0.6944774403376167\n",
      "state terminated\n",
      "episode 1824, reward 660.0, memory_length 2000, epsilon 0.6943385607379721\n",
      "state terminated\n",
      "episode 1825, reward 1000.0, memory_length 2000, epsilon 0.6941997089114701\n",
      "state terminated\n",
      "episode 1826, reward 908.0, memory_length 2000, epsilon 0.6940608848525565\n",
      "state terminated\n",
      "episode 1827, reward 901.0, memory_length 2000, epsilon 0.6939220885556783\n",
      "state terminated\n",
      "episode 1828, reward 723.0, memory_length 2000, epsilon 0.6937833200152838\n",
      "state terminated\n",
      "episode 1829, reward 846.0, memory_length 2000, epsilon 0.693644579225822\n",
      "state terminated\n",
      "episode 1830, reward 828.0, memory_length 2000, epsilon 0.6935058661817437\n",
      "state terminated\n",
      "episode 1831, reward 798.0, memory_length 2000, epsilon 0.6933671808775\n",
      "state terminated\n",
      "episode 1832, reward 805.0, memory_length 2000, epsilon 0.6932285233075437\n",
      "state terminated\n",
      "episode 1833, reward 971.0, memory_length 2000, epsilon 0.6930898934663284\n",
      "state terminated\n",
      "episode 1834, reward 944.0, memory_length 2000, epsilon 0.692951291348309\n",
      "state terminated\n",
      "episode 1835, reward 875.0, memory_length 2000, epsilon 0.6928127169479412\n",
      "state terminated\n",
      "episode 1836, reward 963.0, memory_length 2000, epsilon 0.6926741702596823\n",
      "state terminated\n",
      "episode 1837, reward 938.0, memory_length 2000, epsilon 0.6925356512779903\n",
      "state terminated\n",
      "episode 1838, reward 1188.0, memory_length 2000, epsilon 0.6923971599973243\n",
      "state terminated\n",
      "episode 1839, reward 939.0, memory_length 2000, epsilon 0.692258696412145\n",
      "state terminated\n",
      "episode 1840, reward 916.0, memory_length 2000, epsilon 0.6921202605169134\n",
      "state terminated\n",
      "episode 1841, reward 839.0, memory_length 2000, epsilon 0.6919818523060925\n",
      "state terminated\n",
      "episode 1842, reward 1228.0, memory_length 2000, epsilon 0.6918434717741458\n",
      "state terminated\n",
      "episode 1843, reward 891.0, memory_length 2000, epsilon 0.691705118915538\n",
      "state terminated\n",
      "episode 1844, reward 867.0, memory_length 2000, epsilon 0.6915667937247352\n",
      "state terminated\n",
      "episode 1845, reward 686.0, memory_length 2000, epsilon 0.691428496196204\n",
      "state terminated\n",
      "episode 1846, reward 772.0, memory_length 2000, epsilon 0.6912902263244128\n",
      "state terminated\n",
      "episode 1847, reward 1170.0, memory_length 2000, epsilon 0.6911519841038307\n",
      "state terminated\n",
      "episode 1848, reward 882.0, memory_length 2000, epsilon 0.6910137695289282\n",
      "state terminated\n",
      "episode 1849, reward 728.0, memory_length 2000, epsilon 0.6908755825941766\n",
      "state terminated\n",
      "episode 1850, reward 980.0, memory_length 2000, epsilon 0.6907374232940483\n",
      "state terminated\n",
      "episode 1851, reward 980.0, memory_length 2000, epsilon 0.6905992916230169\n",
      "state terminated\n",
      "episode 1852, reward 1079.0, memory_length 2000, epsilon 0.6904611875755574\n",
      "state terminated\n",
      "episode 1853, reward 811.0, memory_length 2000, epsilon 0.6903231111461455\n",
      "state terminated\n",
      "episode 1854, reward 630.0, memory_length 2000, epsilon 0.6901850623292581\n",
      "state terminated\n",
      "episode 1855, reward 733.0, memory_length 2000, epsilon 0.6900470411193734\n",
      "state terminated\n",
      "episode 1856, reward 1026.0, memory_length 2000, epsilon 0.6899090475109703\n",
      "state terminated\n",
      "episode 1857, reward 937.0, memory_length 2000, epsilon 0.6897710814985293\n",
      "state terminated\n",
      "episode 1858, reward 727.0, memory_length 2000, epsilon 0.6896331430765316\n",
      "state terminated\n",
      "episode 1859, reward 787.0, memory_length 2000, epsilon 0.6894952322394596\n",
      "state terminated\n",
      "episode 1860, reward 771.0, memory_length 2000, epsilon 0.6893573489817971\n",
      "state terminated\n",
      "episode 1861, reward 691.0, memory_length 2000, epsilon 0.6892194932980287\n",
      "state terminated\n",
      "episode 1862, reward 856.0, memory_length 2000, epsilon 0.6890816651826401\n",
      "state terminated\n",
      "episode 1863, reward 1001.0, memory_length 2000, epsilon 0.6889438646301181\n",
      "state terminated\n",
      "episode 1864, reward 756.0, memory_length 2000, epsilon 0.6888060916349508\n",
      "state terminated\n",
      "episode 1865, reward 582.0, memory_length 2000, epsilon 0.6886683461916273\n",
      "state terminated\n",
      "episode 1866, reward 964.0, memory_length 2000, epsilon 0.6885306282946377\n",
      "state terminated\n",
      "episode 1867, reward 416.0, memory_length 2000, epsilon 0.6883929379384734\n",
      "state terminated\n",
      "episode 1868, reward 616.0, memory_length 2000, epsilon 0.6882552751176267\n",
      "state terminated\n",
      "episode 1869, reward 729.0, memory_length 2000, epsilon 0.6881176398265911\n",
      "state terminated\n",
      "episode 1870, reward 808.0, memory_length 2000, epsilon 0.6879800320598611\n",
      "state terminated\n",
      "episode 1871, reward 878.0, memory_length 2000, epsilon 0.6878424518119325\n",
      "state terminated\n",
      "episode 1872, reward 790.0, memory_length 2000, epsilon 0.6877048990773021\n",
      "state terminated\n",
      "episode 1873, reward 742.0, memory_length 2000, epsilon 0.6875673738504677\n",
      "state terminated\n",
      "episode 1874, reward 884.0, memory_length 2000, epsilon 0.6874298761259284\n",
      "state terminated\n",
      "episode 1875, reward 360.0, memory_length 2000, epsilon 0.6872924058981843\n",
      "state terminated\n",
      "episode 1876, reward 961.0, memory_length 2000, epsilon 0.6871549631617364\n",
      "state terminated\n",
      "episode 1877, reward 950.0, memory_length 2000, epsilon 0.6870175479110872\n",
      "state terminated\n",
      "episode 1878, reward 607.0, memory_length 2000, epsilon 0.6868801601407399\n",
      "state terminated\n",
      "episode 1879, reward 874.0, memory_length 2000, epsilon 0.6867427998451991\n",
      "state terminated\n",
      "episode 1880, reward 895.0, memory_length 2000, epsilon 0.6866054670189705\n",
      "state terminated\n",
      "episode 1881, reward 1263.0, memory_length 2000, epsilon 0.6864681616565608\n",
      "state terminated\n",
      "episode 1882, reward 891.0, memory_length 2000, epsilon 0.6863308837524774\n",
      "state terminated\n",
      "episode 1883, reward 773.0, memory_length 2000, epsilon 0.6861936333012295\n",
      "state terminated\n",
      "episode 1884, reward 1127.0, memory_length 2000, epsilon 0.6860564102973271\n",
      "state terminated\n",
      "episode 1885, reward 1046.0, memory_length 2000, epsilon 0.6859192147352812\n",
      "state terminated\n",
      "episode 1886, reward 1004.0, memory_length 2000, epsilon 0.6857820466096038\n",
      "state terminated\n",
      "episode 1887, reward 1177.0, memory_length 2000, epsilon 0.6856449059148085\n",
      "state terminated\n",
      "episode 1888, reward 877.0, memory_length 2000, epsilon 0.6855077926454096\n",
      "state terminated\n",
      "episode 1889, reward 729.0, memory_length 2000, epsilon 0.6853707067959224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1890, reward 833.0, memory_length 2000, epsilon 0.6852336483608636\n",
      "state terminated\n",
      "episode 1891, reward 845.0, memory_length 2000, epsilon 0.6850966173347508\n",
      "state terminated\n",
      "episode 1892, reward 657.0, memory_length 2000, epsilon 0.6849596137121029\n",
      "state terminated\n",
      "episode 1893, reward 724.0, memory_length 2000, epsilon 0.6848226374874395\n",
      "state terminated\n",
      "episode 1894, reward 466.0, memory_length 2000, epsilon 0.6846856886552817\n",
      "state terminated\n",
      "episode 1895, reward 701.0, memory_length 2000, epsilon 0.6845487672101516\n",
      "state terminated\n",
      "episode 1896, reward 980.0, memory_length 2000, epsilon 0.6844118731465721\n",
      "state terminated\n",
      "episode 1897, reward 762.0, memory_length 2000, epsilon 0.6842750064590679\n",
      "state terminated\n",
      "episode 1898, reward 571.0, memory_length 2000, epsilon 0.6841381671421639\n",
      "state terminated\n",
      "episode 1899, reward 735.0, memory_length 2000, epsilon 0.6840013551903866\n",
      "state terminated\n",
      "episode 1900, reward 716.0, memory_length 2000, epsilon 0.6838645705982637\n",
      "state terminated\n",
      "episode 1901, reward 771.0, memory_length 2000, epsilon 0.6837278133603236\n",
      "state terminated\n",
      "episode 1902, reward 670.0, memory_length 2000, epsilon 0.6835910834710963\n",
      "state terminated\n",
      "episode 1903, reward 867.0, memory_length 2000, epsilon 0.6834543809251125\n",
      "state terminated\n",
      "episode 1904, reward 402.0, memory_length 2000, epsilon 0.6833177057169038\n",
      "state terminated\n",
      "episode 1905, reward 985.0, memory_length 2000, epsilon 0.6831810578410035\n",
      "state terminated\n",
      "episode 1906, reward 1043.0, memory_length 2000, epsilon 0.6830444372919455\n",
      "state terminated\n",
      "episode 1907, reward 606.0, memory_length 2000, epsilon 0.6829078440642652\n",
      "state terminated\n",
      "episode 1908, reward 684.0, memory_length 2000, epsilon 0.6827712781524988\n",
      "state terminated\n",
      "episode 1909, reward 926.0, memory_length 2000, epsilon 0.6826347395511836\n",
      "state terminated\n",
      "episode 1910, reward 751.0, memory_length 2000, epsilon 0.682498228254858\n",
      "state terminated\n",
      "episode 1911, reward 785.0, memory_length 2000, epsilon 0.6823617442580616\n",
      "state terminated\n",
      "episode 1912, reward 825.0, memory_length 2000, epsilon 0.6822252875553352\n",
      "state terminated\n",
      "episode 1913, reward 859.0, memory_length 2000, epsilon 0.6820888581412203\n",
      "state terminated\n",
      "episode 1914, reward 820.0, memory_length 2000, epsilon 0.6819524560102598\n",
      "state terminated\n",
      "episode 1915, reward 970.0, memory_length 2000, epsilon 0.6818160811569977\n",
      "state terminated\n",
      "episode 1916, reward 1074.0, memory_length 2000, epsilon 0.6816797335759788\n",
      "state terminated\n",
      "episode 1917, reward 627.0, memory_length 2000, epsilon 0.6815434132617495\n",
      "state terminated\n",
      "episode 1918, reward 936.0, memory_length 2000, epsilon 0.6814071202088567\n",
      "state terminated\n",
      "episode 1919, reward 540.0, memory_length 2000, epsilon 0.6812708544118489\n",
      "state terminated\n",
      "episode 1920, reward 882.0, memory_length 2000, epsilon 0.6811346158652754\n",
      "state terminated\n",
      "episode 1921, reward 1037.0, memory_length 2000, epsilon 0.6809984045636864\n",
      "state terminated\n",
      "episode 1922, reward 924.0, memory_length 2000, epsilon 0.6808622205016338\n",
      "state terminated\n",
      "episode 1923, reward 741.0, memory_length 2000, epsilon 0.6807260636736703\n",
      "state terminated\n",
      "episode 1924, reward 746.0, memory_length 2000, epsilon 0.6805899340743491\n",
      "state terminated\n",
      "episode 1925, reward 655.0, memory_length 2000, epsilon 0.6804538316982256\n",
      "state terminated\n",
      "episode 1926, reward 1026.0, memory_length 2000, epsilon 0.6803177565398553\n",
      "state terminated\n",
      "episode 1927, reward 858.0, memory_length 2000, epsilon 0.6801817085937956\n",
      "state terminated\n",
      "episode 1928, reward 835.0, memory_length 2000, epsilon 0.6800456878546041\n",
      "state terminated\n",
      "episode 1929, reward 692.0, memory_length 2000, epsilon 0.6799096943168401\n",
      "state terminated\n",
      "episode 1930, reward 1199.0, memory_length 2000, epsilon 0.6797737279750642\n",
      "state terminated\n",
      "episode 1931, reward 861.0, memory_length 2000, epsilon 0.6796377888238375\n",
      "state terminated\n",
      "episode 1932, reward 878.0, memory_length 2000, epsilon 0.6795018768577223\n",
      "state terminated\n",
      "episode 1933, reward 983.0, memory_length 2000, epsilon 0.6793659920712825\n",
      "state terminated\n",
      "episode 1934, reward 711.0, memory_length 2000, epsilon 0.6792301344590822\n",
      "state terminated\n",
      "episode 1935, reward 1141.0, memory_length 2000, epsilon 0.6790943040156875\n",
      "state terminated\n",
      "episode 1936, reward 872.0, memory_length 2000, epsilon 0.678958500735665\n",
      "state terminated\n",
      "episode 1937, reward 464.0, memory_length 2000, epsilon 0.6788227246135827\n",
      "state terminated\n",
      "episode 1938, reward 832.0, memory_length 2000, epsilon 0.6786869756440095\n",
      "state terminated\n",
      "episode 1939, reward 845.0, memory_length 2000, epsilon 0.6785512538215153\n",
      "state terminated\n",
      "episode 1940, reward 728.0, memory_length 2000, epsilon 0.6784155591406714\n",
      "state terminated\n",
      "episode 1941, reward 771.0, memory_length 2000, epsilon 0.67827989159605\n",
      "state terminated\n",
      "episode 1942, reward 1007.0, memory_length 2000, epsilon 0.6781442511822243\n",
      "state terminated\n",
      "episode 1943, reward 801.0, memory_length 2000, epsilon 0.6780086378937688\n",
      "state terminated\n",
      "episode 1944, reward 1007.0, memory_length 2000, epsilon 0.6778730517252587\n",
      "state terminated\n",
      "episode 1945, reward 899.0, memory_length 2000, epsilon 0.6777374926712709\n",
      "state terminated\n",
      "episode 1946, reward 810.0, memory_length 2000, epsilon 0.677601960726383\n",
      "state terminated\n",
      "episode 1947, reward 1124.0, memory_length 2000, epsilon 0.6774664558851735\n",
      "state terminated\n",
      "episode 1948, reward 1030.0, memory_length 2000, epsilon 0.6773309781422223\n",
      "state terminated\n",
      "episode 1949, reward 720.0, memory_length 2000, epsilon 0.6771955274921104\n",
      "state terminated\n",
      "episode 1950, reward 777.0, memory_length 2000, epsilon 0.6770601039294196\n",
      "state terminated\n",
      "episode 1951, reward 864.0, memory_length 2000, epsilon 0.6769247074487332\n",
      "state terminated\n",
      "episode 1952, reward 1002.0, memory_length 2000, epsilon 0.6767893380446351\n",
      "state terminated\n",
      "episode 1953, reward 353.0, memory_length 2000, epsilon 0.6766539957117106\n",
      "state terminated\n",
      "episode 1954, reward 1224.0, memory_length 2000, epsilon 0.676518680444546\n",
      "state terminated\n",
      "episode 1955, reward 747.0, memory_length 2000, epsilon 0.6763833922377287\n",
      "state terminated\n",
      "episode 1956, reward 1278.0, memory_length 2000, epsilon 0.6762481310858474\n",
      "state terminated\n",
      "episode 1957, reward 835.0, memory_length 2000, epsilon 0.6761128969834911\n",
      "state terminated\n",
      "episode 1958, reward 810.0, memory_length 2000, epsilon 0.6759776899252509\n",
      "state terminated\n",
      "episode 1959, reward 1250.0, memory_length 2000, epsilon 0.6758425099057185\n",
      "state terminated\n",
      "episode 1960, reward 838.0, memory_length 2000, epsilon 0.6757073569194864\n",
      "state terminated\n",
      "episode 1961, reward 980.0, memory_length 2000, epsilon 0.6755722309611487\n",
      "state terminated\n",
      "episode 1962, reward 835.0, memory_length 2000, epsilon 0.6754371320253004\n",
      "state terminated\n",
      "episode 1963, reward 657.0, memory_length 2000, epsilon 0.6753020601065375\n",
      "state terminated\n",
      "episode 1964, reward 737.0, memory_length 2000, epsilon 0.675167015199457\n",
      "state terminated\n",
      "episode 1965, reward 570.0, memory_length 2000, epsilon 0.6750319972986573\n",
      "state terminated\n",
      "episode 1966, reward 1435.0, memory_length 2000, epsilon 0.6748970063987375\n",
      "state terminated\n",
      "episode 1967, reward 992.0, memory_length 2000, epsilon 0.6747620424942982\n",
      "state terminated\n",
      "episode 1968, reward 767.0, memory_length 2000, epsilon 0.6746271055799405\n",
      "state terminated\n",
      "episode 1969, reward 985.0, memory_length 2000, epsilon 0.6744921956502672\n",
      "state terminated\n",
      "episode 1970, reward 898.0, memory_length 2000, epsilon 0.6743573126998818\n",
      "state terminated\n",
      "episode 1971, reward 804.0, memory_length 2000, epsilon 0.674222456723389\n",
      "state terminated\n",
      "episode 1972, reward 1053.0, memory_length 2000, epsilon 0.6740876277153945\n",
      "state terminated\n",
      "episode 1973, reward 1120.0, memory_length 2000, epsilon 0.6739528256705052\n",
      "state terminated\n",
      "episode 1974, reward 767.0, memory_length 2000, epsilon 0.6738180505833291\n",
      "state terminated\n",
      "episode 1975, reward 789.0, memory_length 2000, epsilon 0.6736833024484752\n",
      "state terminated\n",
      "episode 1976, reward 920.0, memory_length 2000, epsilon 0.6735485812605533\n",
      "state terminated\n",
      "episode 1977, reward 715.0, memory_length 2000, epsilon 0.6734138870141747\n",
      "state terminated\n",
      "episode 1978, reward 705.0, memory_length 2000, epsilon 0.6732792197039519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 1979, reward 1116.0, memory_length 2000, epsilon 0.6731445793244978\n",
      "state terminated\n",
      "episode 1980, reward 738.0, memory_length 2000, epsilon 0.6730099658704269\n",
      "state terminated\n",
      "episode 1981, reward 541.0, memory_length 2000, epsilon 0.672875379336355\n",
      "state terminated\n",
      "episode 1982, reward 792.0, memory_length 2000, epsilon 0.6727408197168981\n",
      "state terminated\n",
      "episode 1983, reward 1004.0, memory_length 2000, epsilon 0.6726062870066744\n",
      "state terminated\n",
      "episode 1984, reward 958.0, memory_length 2000, epsilon 0.6724717812003019\n",
      "state terminated\n",
      "episode 1985, reward 936.0, memory_length 2000, epsilon 0.6723373022924009\n",
      "state terminated\n",
      "episode 1986, reward 643.0, memory_length 2000, epsilon 0.6722028502775921\n",
      "state terminated\n",
      "episode 1987, reward 830.0, memory_length 2000, epsilon 0.6720684251504974\n",
      "state terminated\n",
      "episode 1988, reward 1212.0, memory_length 2000, epsilon 0.6719340269057398\n",
      "state terminated\n",
      "episode 1989, reward 1425.0, memory_length 2000, epsilon 0.6717996555379433\n",
      "state terminated\n",
      "episode 1990, reward 777.0, memory_length 2000, epsilon 0.6716653110417331\n",
      "state terminated\n",
      "episode 1991, reward 724.0, memory_length 2000, epsilon 0.6715309934117355\n",
      "state terminated\n",
      "episode 1992, reward 904.0, memory_length 2000, epsilon 0.6713967026425777\n",
      "state terminated\n",
      "episode 1993, reward 951.0, memory_length 2000, epsilon 0.6712624387288881\n",
      "state terminated\n",
      "episode 1994, reward 611.0, memory_length 2000, epsilon 0.6711282016652962\n",
      "state terminated\n",
      "episode 1995, reward 684.0, memory_length 2000, epsilon 0.6709939914464323\n",
      "state terminated\n",
      "episode 1996, reward 997.0, memory_length 2000, epsilon 0.6708598080669284\n",
      "state terminated\n",
      "episode 1997, reward 720.0, memory_length 2000, epsilon 0.6707256515214166\n",
      "state terminated\n",
      "episode 1998, reward 614.0, memory_length 2000, epsilon 0.6705915218045312\n",
      "state terminated\n",
      "episode 1999, reward 754.0, memory_length 2000, epsilon 0.6704574189109066\n",
      "state terminated\n",
      "episode 2000, reward 826.0, memory_length 2000, epsilon 0.6703233428351789\n",
      "Total time taken  12586.419902324677\n",
      "state terminated\n",
      "episode 2001, reward 692.0, memory_length 2000, epsilon 0.670189293571985\n",
      "state terminated\n",
      "episode 2002, reward 622.0, memory_length 2000, epsilon 0.670055271115963\n",
      "state terminated\n",
      "episode 2003, reward 949.0, memory_length 2000, epsilon 0.6699212754617518\n",
      "state terminated\n",
      "episode 2004, reward 760.0, memory_length 2000, epsilon 0.6697873066039919\n",
      "state terminated\n",
      "episode 2005, reward 1164.0, memory_length 2000, epsilon 0.6696533645373242\n",
      "state terminated\n",
      "episode 2006, reward 857.0, memory_length 2000, epsilon 0.6695194492563912\n",
      "state terminated\n",
      "episode 2007, reward 1024.0, memory_length 2000, epsilon 0.6693855607558363\n",
      "state terminated\n",
      "episode 2008, reward 1218.0, memory_length 2000, epsilon 0.6692516990303038\n",
      "state terminated\n",
      "episode 2009, reward 1146.0, memory_length 2000, epsilon 0.6691178640744395\n",
      "state terminated\n",
      "episode 2010, reward 1205.0, memory_length 2000, epsilon 0.6689840558828898\n",
      "state terminated\n",
      "episode 2011, reward 1138.0, memory_length 2000, epsilon 0.6688502744503024\n",
      "state terminated\n",
      "episode 2012, reward 1142.0, memory_length 2000, epsilon 0.6687165197713262\n",
      "state terminated\n",
      "episode 2013, reward 1165.0, memory_length 2000, epsilon 0.6685827918406106\n",
      "state terminated\n",
      "episode 2014, reward 961.0, memory_length 2000, epsilon 0.668449090652807\n",
      "state terminated\n",
      "episode 2015, reward 728.0, memory_length 2000, epsilon 0.6683154162025671\n",
      "state terminated\n",
      "episode 2016, reward 1086.0, memory_length 2000, epsilon 0.6681817684845438\n",
      "state terminated\n",
      "episode 2017, reward 591.0, memory_length 2000, epsilon 0.6680481474933915\n",
      "state terminated\n",
      "episode 2018, reward 1146.0, memory_length 2000, epsilon 0.667914553223765\n",
      "state terminated\n",
      "episode 2019, reward 587.0, memory_length 2000, epsilon 0.6677809856703208\n",
      "state terminated\n",
      "episode 2020, reward 747.0, memory_length 2000, epsilon 0.6676474448277162\n",
      "state terminated\n",
      "episode 2021, reward 756.0, memory_length 2000, epsilon 0.6675139306906095\n",
      "state terminated\n",
      "episode 2022, reward 295.0, memory_length 2000, epsilon 0.6673804432536599\n",
      "state terminated\n",
      "episode 2023, reward 780.0, memory_length 2000, epsilon 0.6672469825115283\n",
      "state terminated\n",
      "episode 2024, reward 857.0, memory_length 2000, epsilon 0.667113548458876\n",
      "state terminated\n",
      "episode 2025, reward 836.0, memory_length 2000, epsilon 0.6669801410903657\n",
      "state terminated\n",
      "episode 2026, reward 697.0, memory_length 2000, epsilon 0.6668467604006613\n",
      "state terminated\n",
      "episode 2027, reward 1017.0, memory_length 2000, epsilon 0.6667134063844272\n",
      "state terminated\n",
      "episode 2028, reward 916.0, memory_length 2000, epsilon 0.6665800790363297\n",
      "state terminated\n",
      "episode 2029, reward 966.0, memory_length 2000, epsilon 0.6664467783510352\n",
      "state terminated\n",
      "episode 2030, reward 688.0, memory_length 2000, epsilon 0.6663135043232121\n",
      "state terminated\n",
      "episode 2031, reward 822.0, memory_length 2000, epsilon 0.6661802569475291\n",
      "state terminated\n",
      "episode 2032, reward 1042.0, memory_length 2000, epsilon 0.6660470362186566\n",
      "state terminated\n",
      "episode 2033, reward 846.0, memory_length 2000, epsilon 0.6659138421312656\n",
      "state terminated\n",
      "episode 2034, reward 871.0, memory_length 2000, epsilon 0.6657806746800283\n",
      "state terminated\n",
      "episode 2035, reward 1223.0, memory_length 2000, epsilon 0.6656475338596182\n",
      "state terminated\n",
      "episode 2036, reward 943.0, memory_length 2000, epsilon 0.6655144196647095\n",
      "state terminated\n",
      "episode 2037, reward 1080.0, memory_length 2000, epsilon 0.6653813320899776\n",
      "state terminated\n",
      "episode 2038, reward 1265.0, memory_length 2000, epsilon 0.6652482711300991\n",
      "state terminated\n",
      "episode 2039, reward 1000.0, memory_length 2000, epsilon 0.6651152367797516\n",
      "state terminated\n",
      "episode 2040, reward 830.0, memory_length 2000, epsilon 0.6649822290336137\n",
      "state terminated\n",
      "episode 2041, reward 1005.0, memory_length 2000, epsilon 0.6648492478863649\n",
      "state terminated\n",
      "episode 2042, reward 735.0, memory_length 2000, epsilon 0.6647162933326862\n",
      "state terminated\n",
      "episode 2043, reward 786.0, memory_length 2000, epsilon 0.6645833653672593\n",
      "state terminated\n",
      "episode 2044, reward 811.0, memory_length 2000, epsilon 0.664450463984767\n",
      "state terminated\n",
      "episode 2045, reward 999.0, memory_length 2000, epsilon 0.6643175891798935\n",
      "state terminated\n",
      "episode 2046, reward 1084.0, memory_length 2000, epsilon 0.6641847409473236\n",
      "state terminated\n",
      "episode 2047, reward 771.0, memory_length 2000, epsilon 0.6640519192817435\n",
      "state terminated\n",
      "episode 2048, reward 878.0, memory_length 2000, epsilon 0.6639191241778402\n",
      "state terminated\n",
      "episode 2049, reward 854.0, memory_length 2000, epsilon 0.6637863556303019\n",
      "state terminated\n",
      "episode 2050, reward 1367.0, memory_length 2000, epsilon 0.663653613633818\n",
      "state terminated\n",
      "episode 2051, reward 817.0, memory_length 2000, epsilon 0.6635208981830787\n",
      "state terminated\n",
      "episode 2052, reward 774.0, memory_length 2000, epsilon 0.6633882092727754\n",
      "state terminated\n",
      "episode 2053, reward 791.0, memory_length 2000, epsilon 0.6632555468976006\n",
      "state terminated\n",
      "episode 2054, reward 1014.0, memory_length 2000, epsilon 0.6631229110522477\n",
      "state terminated\n",
      "episode 2055, reward 1097.0, memory_length 2000, epsilon 0.6629903017314114\n",
      "state terminated\n",
      "episode 2056, reward 927.0, memory_length 2000, epsilon 0.6628577189297872\n",
      "state terminated\n",
      "episode 2057, reward 772.0, memory_length 2000, epsilon 0.6627251626420718\n",
      "state terminated\n",
      "episode 2058, reward 1145.0, memory_length 2000, epsilon 0.6625926328629631\n",
      "state terminated\n",
      "episode 2059, reward 881.0, memory_length 2000, epsilon 0.6624601295871598\n",
      "state terminated\n",
      "episode 2060, reward 851.0, memory_length 2000, epsilon 0.6623276528093617\n",
      "state terminated\n",
      "episode 2061, reward 967.0, memory_length 2000, epsilon 0.6621952025242699\n",
      "state terminated\n",
      "episode 2062, reward 782.0, memory_length 2000, epsilon 0.6620627787265861\n",
      "state terminated\n",
      "episode 2063, reward 1026.0, memory_length 2000, epsilon 0.6619303814110137\n",
      "state terminated\n",
      "episode 2064, reward 831.0, memory_length 2000, epsilon 0.6617980105722566\n",
      "state terminated\n",
      "episode 2065, reward 794.0, memory_length 2000, epsilon 0.66166566620502\n",
      "state terminated\n",
      "episode 2066, reward 1085.0, memory_length 2000, epsilon 0.6615333483040102\n",
      "state terminated\n",
      "episode 2067, reward 938.0, memory_length 2000, epsilon 0.6614010568639344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2068, reward 1234.0, memory_length 2000, epsilon 0.6612687918795009\n",
      "state terminated\n",
      "episode 2069, reward 975.0, memory_length 2000, epsilon 0.6611365533454193\n",
      "state terminated\n",
      "episode 2070, reward 918.0, memory_length 2000, epsilon 0.6610043412563997\n",
      "state terminated\n",
      "episode 2071, reward 1035.0, memory_length 2000, epsilon 0.6608721556071541\n",
      "state terminated\n",
      "episode 2072, reward 1043.0, memory_length 2000, epsilon 0.6607399963923947\n",
      "state terminated\n",
      "episode 2073, reward 435.0, memory_length 2000, epsilon 0.6606078636068351\n",
      "state terminated\n",
      "episode 2074, reward 1110.0, memory_length 2000, epsilon 0.6604757572451903\n",
      "state terminated\n",
      "episode 2075, reward 1195.0, memory_length 2000, epsilon 0.6603436773021758\n",
      "state terminated\n",
      "episode 2076, reward 1142.0, memory_length 2000, epsilon 0.6602116237725085\n",
      "state terminated\n",
      "episode 2077, reward 1125.0, memory_length 2000, epsilon 0.6600795966509062\n",
      "state terminated\n",
      "episode 2078, reward 584.0, memory_length 2000, epsilon 0.659947595932088\n",
      "state terminated\n",
      "episode 2079, reward 759.0, memory_length 2000, epsilon 0.6598156216107737\n",
      "state terminated\n",
      "episode 2080, reward 1083.0, memory_length 2000, epsilon 0.6596836736816842\n",
      "state terminated\n",
      "episode 2081, reward 955.0, memory_length 2000, epsilon 0.6595517521395419\n",
      "state terminated\n",
      "episode 2082, reward 625.0, memory_length 2000, epsilon 0.6594198569790696\n",
      "state terminated\n",
      "episode 2083, reward 1124.0, memory_length 2000, epsilon 0.6592879881949917\n",
      "state terminated\n",
      "episode 2084, reward 890.0, memory_length 2000, epsilon 0.6591561457820335\n",
      "state terminated\n",
      "episode 2085, reward 1030.0, memory_length 2000, epsilon 0.6590243297349211\n",
      "state terminated\n",
      "episode 2086, reward 926.0, memory_length 2000, epsilon 0.6588925400483822\n",
      "state terminated\n",
      "episode 2087, reward 913.0, memory_length 2000, epsilon 0.6587607767171448\n",
      "state terminated\n",
      "episode 2088, reward 1046.0, memory_length 2000, epsilon 0.6586290397359386\n",
      "state terminated\n",
      "episode 2089, reward 940.0, memory_length 2000, epsilon 0.6584973290994941\n",
      "state terminated\n",
      "episode 2090, reward 678.0, memory_length 2000, epsilon 0.6583656448025429\n",
      "state terminated\n",
      "episode 2091, reward 902.0, memory_length 2000, epsilon 0.6582339868398175\n",
      "state terminated\n",
      "episode 2092, reward 979.0, memory_length 2000, epsilon 0.6581023552060518\n",
      "state terminated\n",
      "episode 2093, reward 1326.0, memory_length 2000, epsilon 0.6579707498959801\n",
      "state terminated\n",
      "episode 2094, reward 771.0, memory_length 2000, epsilon 0.6578391709043387\n",
      "state terminated\n",
      "episode 2095, reward 902.0, memory_length 2000, epsilon 0.6577076182258642\n",
      "state terminated\n",
      "episode 2096, reward 787.0, memory_length 2000, epsilon 0.6575760918552945\n",
      "state terminated\n",
      "episode 2097, reward 952.0, memory_length 2000, epsilon 0.6574445917873686\n",
      "state terminated\n",
      "episode 2098, reward 1092.0, memory_length 2000, epsilon 0.6573131180168265\n",
      "state terminated\n",
      "episode 2099, reward 1003.0, memory_length 2000, epsilon 0.6571816705384091\n",
      "state terminated\n",
      "episode 2100, reward 1173.0, memory_length 2000, epsilon 0.6570502493468586\n",
      "state terminated\n",
      "episode 2101, reward 1014.0, memory_length 2000, epsilon 0.6569188544369182\n",
      "state terminated\n",
      "episode 2102, reward 1129.0, memory_length 2000, epsilon 0.6567874858033321\n",
      "state terminated\n",
      "episode 2103, reward 441.0, memory_length 2000, epsilon 0.6566561434408454\n",
      "state terminated\n",
      "episode 2104, reward 1094.0, memory_length 2000, epsilon 0.6565248273442047\n",
      "state terminated\n",
      "episode 2105, reward 567.0, memory_length 2000, epsilon 0.6563935375081571\n",
      "state terminated\n",
      "episode 2106, reward 756.0, memory_length 2000, epsilon 0.6562622739274511\n",
      "state terminated\n",
      "episode 2107, reward 957.0, memory_length 2000, epsilon 0.6561310365968361\n",
      "state terminated\n",
      "episode 2108, reward 835.0, memory_length 2000, epsilon 0.6559998255110627\n",
      "state terminated\n",
      "episode 2109, reward 1066.0, memory_length 2000, epsilon 0.6558686406648824\n",
      "state terminated\n",
      "episode 2110, reward 1021.0, memory_length 2000, epsilon 0.6557374820530477\n",
      "state terminated\n",
      "episode 2111, reward 907.0, memory_length 2000, epsilon 0.6556063496703125\n",
      "state terminated\n",
      "episode 2112, reward 733.0, memory_length 2000, epsilon 0.6554752435114314\n",
      "state terminated\n",
      "episode 2113, reward 895.0, memory_length 2000, epsilon 0.6553441635711601\n",
      "state terminated\n",
      "episode 2114, reward 1053.0, memory_length 2000, epsilon 0.6552131098442554\n",
      "state terminated\n",
      "episode 2115, reward 1037.0, memory_length 2000, epsilon 0.6550820823254752\n",
      "state terminated\n",
      "episode 2116, reward 891.0, memory_length 2000, epsilon 0.6549510810095783\n",
      "state terminated\n",
      "episode 2117, reward 775.0, memory_length 2000, epsilon 0.6548201058913248\n",
      "state terminated\n",
      "episode 2118, reward 909.0, memory_length 2000, epsilon 0.6546891569654757\n",
      "state terminated\n",
      "episode 2119, reward 1107.0, memory_length 2000, epsilon 0.6545582342267928\n",
      "state terminated\n",
      "episode 2120, reward 920.0, memory_length 2000, epsilon 0.6544273376700395\n",
      "state terminated\n",
      "episode 2121, reward 1003.0, memory_length 2000, epsilon 0.6542964672899797\n",
      "state terminated\n",
      "episode 2122, reward 655.0, memory_length 2000, epsilon 0.6541656230813787\n",
      "state terminated\n",
      "episode 2123, reward 630.0, memory_length 2000, epsilon 0.6540348050390027\n",
      "state terminated\n",
      "episode 2124, reward 731.0, memory_length 2000, epsilon 0.653904013157619\n",
      "state terminated\n",
      "episode 2125, reward 876.0, memory_length 2000, epsilon 0.6537732474319959\n",
      "state terminated\n",
      "episode 2126, reward 1291.0, memory_length 2000, epsilon 0.6536425078569028\n",
      "state terminated\n",
      "episode 2127, reward 729.0, memory_length 2000, epsilon 0.6535117944271102\n",
      "state terminated\n",
      "episode 2128, reward 886.0, memory_length 2000, epsilon 0.6533811071373893\n",
      "state terminated\n",
      "episode 2129, reward 1069.0, memory_length 2000, epsilon 0.6532504459825128\n",
      "state terminated\n",
      "episode 2130, reward 959.0, memory_length 2000, epsilon 0.6531198109572544\n",
      "state terminated\n",
      "episode 2131, reward 949.0, memory_length 2000, epsilon 0.6529892020563883\n",
      "state terminated\n",
      "episode 2132, reward 1021.0, memory_length 2000, epsilon 0.6528586192746906\n",
      "state terminated\n",
      "episode 2133, reward 1060.0, memory_length 2000, epsilon 0.6527280626069376\n",
      "state terminated\n",
      "episode 2134, reward 498.0, memory_length 2000, epsilon 0.6525975320479072\n",
      "state terminated\n",
      "episode 2135, reward 589.0, memory_length 2000, epsilon 0.6524670275923782\n",
      "state terminated\n",
      "episode 2136, reward 1157.0, memory_length 2000, epsilon 0.6523365492351304\n",
      "state terminated\n",
      "episode 2137, reward 1120.0, memory_length 2000, epsilon 0.6522060969709447\n",
      "state terminated\n",
      "episode 2138, reward 864.0, memory_length 2000, epsilon 0.6520756707946028\n",
      "state terminated\n",
      "episode 2139, reward 1254.0, memory_length 2000, epsilon 0.6519452707008878\n",
      "state terminated\n",
      "episode 2140, reward 1012.0, memory_length 2000, epsilon 0.6518148966845839\n",
      "state terminated\n",
      "episode 2141, reward 917.0, memory_length 2000, epsilon 0.651684548740476\n",
      "state terminated\n",
      "episode 2142, reward 1242.0, memory_length 2000, epsilon 0.65155422686335\n",
      "state terminated\n",
      "episode 2143, reward 891.0, memory_length 2000, epsilon 0.6514239310479931\n",
      "state terminated\n",
      "episode 2144, reward 1283.0, memory_length 2000, epsilon 0.6512936612891936\n",
      "state terminated\n",
      "episode 2145, reward 1244.0, memory_length 2000, epsilon 0.6511634175817407\n",
      "state terminated\n",
      "episode 2146, reward 855.0, memory_length 2000, epsilon 0.6510331999204245\n",
      "state terminated\n",
      "episode 2147, reward 837.0, memory_length 2000, epsilon 0.6509030083000364\n",
      "state terminated\n",
      "episode 2148, reward 1196.0, memory_length 2000, epsilon 0.6507728427153687\n",
      "state terminated\n",
      "episode 2149, reward 943.0, memory_length 2000, epsilon 0.6506427031612149\n",
      "state terminated\n",
      "episode 2150, reward 932.0, memory_length 2000, epsilon 0.6505125896323692\n",
      "state terminated\n",
      "episode 2151, reward 894.0, memory_length 2000, epsilon 0.6503825021236274\n",
      "state terminated\n",
      "episode 2152, reward 1059.0, memory_length 2000, epsilon 0.6502524406297856\n",
      "state terminated\n",
      "episode 2153, reward 1136.0, memory_length 2000, epsilon 0.6501224051456415\n",
      "state terminated\n",
      "episode 2154, reward 1120.0, memory_length 2000, epsilon 0.6499923956659936\n",
      "state terminated\n",
      "episode 2155, reward 764.0, memory_length 2000, epsilon 0.6498624121856418\n",
      "state terminated\n",
      "episode 2156, reward 489.0, memory_length 2000, epsilon 0.6497324546993865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2157, reward 969.0, memory_length 2000, epsilon 0.6496025232020294\n",
      "state terminated\n",
      "episode 2158, reward 1102.0, memory_length 2000, epsilon 0.6494726176883733\n",
      "state terminated\n",
      "episode 2159, reward 641.0, memory_length 2000, epsilon 0.6493427381532222\n",
      "state terminated\n",
      "episode 2160, reward 1296.0, memory_length 2000, epsilon 0.6492128845913806\n",
      "state terminated\n",
      "episode 2161, reward 1098.0, memory_length 2000, epsilon 0.6490830569976543\n",
      "state terminated\n",
      "episode 2162, reward 868.0, memory_length 2000, epsilon 0.6489532553668506\n",
      "state terminated\n",
      "episode 2163, reward 1344.0, memory_length 2000, epsilon 0.6488234796937772\n",
      "state terminated\n",
      "episode 2164, reward 1178.0, memory_length 2000, epsilon 0.6486937299732429\n",
      "state terminated\n",
      "episode 2165, reward 565.0, memory_length 2000, epsilon 0.648564006200058\n",
      "state terminated\n",
      "episode 2166, reward 1471.0, memory_length 2000, epsilon 0.6484343083690335\n",
      "state terminated\n",
      "episode 2167, reward 1043.0, memory_length 2000, epsilon 0.6483046364749813\n",
      "state terminated\n",
      "episode 2168, reward 1566.0, memory_length 2000, epsilon 0.6481749905127145\n",
      "state terminated\n",
      "episode 2169, reward 843.0, memory_length 2000, epsilon 0.6480453704770477\n",
      "state terminated\n",
      "episode 2170, reward 929.0, memory_length 2000, epsilon 0.6479157763627957\n",
      "state terminated\n",
      "episode 2171, reward 1210.0, memory_length 2000, epsilon 0.6477862081647748\n",
      "state terminated\n",
      "episode 2172, reward 934.0, memory_length 2000, epsilon 0.6476566658778025\n",
      "state terminated\n",
      "episode 2173, reward 1125.0, memory_length 2000, epsilon 0.6475271494966967\n",
      "state terminated\n",
      "episode 2174, reward 916.0, memory_length 2000, epsilon 0.647397659016277\n",
      "state terminated\n",
      "episode 2175, reward 1218.0, memory_length 2000, epsilon 0.6472681944313639\n",
      "state terminated\n",
      "episode 2176, reward 1488.0, memory_length 2000, epsilon 0.6471387557367785\n",
      "state terminated\n",
      "episode 2177, reward 596.0, memory_length 2000, epsilon 0.6470093429273435\n",
      "state terminated\n",
      "episode 2178, reward 1015.0, memory_length 2000, epsilon 0.6468799559978822\n",
      "state terminated\n",
      "episode 2179, reward 647.0, memory_length 2000, epsilon 0.6467505949432192\n",
      "state terminated\n",
      "episode 2180, reward 846.0, memory_length 2000, epsilon 0.6466212597581803\n",
      "state terminated\n",
      "episode 2181, reward 1240.0, memory_length 2000, epsilon 0.6464919504375917\n",
      "state terminated\n",
      "episode 2182, reward 934.0, memory_length 2000, epsilon 0.6463626669762813\n",
      "state terminated\n",
      "episode 2183, reward 1228.0, memory_length 2000, epsilon 0.6462334093690775\n",
      "state terminated\n",
      "episode 2184, reward 1051.0, memory_length 2000, epsilon 0.6461041776108104\n",
      "state terminated\n",
      "episode 2185, reward 814.0, memory_length 2000, epsilon 0.6459749716963104\n",
      "state terminated\n",
      "episode 2186, reward 623.0, memory_length 2000, epsilon 0.6458457916204093\n",
      "state terminated\n",
      "episode 2187, reward 638.0, memory_length 2000, epsilon 0.6457166373779399\n",
      "state terminated\n",
      "episode 2188, reward 881.0, memory_length 2000, epsilon 0.6455875089637362\n",
      "state terminated\n",
      "episode 2189, reward 656.0, memory_length 2000, epsilon 0.645458406372633\n",
      "state terminated\n",
      "episode 2190, reward 1110.0, memory_length 2000, epsilon 0.645329329599466\n",
      "state terminated\n",
      "episode 2191, reward 1129.0, memory_length 2000, epsilon 0.6452002786390723\n",
      "state terminated\n",
      "episode 2192, reward 588.0, memory_length 2000, epsilon 0.6450712534862898\n",
      "state terminated\n",
      "episode 2193, reward 1017.0, memory_length 2000, epsilon 0.6449422541359576\n",
      "state terminated\n",
      "episode 2194, reward 984.0, memory_length 2000, epsilon 0.6448132805829156\n",
      "state terminated\n",
      "episode 2195, reward 1091.0, memory_length 2000, epsilon 0.644684332822005\n",
      "state terminated\n",
      "episode 2196, reward 1026.0, memory_length 2000, epsilon 0.6445554108480677\n",
      "state terminated\n",
      "episode 2197, reward 810.0, memory_length 2000, epsilon 0.6444265146559469\n",
      "state terminated\n",
      "episode 2198, reward 1151.0, memory_length 2000, epsilon 0.6442976442404869\n",
      "state terminated\n",
      "episode 2199, reward 897.0, memory_length 2000, epsilon 0.6441687995965326\n",
      "state terminated\n",
      "episode 2200, reward 902.0, memory_length 2000, epsilon 0.6440399807189305\n",
      "state terminated\n",
      "episode 2201, reward 766.0, memory_length 2000, epsilon 0.6439111876025276\n",
      "state terminated\n",
      "episode 2202, reward 906.0, memory_length 2000, epsilon 0.6437824202421725\n",
      "state terminated\n",
      "episode 2203, reward 1055.0, memory_length 2000, epsilon 0.643653678632714\n",
      "state terminated\n",
      "episode 2204, reward 625.0, memory_length 2000, epsilon 0.643524962769003\n",
      "state terminated\n",
      "episode 2205, reward 783.0, memory_length 2000, epsilon 0.6433962726458905\n",
      "state terminated\n",
      "episode 2206, reward 1035.0, memory_length 2000, epsilon 0.6432676082582288\n",
      "state terminated\n",
      "episode 2207, reward 1326.0, memory_length 2000, epsilon 0.6431389696008717\n",
      "state terminated\n",
      "episode 2208, reward 981.0, memory_length 2000, epsilon 0.6430103566686735\n",
      "state terminated\n",
      "episode 2209, reward 911.0, memory_length 2000, epsilon 0.6428817694564897\n",
      "state terminated\n",
      "episode 2210, reward 882.0, memory_length 2000, epsilon 0.6427532079591767\n",
      "state terminated\n",
      "episode 2211, reward 1035.0, memory_length 2000, epsilon 0.642624672171592\n",
      "state terminated\n",
      "episode 2212, reward 761.0, memory_length 2000, epsilon 0.6424961620885944\n",
      "state terminated\n",
      "episode 2213, reward 851.0, memory_length 2000, epsilon 0.6423676777050432\n",
      "state terminated\n",
      "episode 2214, reward 1066.0, memory_length 2000, epsilon 0.6422392190157994\n",
      "state terminated\n",
      "episode 2215, reward 1171.0, memory_length 2000, epsilon 0.6421107860157244\n",
      "state terminated\n",
      "episode 2216, reward 1066.0, memory_length 2000, epsilon 0.6419823786996808\n",
      "state terminated\n",
      "episode 2217, reward 1398.0, memory_length 2000, epsilon 0.6418539970625325\n",
      "state terminated\n",
      "episode 2218, reward 858.0, memory_length 2000, epsilon 0.6417256410991442\n",
      "state terminated\n",
      "episode 2219, reward 1009.0, memory_length 2000, epsilon 0.6415973108043816\n",
      "state terminated\n",
      "episode 2220, reward 1170.0, memory_length 2000, epsilon 0.6414690061731115\n",
      "state terminated\n",
      "episode 2221, reward 984.0, memory_length 2000, epsilon 0.6413407272002017\n",
      "state terminated\n",
      "episode 2222, reward 1044.0, memory_length 2000, epsilon 0.6412124738805213\n",
      "state terminated\n",
      "episode 2223, reward 967.0, memory_length 2000, epsilon 0.6410842462089398\n",
      "state terminated\n",
      "episode 2224, reward 1075.0, memory_length 2000, epsilon 0.6409560441803281\n",
      "state terminated\n",
      "episode 2225, reward 837.0, memory_length 2000, epsilon 0.6408278677895584\n",
      "state terminated\n",
      "episode 2226, reward 895.0, memory_length 2000, epsilon 0.6406997170315035\n",
      "state terminated\n",
      "episode 2227, reward 1061.0, memory_length 2000, epsilon 0.6405715919010373\n",
      "state terminated\n",
      "episode 2228, reward 880.0, memory_length 2000, epsilon 0.6404434923930349\n",
      "state terminated\n",
      "episode 2229, reward 1223.0, memory_length 2000, epsilon 0.6403154185023723\n",
      "state terminated\n",
      "episode 2230, reward 1377.0, memory_length 2000, epsilon 0.6401873702239265\n",
      "state terminated\n",
      "episode 2231, reward 1377.0, memory_length 2000, epsilon 0.6400593475525757\n",
      "state terminated\n",
      "episode 2232, reward 1323.0, memory_length 2000, epsilon 0.6399313504831986\n",
      "state terminated\n",
      "episode 2233, reward 679.0, memory_length 2000, epsilon 0.6398033790106759\n",
      "state terminated\n",
      "episode 2234, reward 465.0, memory_length 2000, epsilon 0.6396754331298882\n",
      "state terminated\n",
      "episode 2235, reward 975.0, memory_length 2000, epsilon 0.6395475128357181\n",
      "state terminated\n",
      "episode 2236, reward 718.0, memory_length 2000, epsilon 0.6394196181230485\n",
      "state terminated\n",
      "episode 2237, reward 1198.0, memory_length 2000, epsilon 0.6392917489867638\n",
      "state terminated\n",
      "episode 2238, reward 1017.0, memory_length 2000, epsilon 0.6391639054217491\n",
      "state terminated\n",
      "episode 2239, reward 1227.0, memory_length 2000, epsilon 0.6390360874228906\n",
      "state terminated\n",
      "episode 2240, reward 1218.0, memory_length 2000, epsilon 0.638908294985076\n",
      "state terminated\n",
      "episode 2241, reward 1087.0, memory_length 2000, epsilon 0.6387805281031929\n",
      "state terminated\n",
      "episode 2242, reward 1053.0, memory_length 2000, epsilon 0.6386527867721312\n",
      "state terminated\n",
      "episode 2243, reward 976.0, memory_length 2000, epsilon 0.638525070986781\n",
      "state terminated\n",
      "episode 2244, reward 917.0, memory_length 2000, epsilon 0.6383973807420338\n",
      "state terminated\n",
      "episode 2245, reward 858.0, memory_length 2000, epsilon 0.6382697160327818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2246, reward 936.0, memory_length 2000, epsilon 0.6381420768539187\n",
      "state terminated\n",
      "episode 2247, reward 1291.0, memory_length 2000, epsilon 0.6380144632003386\n",
      "state terminated\n",
      "episode 2248, reward 794.0, memory_length 2000, epsilon 0.6378868750669372\n",
      "state terminated\n",
      "episode 2249, reward 913.0, memory_length 2000, epsilon 0.6377593124486108\n",
      "state terminated\n",
      "episode 2250, reward 1047.0, memory_length 2000, epsilon 0.6376317753402571\n",
      "state terminated\n",
      "episode 2251, reward 967.0, memory_length 2000, epsilon 0.6375042637367743\n",
      "state terminated\n",
      "episode 2252, reward 409.0, memory_length 2000, epsilon 0.6373767776330624\n",
      "state terminated\n",
      "episode 2253, reward 895.0, memory_length 2000, epsilon 0.6372493170240214\n",
      "state terminated\n",
      "episode 2254, reward 1129.0, memory_length 2000, epsilon 0.6371218819045534\n",
      "state terminated\n",
      "episode 2255, reward 720.0, memory_length 2000, epsilon 0.6369944722695607\n",
      "state terminated\n",
      "episode 2256, reward 1309.0, memory_length 2000, epsilon 0.636867088113947\n",
      "state terminated\n",
      "episode 2257, reward 996.0, memory_length 2000, epsilon 0.6367397294326168\n",
      "state terminated\n",
      "episode 2258, reward 596.0, memory_length 2000, epsilon 0.636612396220476\n",
      "state terminated\n",
      "episode 2259, reward 986.0, memory_length 2000, epsilon 0.636485088472431\n",
      "state terminated\n",
      "episode 2260, reward 1052.0, memory_length 2000, epsilon 0.6363578061833898\n",
      "state terminated\n",
      "episode 2261, reward 1049.0, memory_length 2000, epsilon 0.6362305493482608\n",
      "state terminated\n",
      "episode 2262, reward 1062.0, memory_length 2000, epsilon 0.6361033179619539\n",
      "state terminated\n",
      "episode 2263, reward 895.0, memory_length 2000, epsilon 0.6359761120193798\n",
      "state terminated\n",
      "episode 2264, reward 843.0, memory_length 2000, epsilon 0.6358489315154502\n",
      "state terminated\n",
      "episode 2265, reward 958.0, memory_length 2000, epsilon 0.635721776445078\n",
      "state terminated\n",
      "episode 2266, reward 746.0, memory_length 2000, epsilon 0.635594646803177\n",
      "state terminated\n",
      "episode 2267, reward 1232.0, memory_length 2000, epsilon 0.6354675425846618\n",
      "state terminated\n",
      "episode 2268, reward 753.0, memory_length 2000, epsilon 0.6353404637844485\n",
      "state terminated\n",
      "episode 2269, reward 992.0, memory_length 2000, epsilon 0.6352134103974538\n",
      "state terminated\n",
      "episode 2270, reward 841.0, memory_length 2000, epsilon 0.6350863824185956\n",
      "state terminated\n",
      "episode 2271, reward 666.0, memory_length 2000, epsilon 0.6349593798427928\n",
      "state terminated\n",
      "episode 2272, reward 759.0, memory_length 2000, epsilon 0.6348324026649654\n",
      "state terminated\n",
      "episode 2273, reward 1351.0, memory_length 2000, epsilon 0.634705450880034\n",
      "state terminated\n",
      "episode 2274, reward 1075.0, memory_length 2000, epsilon 0.6345785244829208\n",
      "state terminated\n",
      "episode 2275, reward 634.0, memory_length 2000, epsilon 0.6344516234685488\n",
      "state terminated\n",
      "episode 2276, reward 944.0, memory_length 2000, epsilon 0.6343247478318416\n",
      "state terminated\n",
      "episode 2277, reward 1170.0, memory_length 2000, epsilon 0.6341978975677244\n",
      "state terminated\n",
      "episode 2278, reward 859.0, memory_length 2000, epsilon 0.6340710726711233\n",
      "state terminated\n",
      "episode 2279, reward 1145.0, memory_length 2000, epsilon 0.6339442731369651\n",
      "state terminated\n",
      "episode 2280, reward 1084.0, memory_length 2000, epsilon 0.633817498960178\n",
      "state terminated\n",
      "episode 2281, reward 1125.0, memory_length 2000, epsilon 0.633690750135691\n",
      "state terminated\n",
      "episode 2282, reward 699.0, memory_length 2000, epsilon 0.6335640266584339\n",
      "state terminated\n",
      "episode 2283, reward 1295.0, memory_length 2000, epsilon 0.6334373285233381\n",
      "state terminated\n",
      "episode 2284, reward 1616.0, memory_length 2000, epsilon 0.6333106557253354\n",
      "state terminated\n",
      "episode 2285, reward 817.0, memory_length 2000, epsilon 0.6331840082593592\n",
      "state terminated\n",
      "episode 2286, reward 1183.0, memory_length 2000, epsilon 0.6330573861203432\n",
      "state terminated\n",
      "episode 2287, reward 1179.0, memory_length 2000, epsilon 0.6329307893032229\n",
      "state terminated\n",
      "episode 2288, reward 957.0, memory_length 2000, epsilon 0.6328042178029342\n",
      "state terminated\n",
      "episode 2289, reward 619.0, memory_length 2000, epsilon 0.6326776716144142\n",
      "state terminated\n",
      "episode 2290, reward 1173.0, memory_length 2000, epsilon 0.6325511507326013\n",
      "state terminated\n",
      "episode 2291, reward 828.0, memory_length 2000, epsilon 0.6324246551524344\n",
      "state terminated\n",
      "episode 2292, reward 758.0, memory_length 2000, epsilon 0.6322981848688539\n",
      "state terminated\n",
      "episode 2293, reward 1021.0, memory_length 2000, epsilon 0.6321717398768008\n",
      "state terminated\n",
      "episode 2294, reward 737.0, memory_length 2000, epsilon 0.6320453201712174\n",
      "state terminated\n",
      "episode 2295, reward 1178.0, memory_length 2000, epsilon 0.6319189257470469\n",
      "state terminated\n",
      "episode 2296, reward 712.0, memory_length 2000, epsilon 0.6317925565992335\n",
      "state terminated\n",
      "episode 2297, reward 1241.0, memory_length 2000, epsilon 0.6316662127227224\n",
      "state terminated\n",
      "episode 2298, reward 1147.0, memory_length 2000, epsilon 0.6315398941124599\n",
      "state terminated\n",
      "episode 2299, reward 1197.0, memory_length 2000, epsilon 0.6314136007633933\n",
      "state terminated\n",
      "episode 2300, reward 1334.0, memory_length 2000, epsilon 0.6312873326704709\n",
      "state terminated\n",
      "episode 2301, reward 637.0, memory_length 2000, epsilon 0.6311610898286418\n",
      "state terminated\n",
      "episode 2302, reward 846.0, memory_length 2000, epsilon 0.6310348722328564\n",
      "state terminated\n",
      "episode 2303, reward 965.0, memory_length 2000, epsilon 0.6309086798780659\n",
      "state terminated\n",
      "episode 2304, reward 866.0, memory_length 2000, epsilon 0.6307825127592227\n",
      "state terminated\n",
      "episode 2305, reward 1138.0, memory_length 2000, epsilon 0.6306563708712802\n",
      "state terminated\n",
      "episode 2306, reward 1113.0, memory_length 2000, epsilon 0.6305302542091925\n",
      "state terminated\n",
      "episode 2307, reward 1064.0, memory_length 2000, epsilon 0.630404162767915\n",
      "state terminated\n",
      "episode 2308, reward 971.0, memory_length 2000, epsilon 0.6302780965424043\n",
      "state terminated\n",
      "episode 2309, reward 1187.0, memory_length 2000, epsilon 0.6301520555276174\n",
      "state terminated\n",
      "episode 2310, reward 1195.0, memory_length 2000, epsilon 0.6300260397185128\n",
      "state terminated\n",
      "episode 2311, reward 741.0, memory_length 2000, epsilon 0.6299000491100499\n",
      "state terminated\n",
      "episode 2312, reward 1192.0, memory_length 2000, epsilon 0.6297740836971891\n",
      "state terminated\n",
      "episode 2313, reward 1404.0, memory_length 2000, epsilon 0.6296481434748917\n",
      "state terminated\n",
      "episode 2314, reward 869.0, memory_length 2000, epsilon 0.6295222284381201\n",
      "state terminated\n",
      "episode 2315, reward 1181.0, memory_length 2000, epsilon 0.6293963385818379\n",
      "state terminated\n",
      "episode 2316, reward 764.0, memory_length 2000, epsilon 0.6292704739010091\n",
      "state terminated\n",
      "episode 2317, reward 803.0, memory_length 2000, epsilon 0.6291446343905993\n",
      "state terminated\n",
      "episode 2318, reward 1530.0, memory_length 2000, epsilon 0.6290188200455751\n",
      "state terminated\n",
      "episode 2319, reward 993.0, memory_length 2000, epsilon 0.6288930308609038\n",
      "state terminated\n",
      "episode 2320, reward 1342.0, memory_length 2000, epsilon 0.6287672668315537\n",
      "state terminated\n",
      "episode 2321, reward 798.0, memory_length 2000, epsilon 0.6286415279524945\n",
      "state terminated\n",
      "episode 2322, reward 898.0, memory_length 2000, epsilon 0.6285158142186964\n",
      "state terminated\n",
      "episode 2323, reward 1093.0, memory_length 2000, epsilon 0.628390125625131\n",
      "state terminated\n",
      "episode 2324, reward 778.0, memory_length 2000, epsilon 0.6282644621667706\n",
      "state terminated\n",
      "episode 2325, reward 1314.0, memory_length 2000, epsilon 0.6281388238385889\n",
      "state terminated\n",
      "episode 2326, reward 1134.0, memory_length 2000, epsilon 0.6280132106355601\n",
      "state terminated\n",
      "episode 2327, reward 934.0, memory_length 2000, epsilon 0.62788762255266\n",
      "state terminated\n",
      "episode 2328, reward 1127.0, memory_length 2000, epsilon 0.6277620595848648\n",
      "state terminated\n",
      "episode 2329, reward 1215.0, memory_length 2000, epsilon 0.627636521727152\n",
      "state terminated\n",
      "episode 2330, reward 683.0, memory_length 2000, epsilon 0.6275110089745002\n",
      "state terminated\n",
      "episode 2331, reward 1075.0, memory_length 2000, epsilon 0.627385521321889\n",
      "state terminated\n",
      "episode 2332, reward 1117.0, memory_length 2000, epsilon 0.6272600587642986\n",
      "state terminated\n",
      "episode 2333, reward 1227.0, memory_length 2000, epsilon 0.6271346212967105\n",
      "state terminated\n",
      "episode 2334, reward 723.0, memory_length 2000, epsilon 0.6270092089141074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2335, reward 1277.0, memory_length 2000, epsilon 0.6268838216114729\n",
      "state terminated\n",
      "episode 2336, reward 1160.0, memory_length 2000, epsilon 0.6267584593837913\n",
      "state terminated\n",
      "episode 2337, reward 1271.0, memory_length 2000, epsilon 0.6266331222260481\n",
      "state terminated\n",
      "episode 2338, reward 722.0, memory_length 2000, epsilon 0.6265078101332298\n",
      "state terminated\n",
      "episode 2339, reward 745.0, memory_length 2000, epsilon 0.626382523100324\n",
      "state terminated\n",
      "episode 2340, reward 647.0, memory_length 2000, epsilon 0.6262572611223194\n",
      "state terminated\n",
      "episode 2341, reward 924.0, memory_length 2000, epsilon 0.6261320241942051\n",
      "state terminated\n",
      "episode 2342, reward 902.0, memory_length 2000, epsilon 0.626006812310972\n",
      "state terminated\n",
      "episode 2343, reward 993.0, memory_length 2000, epsilon 0.6258816254676115\n",
      "state terminated\n",
      "episode 2344, reward 1128.0, memory_length 2000, epsilon 0.625756463659116\n",
      "state terminated\n",
      "episode 2345, reward 1188.0, memory_length 2000, epsilon 0.6256313268804792\n",
      "state terminated\n",
      "episode 2346, reward 1414.0, memory_length 2000, epsilon 0.6255062151266955\n",
      "state terminated\n",
      "episode 2347, reward 1142.0, memory_length 2000, epsilon 0.6253811283927604\n",
      "state terminated\n",
      "episode 2348, reward 956.0, memory_length 2000, epsilon 0.6252560666736706\n",
      "state terminated\n",
      "episode 2349, reward 1200.0, memory_length 2000, epsilon 0.6251310299644236\n",
      "state terminated\n",
      "episode 2350, reward 817.0, memory_length 2000, epsilon 0.6250060182600179\n",
      "state terminated\n",
      "episode 2351, reward 1143.0, memory_length 2000, epsilon 0.6248810315554529\n",
      "state terminated\n",
      "episode 2352, reward 1240.0, memory_length 2000, epsilon 0.6247560698457294\n",
      "state terminated\n",
      "episode 2353, reward 1249.0, memory_length 2000, epsilon 0.6246311331258487\n",
      "state terminated\n",
      "episode 2354, reward 975.0, memory_length 2000, epsilon 0.6245062213908134\n",
      "state terminated\n",
      "episode 2355, reward 745.0, memory_length 2000, epsilon 0.6243813346356271\n",
      "state terminated\n",
      "episode 2356, reward 1268.0, memory_length 2000, epsilon 0.6242564728552943\n",
      "state terminated\n",
      "episode 2357, reward 1185.0, memory_length 2000, epsilon 0.6241316360448202\n",
      "state terminated\n",
      "episode 2358, reward 1048.0, memory_length 2000, epsilon 0.6240068241992119\n",
      "state terminated\n",
      "episode 2359, reward 942.0, memory_length 2000, epsilon 0.6238820373134766\n",
      "state terminated\n",
      "episode 2360, reward 979.0, memory_length 2000, epsilon 0.6237572753826228\n",
      "state terminated\n",
      "episode 2361, reward 920.0, memory_length 2000, epsilon 0.6236325384016602\n",
      "state terminated\n",
      "episode 2362, reward 673.0, memory_length 2000, epsilon 0.6235078263655992\n",
      "state terminated\n",
      "episode 2363, reward 641.0, memory_length 2000, epsilon 0.6233831392694513\n",
      "state terminated\n",
      "episode 2364, reward 1061.0, memory_length 2000, epsilon 0.6232584771082291\n",
      "state terminated\n",
      "episode 2365, reward 1270.0, memory_length 2000, epsilon 0.623133839876946\n",
      "state terminated\n",
      "episode 2366, reward 1116.0, memory_length 2000, epsilon 0.6230092275706167\n",
      "state terminated\n",
      "episode 2367, reward 775.0, memory_length 2000, epsilon 0.6228846401842565\n",
      "state terminated\n",
      "episode 2368, reward 680.0, memory_length 2000, epsilon 0.622760077712882\n",
      "state terminated\n",
      "episode 2369, reward 746.0, memory_length 2000, epsilon 0.6226355401515107\n",
      "state terminated\n",
      "episode 2370, reward 1026.0, memory_length 2000, epsilon 0.622511027495161\n",
      "state terminated\n",
      "episode 2371, reward 966.0, memory_length 2000, epsilon 0.6223865397388526\n",
      "state terminated\n",
      "episode 2372, reward 1122.0, memory_length 2000, epsilon 0.6222620768776058\n",
      "state terminated\n",
      "episode 2373, reward 1277.0, memory_length 2000, epsilon 0.6221376389064422\n",
      "state terminated\n",
      "episode 2374, reward 1187.0, memory_length 2000, epsilon 0.6220132258203842\n",
      "state terminated\n",
      "episode 2375, reward 864.0, memory_length 2000, epsilon 0.6218888376144553\n",
      "state terminated\n",
      "episode 2376, reward 1168.0, memory_length 2000, epsilon 0.6217644742836801\n",
      "state terminated\n",
      "episode 2377, reward 909.0, memory_length 2000, epsilon 0.6216401358230839\n",
      "state terminated\n",
      "episode 2378, reward 1329.0, memory_length 2000, epsilon 0.6215158222276932\n",
      "state terminated\n",
      "episode 2379, reward 1089.0, memory_length 2000, epsilon 0.6213915334925355\n",
      "state terminated\n",
      "episode 2380, reward 794.0, memory_length 2000, epsilon 0.6212672696126391\n",
      "state terminated\n",
      "episode 2381, reward 1281.0, memory_length 2000, epsilon 0.6211430305830338\n",
      "state terminated\n",
      "episode 2382, reward 1215.0, memory_length 2000, epsilon 0.6210188163987496\n",
      "state terminated\n",
      "episode 2383, reward 1156.0, memory_length 2000, epsilon 0.6208946270548182\n",
      "state terminated\n",
      "episode 2384, reward 1072.0, memory_length 2000, epsilon 0.620770462546272\n",
      "state terminated\n",
      "episode 2385, reward 1323.0, memory_length 2000, epsilon 0.6206463228681444\n",
      "state terminated\n",
      "episode 2386, reward 1029.0, memory_length 2000, epsilon 0.6205222080154698\n",
      "state terminated\n",
      "episode 2387, reward 1006.0, memory_length 2000, epsilon 0.6203981179832834\n",
      "state terminated\n",
      "episode 2388, reward 1260.0, memory_length 2000, epsilon 0.620274052766622\n",
      "state terminated\n",
      "episode 2389, reward 1488.0, memory_length 2000, epsilon 0.6201500123605228\n",
      "state terminated\n",
      "episode 2390, reward 1017.0, memory_length 2000, epsilon 0.620025996760024\n",
      "state terminated\n",
      "episode 2391, reward 674.0, memory_length 2000, epsilon 0.6199020059601654\n",
      "state terminated\n",
      "episode 2392, reward 1214.0, memory_length 2000, epsilon 0.6197780399559869\n",
      "state terminated\n",
      "episode 2393, reward 1037.0, memory_length 2000, epsilon 0.6196540987425303\n",
      "state terminated\n",
      "episode 2394, reward 1206.0, memory_length 2000, epsilon 0.6195301823148376\n",
      "state terminated\n",
      "episode 2395, reward 1283.0, memory_length 2000, epsilon 0.6194062906679523\n",
      "state terminated\n",
      "episode 2396, reward 1091.0, memory_length 2000, epsilon 0.6192824237969188\n",
      "state terminated\n",
      "episode 2397, reward 1057.0, memory_length 2000, epsilon 0.6191585816967822\n",
      "state terminated\n",
      "episode 2398, reward 1023.0, memory_length 2000, epsilon 0.6190347643625889\n",
      "state terminated\n",
      "episode 2399, reward 963.0, memory_length 2000, epsilon 0.6189109717893864\n",
      "state terminated\n",
      "episode 2400, reward 1053.0, memory_length 2000, epsilon 0.6187872039722228\n",
      "state terminated\n",
      "episode 2401, reward 1055.0, memory_length 2000, epsilon 0.6186634609061474\n",
      "state terminated\n",
      "episode 2402, reward 836.0, memory_length 2000, epsilon 0.6185397425862106\n",
      "state terminated\n",
      "episode 2403, reward 1339.0, memory_length 2000, epsilon 0.6184160490074635\n",
      "state terminated\n",
      "episode 2404, reward 973.0, memory_length 2000, epsilon 0.6182923801649585\n",
      "state terminated\n",
      "episode 2405, reward 972.0, memory_length 2000, epsilon 0.6181687360537488\n",
      "state terminated\n",
      "episode 2406, reward 776.0, memory_length 2000, epsilon 0.6180451166688886\n",
      "state terminated\n",
      "episode 2407, reward 1174.0, memory_length 2000, epsilon 0.617921522005433\n",
      "state terminated\n",
      "episode 2408, reward 1008.0, memory_length 2000, epsilon 0.6177979520584386\n",
      "state terminated\n",
      "episode 2409, reward 858.0, memory_length 2000, epsilon 0.6176744068229624\n",
      "state terminated\n",
      "episode 2410, reward 970.0, memory_length 2000, epsilon 0.6175508862940623\n",
      "state terminated\n",
      "episode 2411, reward 1034.0, memory_length 2000, epsilon 0.617427390466798\n",
      "state terminated\n",
      "episode 2412, reward 1071.0, memory_length 2000, epsilon 0.6173039193362292\n",
      "state terminated\n",
      "episode 2413, reward 1274.0, memory_length 2000, epsilon 0.6171804728974173\n",
      "state terminated\n",
      "episode 2414, reward 1289.0, memory_length 2000, epsilon 0.6170570511454244\n",
      "state terminated\n",
      "episode 2415, reward 1136.0, memory_length 2000, epsilon 0.6169336540753136\n",
      "state terminated\n",
      "episode 2416, reward 712.0, memory_length 2000, epsilon 0.6168102816821491\n",
      "state terminated\n",
      "episode 2417, reward 1271.0, memory_length 2000, epsilon 0.616686933960996\n",
      "state terminated\n",
      "episode 2418, reward 1160.0, memory_length 2000, epsilon 0.6165636109069204\n",
      "state terminated\n",
      "episode 2419, reward 1433.0, memory_length 2000, epsilon 0.6164403125149891\n",
      "state terminated\n",
      "episode 2420, reward 1181.0, memory_length 2000, epsilon 0.6163170387802706\n",
      "state terminated\n",
      "episode 2421, reward 1236.0, memory_length 2000, epsilon 0.6161937896978334\n",
      "state terminated\n",
      "episode 2422, reward 579.0, memory_length 2000, epsilon 0.6160705652627483\n",
      "state terminated\n",
      "episode 2423, reward 1227.0, memory_length 2000, epsilon 0.6159473654700856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2424, reward 1356.0, memory_length 2000, epsilon 0.6158241903149176\n",
      "state terminated\n",
      "episode 2425, reward 1492.0, memory_length 2000, epsilon 0.6157010397923175\n",
      "state terminated\n",
      "episode 2426, reward 1300.0, memory_length 2000, epsilon 0.6155779138973588\n",
      "state terminated\n",
      "episode 2427, reward 1008.0, memory_length 2000, epsilon 0.6154548126251169\n",
      "state terminated\n",
      "episode 2428, reward 997.0, memory_length 2000, epsilon 0.6153317359706677\n",
      "state terminated\n",
      "episode 2429, reward 1197.0, memory_length 2000, epsilon 0.6152086839290879\n",
      "state terminated\n",
      "episode 2430, reward 674.0, memory_length 2000, epsilon 0.6150856564954555\n",
      "state terminated\n",
      "episode 2431, reward 876.0, memory_length 2000, epsilon 0.6149626536648495\n",
      "state terminated\n",
      "episode 2432, reward 1042.0, memory_length 2000, epsilon 0.6148396754323497\n",
      "state terminated\n",
      "episode 2433, reward 926.0, memory_length 2000, epsilon 0.6147167217930369\n",
      "state terminated\n",
      "episode 2434, reward 604.0, memory_length 2000, epsilon 0.6145937927419932\n",
      "state terminated\n",
      "episode 2435, reward 1196.0, memory_length 2000, epsilon 0.6144708882743013\n",
      "state terminated\n",
      "episode 2436, reward 1299.0, memory_length 2000, epsilon 0.6143480083850449\n",
      "state terminated\n",
      "episode 2437, reward 1413.0, memory_length 2000, epsilon 0.614225153069309\n",
      "state terminated\n",
      "episode 2438, reward 1221.0, memory_length 2000, epsilon 0.6141023223221793\n",
      "state terminated\n",
      "episode 2439, reward 1035.0, memory_length 2000, epsilon 0.6139795161387426\n",
      "state terminated\n",
      "episode 2440, reward 1357.0, memory_length 2000, epsilon 0.6138567345140865\n",
      "state terminated\n",
      "episode 2441, reward 1026.0, memory_length 2000, epsilon 0.6137339774433\n",
      "state terminated\n",
      "episode 2442, reward 712.0, memory_length 2000, epsilon 0.6136112449214727\n",
      "state terminated\n",
      "episode 2443, reward 866.0, memory_length 2000, epsilon 0.6134885369436952\n",
      "state terminated\n",
      "episode 2444, reward 1026.0, memory_length 2000, epsilon 0.6133658535050592\n",
      "state terminated\n",
      "episode 2445, reward 1406.0, memory_length 2000, epsilon 0.6132431946006575\n",
      "state terminated\n",
      "episode 2446, reward 927.0, memory_length 2000, epsilon 0.6131205602255836\n",
      "state terminated\n",
      "episode 2447, reward 813.0, memory_length 2000, epsilon 0.6129979503749323\n",
      "state terminated\n",
      "episode 2448, reward 1155.0, memory_length 2000, epsilon 0.6128753650437991\n",
      "state terminated\n",
      "episode 2449, reward 1338.0, memory_length 2000, epsilon 0.6127528042272805\n",
      "state terminated\n",
      "episode 2450, reward 1270.0, memory_length 2000, epsilon 0.6126302679204741\n",
      "state terminated\n",
      "episode 2451, reward 1105.0, memory_length 2000, epsilon 0.6125077561184786\n",
      "state terminated\n",
      "episode 2452, reward 1223.0, memory_length 2000, epsilon 0.6123852688163934\n",
      "state terminated\n",
      "episode 2453, reward 1352.0, memory_length 2000, epsilon 0.612262806009319\n",
      "state terminated\n",
      "episode 2454, reward 1222.0, memory_length 2000, epsilon 0.6121403676923571\n",
      "state terminated\n",
      "episode 2455, reward 1084.0, memory_length 2000, epsilon 0.6120179538606099\n",
      "state terminated\n",
      "episode 2456, reward 1213.0, memory_length 2000, epsilon 0.6118955645091808\n",
      "state terminated\n",
      "episode 2457, reward 1330.0, memory_length 2000, epsilon 0.6117731996331744\n",
      "state terminated\n",
      "episode 2458, reward 975.0, memory_length 2000, epsilon 0.6116508592276962\n",
      "state terminated\n",
      "episode 2459, reward 1196.0, memory_length 2000, epsilon 0.6115285432878523\n",
      "state terminated\n",
      "episode 2460, reward 1236.0, memory_length 2000, epsilon 0.6114062518087503\n",
      "state terminated\n",
      "episode 2461, reward 1260.0, memory_length 2000, epsilon 0.6112839847854984\n",
      "state terminated\n",
      "episode 2462, reward 1503.0, memory_length 2000, epsilon 0.6111617422132061\n",
      "state terminated\n",
      "episode 2463, reward 1095.0, memory_length 2000, epsilon 0.6110395240869834\n",
      "state terminated\n",
      "episode 2464, reward 1134.0, memory_length 2000, epsilon 0.6109173304019418\n",
      "state terminated\n",
      "episode 2465, reward 1047.0, memory_length 2000, epsilon 0.6107951611531935\n",
      "state terminated\n",
      "episode 2466, reward 1288.0, memory_length 2000, epsilon 0.6106730163358518\n",
      "state terminated\n",
      "episode 2467, reward 1044.0, memory_length 2000, epsilon 0.6105508959450308\n",
      "state terminated\n",
      "episode 2468, reward 1059.0, memory_length 2000, epsilon 0.6104287999758456\n",
      "state terminated\n",
      "episode 2469, reward 1232.0, memory_length 2000, epsilon 0.6103067284234126\n",
      "state terminated\n",
      "episode 2470, reward 1516.0, memory_length 2000, epsilon 0.6101846812828489\n",
      "state terminated\n",
      "episode 2471, reward 818.0, memory_length 2000, epsilon 0.6100626585492724\n",
      "state terminated\n",
      "episode 2472, reward 1111.0, memory_length 2000, epsilon 0.6099406602178024\n",
      "state terminated\n",
      "episode 2473, reward 1190.0, memory_length 2000, epsilon 0.6098186862835588\n",
      "state terminated\n",
      "episode 2474, reward 1126.0, memory_length 2000, epsilon 0.6096967367416628\n",
      "state terminated\n",
      "episode 2475, reward 809.0, memory_length 2000, epsilon 0.6095748115872363\n",
      "state terminated\n",
      "episode 2476, reward 1016.0, memory_length 2000, epsilon 0.6094529108154023\n",
      "state terminated\n",
      "episode 2477, reward 1278.0, memory_length 2000, epsilon 0.609331034421285\n",
      "state terminated\n",
      "episode 2478, reward 819.0, memory_length 2000, epsilon 0.609209182400009\n",
      "state terminated\n",
      "episode 2479, reward 1120.0, memory_length 2000, epsilon 0.6090873547467004\n",
      "state terminated\n",
      "episode 2480, reward 1223.0, memory_length 2000, epsilon 0.6089655514564861\n",
      "state terminated\n",
      "episode 2481, reward 1087.0, memory_length 2000, epsilon 0.608843772524494\n",
      "state terminated\n",
      "episode 2482, reward 1385.0, memory_length 2000, epsilon 0.6087220179458528\n",
      "state terminated\n",
      "episode 2483, reward 1179.0, memory_length 2000, epsilon 0.6086002877156924\n",
      "state terminated\n",
      "episode 2484, reward 1343.0, memory_length 2000, epsilon 0.6084785818291436\n",
      "state terminated\n",
      "episode 2485, reward 702.0, memory_length 2000, epsilon 0.6083569002813382\n",
      "state terminated\n",
      "episode 2486, reward 1167.0, memory_length 2000, epsilon 0.6082352430674087\n",
      "state terminated\n",
      "episode 2487, reward 769.0, memory_length 2000, epsilon 0.6081136101824892\n",
      "state terminated\n",
      "episode 2488, reward 1293.0, memory_length 2000, epsilon 0.6079920016217142\n",
      "state terminated\n",
      "episode 2489, reward 1008.0, memory_length 2000, epsilon 0.6078704173802193\n",
      "state terminated\n",
      "episode 2490, reward 1042.0, memory_length 2000, epsilon 0.6077488574531411\n",
      "state terminated\n",
      "episode 2491, reward 891.0, memory_length 2000, epsilon 0.6076273218356174\n",
      "state terminated\n",
      "episode 2492, reward 918.0, memory_length 2000, epsilon 0.6075058105227865\n",
      "state terminated\n",
      "episode 2493, reward 729.0, memory_length 2000, epsilon 0.6073843235097882\n",
      "state terminated\n",
      "episode 2494, reward 1444.0, memory_length 2000, epsilon 0.607262860791763\n",
      "state terminated\n",
      "episode 2495, reward 936.0, memory_length 2000, epsilon 0.6071414223638523\n",
      "state terminated\n",
      "episode 2496, reward 1252.0, memory_length 2000, epsilon 0.6070200082211984\n",
      "state terminated\n",
      "episode 2497, reward 1159.0, memory_length 2000, epsilon 0.606898618358945\n",
      "state terminated\n",
      "episode 2498, reward 1152.0, memory_length 2000, epsilon 0.6067772527722365\n",
      "state terminated\n",
      "episode 2499, reward 1356.0, memory_length 2000, epsilon 0.6066559114562181\n",
      "state terminated\n",
      "episode 2500, reward 1301.0, memory_length 2000, epsilon 0.6065345944060363\n",
      "state terminated\n",
      "episode 2501, reward 1057.0, memory_length 2000, epsilon 0.6064133016168383\n",
      "state terminated\n",
      "episode 2502, reward 1215.0, memory_length 2000, epsilon 0.6062920330837724\n",
      "state terminated\n",
      "episode 2503, reward 1120.0, memory_length 2000, epsilon 0.606170788801988\n",
      "state terminated\n",
      "episode 2504, reward 856.0, memory_length 2000, epsilon 0.6060495687666352\n",
      "state terminated\n",
      "episode 2505, reward 1309.0, memory_length 2000, epsilon 0.6059283729728653\n",
      "state terminated\n",
      "episode 2506, reward 1209.0, memory_length 2000, epsilon 0.6058072014158303\n",
      "state terminated\n",
      "episode 2507, reward 1088.0, memory_length 2000, epsilon 0.6056860540906834\n",
      "state terminated\n",
      "episode 2508, reward 920.0, memory_length 2000, epsilon 0.6055649309925789\n",
      "state terminated\n",
      "episode 2509, reward 1362.0, memory_length 2000, epsilon 0.6054438321166716\n",
      "state terminated\n",
      "episode 2510, reward 1323.0, memory_length 2000, epsilon 0.6053227574581178\n",
      "state terminated\n",
      "episode 2511, reward 1172.0, memory_length 2000, epsilon 0.6052017070120742\n",
      "state terminated\n",
      "episode 2512, reward 1214.0, memory_length 2000, epsilon 0.605080680773699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2513, reward 1494.0, memory_length 2000, epsilon 0.6049596787381513\n",
      "state terminated\n",
      "episode 2514, reward 826.0, memory_length 2000, epsilon 0.6048387009005907\n",
      "state terminated\n",
      "episode 2515, reward 979.0, memory_length 2000, epsilon 0.6047177472561781\n",
      "state terminated\n",
      "episode 2516, reward 1660.0, memory_length 2000, epsilon 0.6045968178000756\n",
      "state terminated\n",
      "episode 2517, reward 1151.0, memory_length 2000, epsilon 0.6044759125274458\n",
      "state terminated\n",
      "episode 2518, reward 979.0, memory_length 2000, epsilon 0.6043550314334527\n",
      "state terminated\n",
      "episode 2519, reward 1207.0, memory_length 2000, epsilon 0.6042341745132608\n",
      "state terminated\n",
      "episode 2520, reward 1326.0, memory_length 2000, epsilon 0.6041133417620361\n",
      "state terminated\n",
      "episode 2521, reward 1179.0, memory_length 2000, epsilon 0.6039925331749452\n",
      "state terminated\n",
      "episode 2522, reward 1124.0, memory_length 2000, epsilon 0.6038717487471555\n",
      "state terminated\n",
      "episode 2523, reward 1197.0, memory_length 2000, epsilon 0.6037509884738359\n",
      "state terminated\n",
      "episode 2524, reward 1288.0, memory_length 2000, epsilon 0.603630252350156\n",
      "state terminated\n",
      "episode 2525, reward 971.0, memory_length 2000, epsilon 0.6035095403712862\n",
      "state terminated\n",
      "episode 2526, reward 1023.0, memory_length 2000, epsilon 0.6033888525323982\n",
      "state terminated\n",
      "episode 2527, reward 1285.0, memory_length 2000, epsilon 0.6032681888286643\n",
      "state terminated\n",
      "episode 2528, reward 1214.0, memory_length 2000, epsilon 0.6031475492552579\n",
      "state terminated\n",
      "episode 2529, reward 1470.0, memory_length 2000, epsilon 0.6030269338073538\n",
      "state terminated\n",
      "episode 2530, reward 1041.0, memory_length 2000, epsilon 0.602906342480127\n",
      "state terminated\n",
      "episode 2531, reward 960.0, memory_length 2000, epsilon 0.6027857752687541\n",
      "state terminated\n",
      "episode 2532, reward 1371.0, memory_length 2000, epsilon 0.6026652321684122\n",
      "state terminated\n",
      "episode 2533, reward 761.0, memory_length 2000, epsilon 0.6025447131742795\n",
      "state terminated\n",
      "episode 2534, reward 1185.0, memory_length 2000, epsilon 0.6024242182815357\n",
      "state terminated\n",
      "episode 2535, reward 1324.0, memory_length 2000, epsilon 0.6023037474853605\n",
      "state terminated\n",
      "episode 2536, reward 1134.0, memory_length 2000, epsilon 0.6021833007809354\n",
      "state terminated\n",
      "episode 2537, reward 958.0, memory_length 2000, epsilon 0.6020628781634424\n",
      "state terminated\n",
      "episode 2538, reward 995.0, memory_length 2000, epsilon 0.6019424796280645\n",
      "state terminated\n",
      "episode 2539, reward 945.0, memory_length 2000, epsilon 0.601822105169986\n",
      "state terminated\n",
      "episode 2540, reward 1251.0, memory_length 2000, epsilon 0.6017017547843917\n",
      "state terminated\n",
      "episode 2541, reward 1110.0, memory_length 2000, epsilon 0.6015814284664678\n",
      "state terminated\n",
      "episode 2542, reward 1008.0, memory_length 2000, epsilon 0.6014611262114009\n",
      "state terminated\n",
      "episode 2543, reward 1288.0, memory_length 2000, epsilon 0.6013408480143793\n",
      "state terminated\n",
      "episode 2544, reward 838.0, memory_length 2000, epsilon 0.6012205938705917\n",
      "state terminated\n",
      "episode 2545, reward 1061.0, memory_length 2000, epsilon 0.6011003637752278\n",
      "state terminated\n",
      "episode 2546, reward 1029.0, memory_length 2000, epsilon 0.6009801577234786\n",
      "state terminated\n",
      "episode 2547, reward 1182.0, memory_length 2000, epsilon 0.6008599757105358\n",
      "state terminated\n",
      "episode 2548, reward 1454.0, memory_length 2000, epsilon 0.6007398177315921\n",
      "state terminated\n",
      "episode 2549, reward 1101.0, memory_length 2000, epsilon 0.6006196837818413\n",
      "state terminated\n",
      "episode 2550, reward 990.0, memory_length 2000, epsilon 0.6004995738564778\n",
      "state terminated\n",
      "episode 2551, reward 985.0, memory_length 2000, epsilon 0.6003794879506974\n",
      "state terminated\n",
      "episode 2552, reward 1097.0, memory_length 2000, epsilon 0.6002594260596965\n",
      "state terminated\n",
      "episode 2553, reward 999.0, memory_length 2000, epsilon 0.6001393881786729\n",
      "state terminated\n",
      "episode 2554, reward 927.0, memory_length 2000, epsilon 0.6000193743028247\n",
      "state terminated\n",
      "episode 2555, reward 1165.0, memory_length 2000, epsilon 0.5998993844273517\n",
      "state terminated\n",
      "episode 2556, reward 1333.0, memory_length 2000, epsilon 0.5997794185474541\n",
      "state terminated\n",
      "episode 2557, reward 938.0, memory_length 2000, epsilon 0.5996594766583333\n",
      "state terminated\n",
      "episode 2558, reward 1192.0, memory_length 2000, epsilon 0.5995395587551916\n",
      "state terminated\n",
      "episode 2559, reward 1175.0, memory_length 2000, epsilon 0.5994196648332325\n",
      "state terminated\n",
      "episode 2560, reward 1251.0, memory_length 2000, epsilon 0.5992997948876599\n",
      "state terminated\n",
      "episode 2561, reward 1034.0, memory_length 2000, epsilon 0.5991799489136793\n",
      "state terminated\n",
      "episode 2562, reward 1422.0, memory_length 2000, epsilon 0.5990601269064967\n",
      "state terminated\n",
      "episode 2563, reward 1386.0, memory_length 2000, epsilon 0.5989403288613192\n",
      "state terminated\n",
      "episode 2564, reward 1065.0, memory_length 2000, epsilon 0.5988205547733549\n",
      "state terminated\n",
      "episode 2565, reward 1084.0, memory_length 2000, epsilon 0.5987008046378132\n",
      "state terminated\n",
      "episode 2566, reward 1105.0, memory_length 2000, epsilon 0.5985810784499034\n",
      "state terminated\n",
      "episode 2567, reward 1313.0, memory_length 2000, epsilon 0.5984613762048369\n",
      "state terminated\n",
      "episode 2568, reward 1354.0, memory_length 2000, epsilon 0.5983416978978255\n",
      "state terminated\n",
      "episode 2569, reward 1151.0, memory_length 2000, epsilon 0.5982220435240821\n",
      "state terminated\n",
      "episode 2570, reward 1133.0, memory_length 2000, epsilon 0.5981024130788207\n",
      "state terminated\n",
      "episode 2571, reward 957.0, memory_length 2000, epsilon 0.5979828065572558\n",
      "state terminated\n",
      "episode 2572, reward 1137.0, memory_length 2000, epsilon 0.5978632239546031\n",
      "state terminated\n",
      "episode 2573, reward 1317.0, memory_length 2000, epsilon 0.5977436652660797\n",
      "state terminated\n",
      "episode 2574, reward 778.0, memory_length 2000, epsilon 0.5976241304869028\n",
      "state terminated\n",
      "episode 2575, reward 1089.0, memory_length 2000, epsilon 0.5975046196122913\n",
      "state terminated\n",
      "episode 2576, reward 1176.0, memory_length 2000, epsilon 0.5973851326374646\n",
      "state terminated\n",
      "episode 2577, reward 1089.0, memory_length 2000, epsilon 0.5972656695576433\n",
      "state terminated\n",
      "episode 2578, reward 1461.0, memory_length 2000, epsilon 0.5971462303680488\n",
      "state terminated\n",
      "episode 2579, reward 1288.0, memory_length 2000, epsilon 0.5970268150639038\n",
      "state terminated\n",
      "episode 2580, reward 1172.0, memory_length 2000, epsilon 0.5969074236404313\n",
      "state terminated\n",
      "episode 2581, reward 1075.0, memory_length 2000, epsilon 0.5967880560928558\n",
      "state terminated\n",
      "episode 2582, reward 1322.0, memory_length 2000, epsilon 0.5966687124164027\n",
      "state terminated\n",
      "episode 2583, reward 1138.0, memory_length 2000, epsilon 0.5965493926062981\n",
      "state terminated\n",
      "episode 2584, reward 1467.0, memory_length 2000, epsilon 0.5964300966577694\n",
      "state terminated\n",
      "episode 2585, reward 1366.0, memory_length 2000, epsilon 0.5963108245660447\n",
      "state terminated\n",
      "episode 2586, reward 1487.0, memory_length 2000, epsilon 0.5961915763263528\n",
      "state terminated\n",
      "episode 2587, reward 1242.0, memory_length 2000, epsilon 0.5960723519339243\n",
      "state terminated\n",
      "episode 2588, reward 1314.0, memory_length 2000, epsilon 0.5959531513839897\n",
      "state terminated\n",
      "episode 2589, reward 1022.0, memory_length 2000, epsilon 0.5958339746717815\n",
      "state terminated\n",
      "episode 2590, reward 1246.0, memory_length 2000, epsilon 0.5957148217925322\n",
      "state terminated\n",
      "episode 2591, reward 1053.0, memory_length 2000, epsilon 0.595595692741476\n",
      "state terminated\n",
      "episode 2592, reward 1004.0, memory_length 2000, epsilon 0.5954765875138474\n",
      "state terminated\n",
      "episode 2593, reward 967.0, memory_length 2000, epsilon 0.5953575061048825\n",
      "state terminated\n",
      "episode 2594, reward 1132.0, memory_length 2000, epsilon 0.5952384485098179\n",
      "state terminated\n",
      "episode 2595, reward 1504.0, memory_length 2000, epsilon 0.5951194147238913\n",
      "state terminated\n",
      "episode 2596, reward 1275.0, memory_length 2000, epsilon 0.5950004047423413\n",
      "state terminated\n",
      "episode 2597, reward 918.0, memory_length 2000, epsilon 0.5948814185604077\n",
      "state terminated\n",
      "episode 2598, reward 1116.0, memory_length 2000, epsilon 0.5947624561733309\n",
      "state terminated\n",
      "episode 2599, reward 764.0, memory_length 2000, epsilon 0.5946435175763524\n",
      "state terminated\n",
      "episode 2600, reward 1222.0, memory_length 2000, epsilon 0.5945246027647146\n",
      "state terminated\n",
      "episode 2601, reward 1264.0, memory_length 2000, epsilon 0.5944057117336611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2602, reward 1214.0, memory_length 2000, epsilon 0.5942868444784362\n",
      "state terminated\n",
      "episode 2603, reward 1203.0, memory_length 2000, epsilon 0.5941680009942849\n",
      "state terminated\n",
      "episode 2604, reward 1141.0, memory_length 2000, epsilon 0.5940491812764539\n",
      "state terminated\n",
      "episode 2605, reward 1503.0, memory_length 2000, epsilon 0.5939303853201903\n",
      "state terminated\n",
      "episode 2606, reward 1351.0, memory_length 2000, epsilon 0.593811613120742\n",
      "state terminated\n",
      "episode 2607, reward 1169.0, memory_length 2000, epsilon 0.5936928646733586\n",
      "state terminated\n",
      "episode 2608, reward 1406.0, memory_length 2000, epsilon 0.5935741399732896\n",
      "state terminated\n",
      "episode 2609, reward 1140.0, memory_length 2000, epsilon 0.5934554390157863\n",
      "state terminated\n",
      "episode 2610, reward 993.0, memory_length 2000, epsilon 0.5933367617961007\n",
      "state terminated\n",
      "episode 2611, reward 1395.0, memory_length 2000, epsilon 0.5932181083094857\n",
      "state terminated\n",
      "episode 2612, reward 1365.0, memory_length 2000, epsilon 0.593099478551195\n",
      "state terminated\n",
      "episode 2613, reward 1215.0, memory_length 2000, epsilon 0.5929808725164836\n",
      "state terminated\n",
      "episode 2614, reward 1322.0, memory_length 2000, epsilon 0.5928622902006072\n",
      "state terminated\n",
      "episode 2615, reward 1109.0, memory_length 2000, epsilon 0.5927437315988225\n",
      "state terminated\n",
      "episode 2616, reward 1212.0, memory_length 2000, epsilon 0.592625196706387\n",
      "state terminated\n",
      "episode 2617, reward 882.0, memory_length 2000, epsilon 0.5925066855185597\n",
      "state terminated\n",
      "episode 2618, reward 1080.0, memory_length 2000, epsilon 0.5923881980305996\n",
      "state terminated\n",
      "episode 2619, reward 1458.0, memory_length 2000, epsilon 0.5922697342377676\n",
      "state terminated\n",
      "episode 2620, reward 1516.0, memory_length 2000, epsilon 0.5921512941353252\n",
      "state terminated\n",
      "episode 2621, reward 1479.0, memory_length 2000, epsilon 0.5920328777185345\n",
      "state terminated\n",
      "episode 2622, reward 1230.0, memory_length 2000, epsilon 0.5919144849826591\n",
      "state terminated\n",
      "episode 2623, reward 1296.0, memory_length 2000, epsilon 0.591796115922963\n",
      "state terminated\n",
      "episode 2624, reward 827.0, memory_length 2000, epsilon 0.5916777705347118\n",
      "state terminated\n",
      "episode 2625, reward 1134.0, memory_length 2000, epsilon 0.5915594488131715\n",
      "state terminated\n",
      "episode 2626, reward 1349.0, memory_length 2000, epsilon 0.591441150753609\n",
      "state terminated\n",
      "episode 2627, reward 1554.0, memory_length 2000, epsilon 0.5913228763512929\n",
      "state terminated\n",
      "episode 2628, reward 1264.0, memory_length 2000, epsilon 0.5912046256014917\n",
      "state terminated\n",
      "episode 2629, reward 1062.0, memory_length 2000, epsilon 0.5910863984994756\n",
      "state terminated\n",
      "episode 2630, reward 1331.0, memory_length 2000, epsilon 0.5909681950405158\n",
      "state terminated\n",
      "episode 2631, reward 1217.0, memory_length 2000, epsilon 0.5908500152198836\n",
      "state terminated\n",
      "episode 2632, reward 1262.0, memory_length 2000, epsilon 0.5907318590328522\n",
      "state terminated\n",
      "episode 2633, reward 1097.0, memory_length 2000, epsilon 0.5906137264746951\n",
      "state terminated\n",
      "episode 2634, reward 1335.0, memory_length 2000, epsilon 0.5904956175406872\n",
      "state terminated\n",
      "episode 2635, reward 967.0, memory_length 2000, epsilon 0.5903775322261042\n",
      "state terminated\n",
      "episode 2636, reward 1385.0, memory_length 2000, epsilon 0.5902594705262226\n",
      "state terminated\n",
      "episode 2637, reward 940.0, memory_length 2000, epsilon 0.5901414324363198\n",
      "state terminated\n",
      "episode 2638, reward 1197.0, memory_length 2000, epsilon 0.5900234179516743\n",
      "state terminated\n",
      "episode 2639, reward 1366.0, memory_length 2000, epsilon 0.5899054270675658\n",
      "state terminated\n",
      "episode 2640, reward 1547.0, memory_length 2000, epsilon 0.5897874597792743\n",
      "state terminated\n",
      "episode 2641, reward 989.0, memory_length 2000, epsilon 0.5896695160820813\n",
      "state terminated\n",
      "episode 2642, reward 1420.0, memory_length 2000, epsilon 0.589551595971269\n",
      "state terminated\n",
      "episode 2643, reward 1155.0, memory_length 2000, epsilon 0.5894336994421207\n",
      "state terminated\n",
      "episode 2644, reward 687.0, memory_length 2000, epsilon 0.5893158264899204\n",
      "state terminated\n",
      "episode 2645, reward 1077.0, memory_length 2000, epsilon 0.5891979771099531\n",
      "state terminated\n",
      "episode 2646, reward 1047.0, memory_length 2000, epsilon 0.5890801512975052\n",
      "state terminated\n",
      "episode 2647, reward 1278.0, memory_length 2000, epsilon 0.5889623490478635\n",
      "state terminated\n",
      "episode 2648, reward 1206.0, memory_length 2000, epsilon 0.5888445703563155\n",
      "state terminated\n",
      "episode 2649, reward 1395.0, memory_length 2000, epsilon 0.5887268152181506\n",
      "state terminated\n",
      "episode 2650, reward 1582.0, memory_length 2000, epsilon 0.5886090836286584\n",
      "state terminated\n",
      "episode 2651, reward 1196.0, memory_length 2000, epsilon 0.5884913755831296\n",
      "state terminated\n",
      "episode 2652, reward 1045.0, memory_length 2000, epsilon 0.5883736910768559\n",
      "state terminated\n",
      "episode 2653, reward 982.0, memory_length 2000, epsilon 0.5882560301051298\n",
      "state terminated\n",
      "episode 2654, reward 880.0, memory_length 2000, epsilon 0.5881383926632451\n",
      "state terminated\n",
      "episode 2655, reward 1599.0, memory_length 2000, epsilon 0.5880207787464963\n",
      "state terminated\n",
      "episode 2656, reward 1433.0, memory_length 2000, epsilon 0.5879031883501785\n",
      "state terminated\n",
      "episode 2657, reward 1163.0, memory_length 2000, epsilon 0.5877856214695885\n",
      "state terminated\n",
      "episode 2658, reward 821.0, memory_length 2000, epsilon 0.5876680781000233\n",
      "state terminated\n",
      "episode 2659, reward 1282.0, memory_length 2000, epsilon 0.5875505582367814\n",
      "state terminated\n",
      "episode 2660, reward 1301.0, memory_length 2000, epsilon 0.5874330618751618\n",
      "state terminated\n",
      "episode 2661, reward 1267.0, memory_length 2000, epsilon 0.5873155890104649\n",
      "state terminated\n",
      "episode 2662, reward 1415.0, memory_length 2000, epsilon 0.5871981396379914\n",
      "state terminated\n",
      "episode 2663, reward 1543.0, memory_length 2000, epsilon 0.5870807137530438\n",
      "state terminated\n",
      "episode 2664, reward 1215.0, memory_length 2000, epsilon 0.5869633113509247\n",
      "state terminated\n",
      "episode 2665, reward 1358.0, memory_length 2000, epsilon 0.5868459324269382\n",
      "state terminated\n",
      "episode 2666, reward 984.0, memory_length 2000, epsilon 0.586728576976389\n",
      "state terminated\n",
      "episode 2667, reward 863.0, memory_length 2000, epsilon 0.5866112449945831\n",
      "state terminated\n",
      "episode 2668, reward 1128.0, memory_length 2000, epsilon 0.5864939364768269\n",
      "state terminated\n",
      "episode 2669, reward 1162.0, memory_length 2000, epsilon 0.5863766514184283\n",
      "state terminated\n",
      "episode 2670, reward 889.0, memory_length 2000, epsilon 0.5862593898146959\n",
      "state terminated\n",
      "episode 2671, reward 841.0, memory_length 2000, epsilon 0.5861421516609392\n",
      "state terminated\n",
      "episode 2672, reward 1213.0, memory_length 2000, epsilon 0.5860249369524686\n",
      "state terminated\n",
      "episode 2673, reward 1367.0, memory_length 2000, epsilon 0.5859077456845954\n",
      "state terminated\n",
      "episode 2674, reward 1348.0, memory_length 2000, epsilon 0.5857905778526323\n",
      "state terminated\n",
      "episode 2675, reward 1406.0, memory_length 2000, epsilon 0.5856734334518923\n",
      "state terminated\n",
      "episode 2676, reward 1498.0, memory_length 2000, epsilon 0.5855563124776898\n",
      "state terminated\n",
      "episode 2677, reward 1208.0, memory_length 2000, epsilon 0.5854392149253398\n",
      "state terminated\n",
      "episode 2678, reward 1046.0, memory_length 2000, epsilon 0.5853221407901585\n",
      "state terminated\n",
      "episode 2679, reward 999.0, memory_length 2000, epsilon 0.5852050900674629\n",
      "state terminated\n",
      "episode 2680, reward 883.0, memory_length 2000, epsilon 0.585088062752571\n",
      "state terminated\n",
      "episode 2681, reward 1313.0, memory_length 2000, epsilon 0.5849710588408016\n",
      "state terminated\n",
      "episode 2682, reward 1188.0, memory_length 2000, epsilon 0.5848540783274748\n",
      "state terminated\n",
      "episode 2683, reward 1077.0, memory_length 2000, epsilon 0.5847371212079111\n",
      "state terminated\n",
      "episode 2684, reward 982.0, memory_length 2000, epsilon 0.5846201874774323\n",
      "state terminated\n",
      "episode 2685, reward 1110.0, memory_length 2000, epsilon 0.5845032771313611\n",
      "state terminated\n",
      "episode 2686, reward 1324.0, memory_length 2000, epsilon 0.5843863901650211\n",
      "state terminated\n",
      "episode 2687, reward 1189.0, memory_length 2000, epsilon 0.5842695265737368\n",
      "state terminated\n",
      "episode 2688, reward 1452.0, memory_length 2000, epsilon 0.5841526863528336\n",
      "state terminated\n",
      "episode 2689, reward 1297.0, memory_length 2000, epsilon 0.5840358694976379\n",
      "state terminated\n",
      "episode 2690, reward 1651.0, memory_length 2000, epsilon 0.5839190760034771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2691, reward 1222.0, memory_length 2000, epsilon 0.5838023058656794\n",
      "state terminated\n",
      "episode 2692, reward 1417.0, memory_length 2000, epsilon 0.5836855590795741\n",
      "state terminated\n",
      "episode 2693, reward 972.0, memory_length 2000, epsilon 0.5835688356404911\n",
      "state terminated\n",
      "episode 2694, reward 1527.0, memory_length 2000, epsilon 0.5834521355437616\n",
      "state terminated\n",
      "episode 2695, reward 1296.0, memory_length 2000, epsilon 0.5833354587847178\n",
      "state terminated\n",
      "episode 2696, reward 1138.0, memory_length 2000, epsilon 0.5832188053586923\n",
      "state terminated\n",
      "episode 2697, reward 706.0, memory_length 2000, epsilon 0.5831021752610192\n",
      "state terminated\n",
      "episode 2698, reward 809.0, memory_length 2000, epsilon 0.582985568487033\n",
      "state terminated\n",
      "episode 2699, reward 1194.0, memory_length 2000, epsilon 0.5828689850320696\n",
      "state terminated\n",
      "episode 2700, reward 1007.0, memory_length 2000, epsilon 0.5827524248914658\n",
      "state terminated\n",
      "episode 2701, reward 1044.0, memory_length 2000, epsilon 0.5826358880605592\n",
      "state terminated\n",
      "episode 2702, reward 1390.0, memory_length 2000, epsilon 0.5825193745346879\n",
      "state terminated\n",
      "episode 2703, reward 1083.0, memory_length 2000, epsilon 0.5824028843091918\n",
      "state terminated\n",
      "episode 2704, reward 1701.0, memory_length 2000, epsilon 0.5822864173794112\n",
      "state terminated\n",
      "episode 2705, reward 1435.0, memory_length 2000, epsilon 0.5821699737406875\n",
      "state terminated\n",
      "episode 2706, reward 1217.0, memory_length 2000, epsilon 0.5820535533883626\n",
      "state terminated\n",
      "episode 2707, reward 1446.0, memory_length 2000, epsilon 0.58193715631778\n",
      "state terminated\n",
      "episode 2708, reward 1312.0, memory_length 2000, epsilon 0.5818207825242836\n",
      "state terminated\n",
      "episode 2709, reward 1327.0, memory_length 2000, epsilon 0.5817044320032188\n",
      "state terminated\n",
      "episode 2710, reward 1182.0, memory_length 2000, epsilon 0.5815881047499312\n",
      "state terminated\n",
      "episode 2711, reward 1155.0, memory_length 2000, epsilon 0.5814718007597679\n",
      "state terminated\n",
      "episode 2712, reward 972.0, memory_length 2000, epsilon 0.5813555200280767\n",
      "state terminated\n",
      "episode 2713, reward 1068.0, memory_length 2000, epsilon 0.5812392625502064\n",
      "state terminated\n",
      "episode 2714, reward 1336.0, memory_length 2000, epsilon 0.5811230283215066\n",
      "state terminated\n",
      "episode 2715, reward 1134.0, memory_length 2000, epsilon 0.5810068173373282\n",
      "state terminated\n",
      "episode 2716, reward 1623.0, memory_length 2000, epsilon 0.5808906295930225\n",
      "state terminated\n",
      "episode 2717, reward 1083.0, memory_length 2000, epsilon 0.5807744650839419\n",
      "state terminated\n",
      "episode 2718, reward 1224.0, memory_length 2000, epsilon 0.5806583238054401\n",
      "state terminated\n",
      "episode 2719, reward 1011.0, memory_length 2000, epsilon 0.5805422057528714\n",
      "state terminated\n",
      "episode 2720, reward 1236.0, memory_length 2000, epsilon 0.5804261109215909\n",
      "state terminated\n",
      "episode 2721, reward 1402.0, memory_length 2000, epsilon 0.5803100393069549\n",
      "state terminated\n",
      "episode 2722, reward 1332.0, memory_length 2000, epsilon 0.5801939909043207\n",
      "state terminated\n",
      "episode 2723, reward 891.0, memory_length 2000, epsilon 0.5800779657090461\n",
      "state terminated\n",
      "episode 2724, reward 1137.0, memory_length 2000, epsilon 0.5799619637164902\n",
      "state terminated\n",
      "episode 2725, reward 1412.0, memory_length 2000, epsilon 0.579845984922013\n",
      "state terminated\n",
      "episode 2726, reward 890.0, memory_length 2000, epsilon 0.5797300293209752\n",
      "state terminated\n",
      "episode 2727, reward 1173.0, memory_length 2000, epsilon 0.5796140969087387\n",
      "state terminated\n",
      "episode 2728, reward 1138.0, memory_length 2000, epsilon 0.5794981876806661\n",
      "state terminated\n",
      "episode 2729, reward 1345.0, memory_length 2000, epsilon 0.579382301632121\n",
      "state terminated\n",
      "episode 2730, reward 1090.0, memory_length 2000, epsilon 0.5792664387584682\n",
      "state terminated\n",
      "episode 2731, reward 1079.0, memory_length 2000, epsilon 0.579150599055073\n",
      "state terminated\n",
      "episode 2732, reward 1365.0, memory_length 2000, epsilon 0.5790347825173018\n",
      "state terminated\n",
      "episode 2733, reward 1153.0, memory_length 2000, epsilon 0.5789189891405221\n",
      "state terminated\n",
      "episode 2734, reward 1163.0, memory_length 2000, epsilon 0.5788032189201018\n",
      "state terminated\n",
      "episode 2735, reward 1162.0, memory_length 2000, epsilon 0.5786874718514106\n",
      "state terminated\n",
      "episode 2736, reward 1169.0, memory_length 2000, epsilon 0.5785717479298181\n",
      "state terminated\n",
      "episode 2737, reward 1439.0, memory_length 2000, epsilon 0.5784560471506958\n",
      "state terminated\n",
      "episode 2738, reward 931.0, memory_length 2000, epsilon 0.5783403695094154\n",
      "state terminated\n",
      "episode 2739, reward 1327.0, memory_length 2000, epsilon 0.5782247150013498\n",
      "state terminated\n",
      "episode 2740, reward 1228.0, memory_length 2000, epsilon 0.5781090836218729\n",
      "state terminated\n",
      "episode 2741, reward 1277.0, memory_length 2000, epsilon 0.5779934753663595\n",
      "state terminated\n",
      "episode 2742, reward 1511.0, memory_length 2000, epsilon 0.5778778902301851\n",
      "state terminated\n",
      "episode 2743, reward 960.0, memory_length 2000, epsilon 0.5777623282087264\n",
      "state terminated\n",
      "episode 2744, reward 1123.0, memory_length 2000, epsilon 0.5776467892973608\n",
      "state terminated\n",
      "episode 2745, reward 1258.0, memory_length 2000, epsilon 0.577531273491467\n",
      "state terminated\n",
      "episode 2746, reward 1461.0, memory_length 2000, epsilon 0.5774157807864242\n",
      "state terminated\n",
      "episode 2747, reward 936.0, memory_length 2000, epsilon 0.5773003111776127\n",
      "state terminated\n",
      "episode 2748, reward 1227.0, memory_length 2000, epsilon 0.5771848646604139\n",
      "state terminated\n",
      "episode 2749, reward 1120.0, memory_length 2000, epsilon 0.5770694412302094\n",
      "state terminated\n",
      "episode 2750, reward 1363.0, memory_length 2000, epsilon 0.5769540408823828\n",
      "state terminated\n",
      "episode 2751, reward 1229.0, memory_length 2000, epsilon 0.576838663612318\n",
      "state terminated\n",
      "episode 2752, reward 1153.0, memory_length 2000, epsilon 0.5767233094153997\n",
      "state terminated\n",
      "episode 2753, reward 1492.0, memory_length 2000, epsilon 0.5766079782870139\n",
      "state terminated\n",
      "episode 2754, reward 1005.0, memory_length 2000, epsilon 0.5764926702225474\n",
      "state terminated\n",
      "episode 2755, reward 1324.0, memory_length 2000, epsilon 0.5763773852173877\n",
      "state terminated\n",
      "episode 2756, reward 1267.0, memory_length 2000, epsilon 0.5762621232669234\n",
      "state terminated\n",
      "episode 2757, reward 1371.0, memory_length 2000, epsilon 0.5761468843665442\n",
      "state terminated\n",
      "episode 2758, reward 1316.0, memory_length 2000, epsilon 0.5760316685116404\n",
      "state terminated\n",
      "episode 2759, reward 943.0, memory_length 2000, epsilon 0.5759164756976035\n",
      "state terminated\n",
      "episode 2760, reward 1349.0, memory_length 2000, epsilon 0.5758013059198256\n",
      "state terminated\n",
      "episode 2761, reward 989.0, memory_length 2000, epsilon 0.5756861591737\n",
      "state terminated\n",
      "episode 2762, reward 1225.0, memory_length 2000, epsilon 0.5755710354546211\n",
      "state terminated\n",
      "episode 2763, reward 1026.0, memory_length 2000, epsilon 0.5754559347579834\n",
      "state terminated\n",
      "episode 2764, reward 1525.0, memory_length 2000, epsilon 0.5753408570791833\n",
      "state terminated\n",
      "episode 2765, reward 1087.0, memory_length 2000, epsilon 0.5752258024136175\n",
      "state terminated\n",
      "episode 2766, reward 1161.0, memory_length 2000, epsilon 0.5751107707566839\n",
      "state terminated\n",
      "episode 2767, reward 879.0, memory_length 2000, epsilon 0.5749957621037812\n",
      "state terminated\n",
      "episode 2768, reward 1130.0, memory_length 2000, epsilon 0.5748807764503091\n",
      "state terminated\n",
      "episode 2769, reward 1093.0, memory_length 2000, epsilon 0.5747658137916681\n",
      "state terminated\n",
      "episode 2770, reward 1691.0, memory_length 2000, epsilon 0.5746508741232598\n",
      "state terminated\n",
      "episode 2771, reward 1296.0, memory_length 2000, epsilon 0.5745359574404865\n",
      "state terminated\n",
      "episode 2772, reward 1030.0, memory_length 2000, epsilon 0.5744210637387515\n",
      "state terminated\n",
      "episode 2773, reward 1173.0, memory_length 2000, epsilon 0.5743061930134592\n",
      "state terminated\n",
      "episode 2774, reward 890.0, memory_length 2000, epsilon 0.5741913452600146\n",
      "state terminated\n",
      "episode 2775, reward 1129.0, memory_length 2000, epsilon 0.574076520473824\n",
      "state terminated\n",
      "episode 2776, reward 1525.0, memory_length 2000, epsilon 0.5739617186502942\n",
      "state terminated\n",
      "episode 2777, reward 1507.0, memory_length 2000, epsilon 0.5738469397848334\n",
      "state terminated\n",
      "episode 2778, reward 1227.0, memory_length 2000, epsilon 0.5737321838728502\n",
      "state terminated\n",
      "episode 2779, reward 1206.0, memory_length 2000, epsilon 0.5736174509097542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2780, reward 639.0, memory_length 2000, epsilon 0.5735027408909565\n",
      "state terminated\n",
      "episode 2781, reward 1532.0, memory_length 2000, epsilon 0.5733880538118685\n",
      "state terminated\n",
      "episode 2782, reward 1080.0, memory_length 2000, epsilon 0.5732733896679028\n",
      "state terminated\n",
      "episode 2783, reward 1171.0, memory_length 2000, epsilon 0.5731587484544728\n",
      "state terminated\n",
      "episode 2784, reward 1300.0, memory_length 2000, epsilon 0.5730441301669926\n",
      "state terminated\n",
      "episode 2785, reward 1447.0, memory_length 2000, epsilon 0.5729295348008778\n",
      "state terminated\n",
      "episode 2786, reward 1039.0, memory_length 2000, epsilon 0.5728149623515445\n",
      "state terminated\n",
      "episode 2787, reward 1333.0, memory_length 2000, epsilon 0.5727004128144098\n",
      "state terminated\n",
      "episode 2788, reward 1232.0, memory_length 2000, epsilon 0.5725858861848916\n",
      "state terminated\n",
      "episode 2789, reward 1455.0, memory_length 2000, epsilon 0.5724713824584089\n",
      "state terminated\n",
      "episode 2790, reward 1133.0, memory_length 2000, epsilon 0.5723569016303817\n",
      "state terminated\n",
      "episode 2791, reward 724.0, memory_length 2000, epsilon 0.5722424436962306\n",
      "state terminated\n",
      "episode 2792, reward 1237.0, memory_length 2000, epsilon 0.5721280086513773\n",
      "state terminated\n",
      "episode 2793, reward 1362.0, memory_length 2000, epsilon 0.5720135964912444\n",
      "state terminated\n",
      "episode 2794, reward 1505.0, memory_length 2000, epsilon 0.5718992072112553\n",
      "state terminated\n",
      "episode 2795, reward 1493.0, memory_length 2000, epsilon 0.5717848408068348\n",
      "state terminated\n",
      "episode 2796, reward 1211.0, memory_length 2000, epsilon 0.5716704972734079\n",
      "state terminated\n",
      "episode 2797, reward 1157.0, memory_length 2000, epsilon 0.571556176606401\n",
      "state terminated\n",
      "episode 2798, reward 1053.0, memory_length 2000, epsilon 0.5714418788012412\n",
      "state terminated\n",
      "episode 2799, reward 1312.0, memory_length 2000, epsilon 0.5713276038533566\n",
      "state terminated\n",
      "episode 2800, reward 943.0, memory_length 2000, epsilon 0.5712133517581763\n",
      "state terminated\n",
      "episode 2801, reward 1409.0, memory_length 2000, epsilon 0.5710991225111302\n",
      "state terminated\n",
      "episode 2802, reward 1429.0, memory_length 2000, epsilon 0.570984916107649\n",
      "state terminated\n",
      "episode 2803, reward 1367.0, memory_length 2000, epsilon 0.5708707325431646\n",
      "state terminated\n",
      "episode 2804, reward 1396.0, memory_length 2000, epsilon 0.5707565718131093\n",
      "state terminated\n",
      "episode 2805, reward 1365.0, memory_length 2000, epsilon 0.5706424339129172\n",
      "state terminated\n",
      "episode 2806, reward 1442.0, memory_length 2000, epsilon 0.5705283188380226\n",
      "state terminated\n",
      "episode 2807, reward 1250.0, memory_length 2000, epsilon 0.5704142265838608\n",
      "state terminated\n",
      "episode 2808, reward 1377.0, memory_length 2000, epsilon 0.570300157145868\n",
      "state terminated\n",
      "episode 2809, reward 1179.0, memory_length 2000, epsilon 0.5701861105194816\n",
      "state terminated\n",
      "episode 2810, reward 1108.0, memory_length 2000, epsilon 0.5700720867001396\n",
      "state terminated\n",
      "episode 2811, reward 1087.0, memory_length 2000, epsilon 0.5699580856832813\n",
      "state terminated\n",
      "episode 2812, reward 1268.0, memory_length 2000, epsilon 0.5698441074643465\n",
      "state terminated\n",
      "episode 2813, reward 1314.0, memory_length 2000, epsilon 0.5697301520387761\n",
      "state terminated\n",
      "episode 2814, reward 966.0, memory_length 2000, epsilon 0.5696162194020117\n",
      "state terminated\n",
      "episode 2815, reward 1273.0, memory_length 2000, epsilon 0.5695023095494962\n",
      "state terminated\n",
      "episode 2816, reward 1132.0, memory_length 2000, epsilon 0.5693884224766733\n",
      "state terminated\n",
      "episode 2817, reward 1245.0, memory_length 2000, epsilon 0.5692745581789873\n",
      "state terminated\n",
      "episode 2818, reward 1566.0, memory_length 2000, epsilon 0.5691607166518837\n",
      "state terminated\n",
      "episode 2819, reward 1300.0, memory_length 2000, epsilon 0.5690468978908088\n",
      "state terminated\n",
      "episode 2820, reward 1273.0, memory_length 2000, epsilon 0.5689331018912099\n",
      "state terminated\n",
      "episode 2821, reward 1142.0, memory_length 2000, epsilon 0.5688193286485351\n",
      "state terminated\n",
      "episode 2822, reward 1593.0, memory_length 2000, epsilon 0.5687055781582337\n",
      "state terminated\n",
      "episode 2823, reward 1547.0, memory_length 2000, epsilon 0.5685918504157554\n",
      "state terminated\n",
      "episode 2824, reward 1376.0, memory_length 2000, epsilon 0.5684781454165512\n",
      "state terminated\n",
      "episode 2825, reward 1284.0, memory_length 2000, epsilon 0.5683644631560728\n",
      "state terminated\n",
      "episode 2826, reward 1407.0, memory_length 2000, epsilon 0.5682508036297732\n",
      "state terminated\n",
      "episode 2827, reward 1111.0, memory_length 2000, epsilon 0.5681371668331057\n",
      "state terminated\n",
      "episode 2828, reward 1376.0, memory_length 2000, epsilon 0.5680235527615249\n",
      "state terminated\n",
      "episode 2829, reward 1299.0, memory_length 2000, epsilon 0.5679099614104862\n",
      "state terminated\n",
      "episode 2830, reward 1456.0, memory_length 2000, epsilon 0.5677963927754462\n",
      "state terminated\n",
      "episode 2831, reward 1188.0, memory_length 2000, epsilon 0.5676828468518621\n",
      "state terminated\n",
      "episode 2832, reward 972.0, memory_length 2000, epsilon 0.5675693236351917\n",
      "state terminated\n",
      "episode 2833, reward 904.0, memory_length 2000, epsilon 0.5674558231208945\n",
      "state terminated\n",
      "episode 2834, reward 1093.0, memory_length 2000, epsilon 0.5673423453044302\n",
      "state terminated\n",
      "episode 2835, reward 1373.0, memory_length 2000, epsilon 0.5672288901812599\n",
      "state terminated\n",
      "episode 2836, reward 1423.0, memory_length 2000, epsilon 0.5671154577468451\n",
      "state terminated\n",
      "episode 2837, reward 1346.0, memory_length 2000, epsilon 0.5670020479966488\n",
      "state terminated\n",
      "episode 2838, reward 1465.0, memory_length 2000, epsilon 0.5668886609261345\n",
      "state terminated\n",
      "episode 2839, reward 1224.0, memory_length 2000, epsilon 0.5667752965307666\n",
      "state terminated\n",
      "episode 2840, reward 998.0, memory_length 2000, epsilon 0.5666619548060108\n",
      "state terminated\n",
      "episode 2841, reward 1118.0, memory_length 2000, epsilon 0.5665486357473333\n",
      "state terminated\n",
      "episode 2842, reward 1244.0, memory_length 2000, epsilon 0.5664353393502011\n",
      "state terminated\n",
      "episode 2843, reward 1445.0, memory_length 2000, epsilon 0.5663220656100826\n",
      "state terminated\n",
      "episode 2844, reward 1133.0, memory_length 2000, epsilon 0.566208814522447\n",
      "state terminated\n",
      "episode 2845, reward 1060.0, memory_length 2000, epsilon 0.5660955860827638\n",
      "state terminated\n",
      "episode 2846, reward 883.0, memory_length 2000, epsilon 0.5659823802865042\n",
      "state terminated\n",
      "episode 2847, reward 1019.0, memory_length 2000, epsilon 0.56586919712914\n",
      "state terminated\n",
      "episode 2848, reward 1483.0, memory_length 2000, epsilon 0.5657560366061436\n",
      "state terminated\n",
      "episode 2849, reward 1530.0, memory_length 2000, epsilon 0.5656428987129889\n",
      "state terminated\n",
      "episode 2850, reward 1119.0, memory_length 2000, epsilon 0.56552978344515\n",
      "state terminated\n",
      "episode 2851, reward 1100.0, memory_length 2000, epsilon 0.5654166907981026\n",
      "state terminated\n",
      "episode 2852, reward 1588.0, memory_length 2000, epsilon 0.5653036207673231\n",
      "state terminated\n",
      "episode 2853, reward 1400.0, memory_length 2000, epsilon 0.5651905733482884\n",
      "state terminated\n",
      "episode 2854, reward 1087.0, memory_length 2000, epsilon 0.5650775485364766\n",
      "state terminated\n",
      "episode 2855, reward 1200.0, memory_length 2000, epsilon 0.5649645463273669\n",
      "state terminated\n",
      "episode 2856, reward 1475.0, memory_length 2000, epsilon 0.5648515667164391\n",
      "state terminated\n",
      "episode 2857, reward 1566.0, memory_length 2000, epsilon 0.5647386096991741\n",
      "state terminated\n",
      "episode 2858, reward 1498.0, memory_length 2000, epsilon 0.5646256752710535\n",
      "state terminated\n",
      "episode 2859, reward 1172.0, memory_length 2000, epsilon 0.5645127634275601\n",
      "state terminated\n",
      "episode 2860, reward 1220.0, memory_length 2000, epsilon 0.564399874164177\n",
      "state terminated\n",
      "episode 2861, reward 1048.0, memory_length 2000, epsilon 0.5642870074763894\n",
      "state terminated\n",
      "episode 2862, reward 1206.0, memory_length 2000, epsilon 0.5641741633596818\n",
      "state terminated\n",
      "episode 2863, reward 1308.0, memory_length 2000, epsilon 0.564061341809541\n",
      "state terminated\n",
      "episode 2864, reward 1336.0, memory_length 2000, epsilon 0.5639485428214539\n",
      "state terminated\n",
      "episode 2865, reward 1557.0, memory_length 2000, epsilon 0.5638357663909086\n",
      "state terminated\n",
      "episode 2866, reward 1249.0, memory_length 2000, epsilon 0.5637230125133941\n",
      "state terminated\n",
      "episode 2867, reward 895.0, memory_length 2000, epsilon 0.5636102811844\n",
      "state terminated\n",
      "episode 2868, reward 1603.0, memory_length 2000, epsilon 0.5634975723994173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2869, reward 1710.0, memory_length 2000, epsilon 0.5633848861539376\n",
      "state terminated\n",
      "episode 2870, reward 1267.0, memory_length 2000, epsilon 0.5632722224434533\n",
      "state terminated\n",
      "episode 2871, reward 1244.0, memory_length 2000, epsilon 0.5631595812634581\n",
      "state terminated\n",
      "episode 2872, reward 1140.0, memory_length 2000, epsilon 0.5630469626094462\n",
      "state terminated\n",
      "episode 2873, reward 1623.0, memory_length 2000, epsilon 0.562934366476913\n",
      "state terminated\n",
      "episode 2874, reward 1512.0, memory_length 2000, epsilon 0.5628217928613544\n",
      "state terminated\n",
      "episode 2875, reward 1173.0, memory_length 2000, epsilon 0.5627092417582676\n",
      "state terminated\n",
      "episode 2876, reward 1012.0, memory_length 2000, epsilon 0.5625967131631505\n",
      "state terminated\n",
      "episode 2877, reward 1148.0, memory_length 2000, epsilon 0.5624842070715022\n",
      "state terminated\n",
      "episode 2878, reward 891.0, memory_length 2000, epsilon 0.562371723478822\n",
      "state terminated\n",
      "episode 2879, reward 1043.0, memory_length 2000, epsilon 0.562259262380611\n",
      "state terminated\n",
      "episode 2880, reward 1332.0, memory_length 2000, epsilon 0.5621468237723705\n",
      "state terminated\n",
      "episode 2881, reward 1348.0, memory_length 2000, epsilon 0.5620344076496029\n",
      "state terminated\n",
      "episode 2882, reward 1465.0, memory_length 2000, epsilon 0.5619220140078118\n",
      "state terminated\n",
      "episode 2883, reward 1386.0, memory_length 2000, epsilon 0.5618096428425015\n",
      "state terminated\n",
      "episode 2884, reward 1572.0, memory_length 2000, epsilon 0.5616972941491768\n",
      "state terminated\n",
      "episode 2885, reward 1443.0, memory_length 2000, epsilon 0.5615849679233439\n",
      "state terminated\n",
      "episode 2886, reward 1044.0, memory_length 2000, epsilon 0.5614726641605099\n",
      "state terminated\n",
      "episode 2887, reward 1168.0, memory_length 2000, epsilon 0.5613603828561825\n",
      "state terminated\n",
      "episode 2888, reward 1248.0, memory_length 2000, epsilon 0.5612481240058704\n",
      "state terminated\n",
      "episode 2889, reward 954.0, memory_length 2000, epsilon 0.5611358876050835\n",
      "state terminated\n",
      "episode 2890, reward 1305.0, memory_length 2000, epsilon 0.561023673649332\n",
      "state terminated\n",
      "episode 2891, reward 1101.0, memory_length 2000, epsilon 0.5609114821341277\n",
      "state terminated\n",
      "episode 2892, reward 1312.0, memory_length 2000, epsilon 0.5607993130549827\n",
      "state terminated\n",
      "episode 2893, reward 1258.0, memory_length 2000, epsilon 0.5606871664074103\n",
      "state terminated\n",
      "episode 2894, reward 1368.0, memory_length 2000, epsilon 0.5605750421869247\n",
      "state terminated\n",
      "episode 2895, reward 1197.0, memory_length 2000, epsilon 0.5604629403890407\n",
      "state terminated\n",
      "episode 2896, reward 1209.0, memory_length 2000, epsilon 0.5603508610092744\n",
      "state terminated\n",
      "episode 2897, reward 1307.0, memory_length 2000, epsilon 0.5602388040431426\n",
      "state terminated\n",
      "episode 2898, reward 1219.0, memory_length 2000, epsilon 0.5601267694861632\n",
      "state terminated\n",
      "episode 2899, reward 1431.0, memory_length 2000, epsilon 0.5600147573338546\n",
      "state terminated\n",
      "episode 2900, reward 1363.0, memory_length 2000, epsilon 0.5599027675817364\n",
      "state terminated\n",
      "episode 2901, reward 1278.0, memory_length 2000, epsilon 0.5597908002253288\n",
      "state terminated\n",
      "episode 2902, reward 1386.0, memory_length 2000, epsilon 0.5596788552601535\n",
      "state terminated\n",
      "episode 2903, reward 1508.0, memory_length 2000, epsilon 0.5595669326817324\n",
      "state terminated\n",
      "episode 2904, reward 1289.0, memory_length 2000, epsilon 0.5594550324855886\n",
      "state terminated\n",
      "episode 2905, reward 1564.0, memory_length 2000, epsilon 0.5593431546672463\n",
      "state terminated\n",
      "episode 2906, reward 1345.0, memory_length 2000, epsilon 0.5592312992222302\n",
      "state terminated\n",
      "episode 2907, reward 1534.0, memory_length 2000, epsilon 0.5591194661460661\n",
      "state terminated\n",
      "episode 2908, reward 1583.0, memory_length 2000, epsilon 0.5590076554342809\n",
      "state terminated\n",
      "episode 2909, reward 1492.0, memory_length 2000, epsilon 0.5588958670824018\n",
      "state terminated\n",
      "episode 2910, reward 824.0, memory_length 2000, epsilon 0.5587841010859574\n",
      "state terminated\n",
      "episode 2911, reward 1442.0, memory_length 2000, epsilon 0.5586723574404773\n",
      "state terminated\n",
      "episode 2912, reward 1344.0, memory_length 2000, epsilon 0.5585606361414915\n",
      "state terminated\n",
      "episode 2913, reward 1420.0, memory_length 2000, epsilon 0.5584489371845313\n",
      "state terminated\n",
      "episode 2914, reward 1442.0, memory_length 2000, epsilon 0.5583372605651286\n",
      "state terminated\n",
      "episode 2915, reward 1352.0, memory_length 2000, epsilon 0.5582256062788163\n",
      "state terminated\n",
      "episode 2916, reward 1407.0, memory_length 2000, epsilon 0.5581139743211284\n",
      "state terminated\n",
      "episode 2917, reward 1385.0, memory_length 2000, epsilon 0.5580023646875996\n",
      "state terminated\n",
      "episode 2918, reward 1010.0, memory_length 2000, epsilon 0.5578907773737655\n",
      "state terminated\n",
      "episode 2919, reward 1502.0, memory_length 2000, epsilon 0.5577792123751624\n",
      "state terminated\n",
      "episode 2920, reward 1388.0, memory_length 2000, epsilon 0.557667669687328\n",
      "state terminated\n",
      "episode 2921, reward 1242.0, memory_length 2000, epsilon 0.5575561493058003\n",
      "state terminated\n",
      "episode 2922, reward 1415.0, memory_length 2000, epsilon 0.5574446512261189\n",
      "state terminated\n",
      "episode 2923, reward 1079.0, memory_length 2000, epsilon 0.5573331754438234\n",
      "state terminated\n",
      "episode 2924, reward 1133.0, memory_length 2000, epsilon 0.5572217219544551\n",
      "state terminated\n",
      "episode 2925, reward 1482.0, memory_length 2000, epsilon 0.5571102907535557\n",
      "state terminated\n",
      "episode 2926, reward 982.0, memory_length 2000, epsilon 0.556998881836668\n",
      "state terminated\n",
      "episode 2927, reward 1342.0, memory_length 2000, epsilon 0.5568874951993358\n",
      "state terminated\n",
      "episode 2928, reward 1170.0, memory_length 2000, epsilon 0.5567761308371033\n",
      "state terminated\n",
      "episode 2929, reward 1199.0, memory_length 2000, epsilon 0.5566647887455163\n",
      "state terminated\n",
      "episode 2930, reward 1128.0, memory_length 2000, epsilon 0.5565534689201207\n",
      "state terminated\n",
      "episode 2931, reward 1394.0, memory_length 2000, epsilon 0.556442171356464\n",
      "state terminated\n",
      "episode 2932, reward 1212.0, memory_length 2000, epsilon 0.5563308960500943\n",
      "state terminated\n",
      "episode 2933, reward 1309.0, memory_length 2000, epsilon 0.5562196429965605\n",
      "state terminated\n",
      "episode 2934, reward 907.0, memory_length 2000, epsilon 0.5561084121914125\n",
      "state terminated\n",
      "episode 2935, reward 989.0, memory_length 2000, epsilon 0.555997203630201\n",
      "state terminated\n",
      "episode 2936, reward 1065.0, memory_length 2000, epsilon 0.5558860173084778\n",
      "state terminated\n",
      "episode 2937, reward 1426.0, memory_length 2000, epsilon 0.5557748532217952\n",
      "state terminated\n",
      "episode 2938, reward 1097.0, memory_length 2000, epsilon 0.555663711365707\n",
      "state terminated\n",
      "episode 2939, reward 1318.0, memory_length 2000, epsilon 0.5555525917357672\n",
      "state terminated\n",
      "episode 2940, reward 813.0, memory_length 2000, epsilon 0.5554414943275312\n",
      "state terminated\n",
      "episode 2941, reward 1155.0, memory_length 2000, epsilon 0.555330419136555\n",
      "state terminated\n",
      "episode 2942, reward 1381.0, memory_length 2000, epsilon 0.5552193661583957\n",
      "state terminated\n",
      "episode 2943, reward 1558.0, memory_length 2000, epsilon 0.5551083353886112\n",
      "state terminated\n",
      "episode 2944, reward 1353.0, memory_length 2000, epsilon 0.5549973268227602\n",
      "state terminated\n",
      "episode 2945, reward 1074.0, memory_length 2000, epsilon 0.5548863404564021\n",
      "state terminated\n",
      "episode 2946, reward 957.0, memory_length 2000, epsilon 0.5547753762850979\n",
      "state terminated\n",
      "episode 2947, reward 1311.0, memory_length 2000, epsilon 0.5546644343044087\n",
      "state terminated\n",
      "episode 2948, reward 1422.0, memory_length 2000, epsilon 0.554553514509897\n",
      "state terminated\n",
      "episode 2949, reward 1754.0, memory_length 2000, epsilon 0.554442616897126\n",
      "state terminated\n",
      "episode 2950, reward 877.0, memory_length 2000, epsilon 0.5543317414616596\n",
      "state terminated\n",
      "episode 2951, reward 973.0, memory_length 2000, epsilon 0.5542208881990631\n",
      "state terminated\n",
      "episode 2952, reward 1287.0, memory_length 2000, epsilon 0.5541100571049021\n",
      "state terminated\n",
      "episode 2953, reward 1065.0, memory_length 2000, epsilon 0.5539992481747436\n",
      "state terminated\n",
      "episode 2954, reward 1334.0, memory_length 2000, epsilon 0.5538884614041549\n",
      "state terminated\n",
      "episode 2955, reward 1251.0, memory_length 2000, epsilon 0.5537776967887048\n",
      "state terminated\n",
      "episode 2956, reward 1501.0, memory_length 2000, epsilon 0.5536669543239627\n",
      "state terminated\n",
      "episode 2957, reward 1564.0, memory_length 2000, epsilon 0.5535562340054988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 2958, reward 1312.0, memory_length 2000, epsilon 0.5534455358288844\n",
      "state terminated\n",
      "episode 2959, reward 1298.0, memory_length 2000, epsilon 0.5533348597896914\n",
      "state terminated\n",
      "episode 2960, reward 1206.0, memory_length 2000, epsilon 0.553224205883493\n",
      "state terminated\n",
      "episode 2961, reward 1345.0, memory_length 2000, epsilon 0.5531135741058628\n",
      "state terminated\n",
      "episode 2962, reward 1251.0, memory_length 2000, epsilon 0.5530029644523757\n",
      "state terminated\n",
      "episode 2963, reward 1431.0, memory_length 2000, epsilon 0.5528923769186073\n",
      "state terminated\n",
      "episode 2964, reward 1390.0, memory_length 2000, epsilon 0.552781811500134\n",
      "state terminated\n",
      "episode 2965, reward 1470.0, memory_length 2000, epsilon 0.5526712681925331\n",
      "state terminated\n",
      "episode 2966, reward 1622.0, memory_length 2000, epsilon 0.5525607469913831\n",
      "state terminated\n",
      "episode 2967, reward 1282.0, memory_length 2000, epsilon 0.552450247892263\n",
      "state terminated\n",
      "episode 2968, reward 1204.0, memory_length 2000, epsilon 0.552339770890753\n",
      "state terminated\n",
      "episode 2969, reward 1030.0, memory_length 2000, epsilon 0.552229315982434\n",
      "state terminated\n",
      "episode 2970, reward 1053.0, memory_length 2000, epsilon 0.5521188831628875\n",
      "state terminated\n",
      "episode 2971, reward 1273.0, memory_length 2000, epsilon 0.5520084724276965\n",
      "state terminated\n",
      "episode 2972, reward 1217.0, memory_length 2000, epsilon 0.5518980837724444\n",
      "state terminated\n",
      "episode 2973, reward 1557.0, memory_length 2000, epsilon 0.5517877171927158\n",
      "state terminated\n",
      "episode 2974, reward 1102.0, memory_length 2000, epsilon 0.5516773726840959\n",
      "state terminated\n",
      "episode 2975, reward 1385.0, memory_length 2000, epsilon 0.5515670502421711\n",
      "state terminated\n",
      "episode 2976, reward 1156.0, memory_length 2000, epsilon 0.5514567498625282\n",
      "state terminated\n",
      "episode 2977, reward 1497.0, memory_length 2000, epsilon 0.5513464715407556\n",
      "state terminated\n",
      "episode 2978, reward 1120.0, memory_length 2000, epsilon 0.5512362152724417\n",
      "state terminated\n",
      "episode 2979, reward 1280.0, memory_length 2000, epsilon 0.5511259810531767\n",
      "state terminated\n",
      "episode 2980, reward 1172.0, memory_length 2000, epsilon 0.5510157688785507\n",
      "state terminated\n",
      "episode 2981, reward 1228.0, memory_length 2000, epsilon 0.5509055787441559\n",
      "state terminated\n",
      "episode 2982, reward 1331.0, memory_length 2000, epsilon 0.5507954106455841\n",
      "state terminated\n",
      "episode 2983, reward 1418.0, memory_length 2000, epsilon 0.5506852645784288\n",
      "state terminated\n",
      "episode 2984, reward 1254.0, memory_length 2000, epsilon 0.5505751405382843\n",
      "state terminated\n",
      "episode 2985, reward 1288.0, memory_length 2000, epsilon 0.5504650385207454\n",
      "state terminated\n",
      "episode 2986, reward 1282.0, memory_length 2000, epsilon 0.550354958521408\n",
      "state terminated\n",
      "episode 2987, reward 1143.0, memory_length 2000, epsilon 0.5502449005358692\n",
      "state terminated\n",
      "episode 2988, reward 1443.0, memory_length 2000, epsilon 0.5501348645597264\n",
      "state terminated\n",
      "episode 2989, reward 1678.0, memory_length 2000, epsilon 0.5500248505885783\n",
      "state terminated\n",
      "episode 2990, reward 1369.0, memory_length 2000, epsilon 0.5499148586180244\n",
      "state terminated\n",
      "episode 2991, reward 1425.0, memory_length 2000, epsilon 0.5498048886436647\n",
      "state terminated\n",
      "episode 2992, reward 1107.0, memory_length 2000, epsilon 0.5496949406611007\n",
      "state terminated\n",
      "episode 2993, reward 1257.0, memory_length 2000, epsilon 0.5495850146659345\n",
      "state terminated\n",
      "episode 2994, reward 1430.0, memory_length 2000, epsilon 0.5494751106537688\n",
      "state terminated\n",
      "episode 2995, reward 1265.0, memory_length 2000, epsilon 0.5493652286202078\n",
      "state terminated\n",
      "episode 2996, reward 1309.0, memory_length 2000, epsilon 0.5492553685608557\n",
      "state terminated\n",
      "episode 2997, reward 1128.0, memory_length 2000, epsilon 0.5491455304713186\n",
      "state terminated\n",
      "episode 2998, reward 1356.0, memory_length 2000, epsilon 0.5490357143472029\n",
      "state terminated\n",
      "episode 2999, reward 1509.0, memory_length 2000, epsilon 0.5489259201841158\n",
      "state terminated\n",
      "episode 3000, reward 1300.0, memory_length 2000, epsilon 0.5488161479776655\n",
      "Total time taken  18187.745279550552\n",
      "state terminated\n",
      "episode 3001, reward 1721.0, memory_length 2000, epsilon 0.5487063977234612\n",
      "state terminated\n",
      "episode 3002, reward 1309.0, memory_length 2000, epsilon 0.5485966694171128\n",
      "state terminated\n",
      "episode 3003, reward 1530.0, memory_length 2000, epsilon 0.5484869630542315\n",
      "state terminated\n",
      "episode 3004, reward 1374.0, memory_length 2000, epsilon 0.5483772786304286\n",
      "state terminated\n",
      "episode 3005, reward 1390.0, memory_length 2000, epsilon 0.548267616141317\n",
      "state terminated\n",
      "episode 3006, reward 1357.0, memory_length 2000, epsilon 0.54815797558251\n",
      "state terminated\n",
      "episode 3007, reward 1491.0, memory_length 2000, epsilon 0.5480483569496222\n",
      "state terminated\n",
      "episode 3008, reward 1315.0, memory_length 2000, epsilon 0.5479387602382687\n",
      "state terminated\n",
      "episode 3009, reward 1413.0, memory_length 2000, epsilon 0.5478291854440658\n",
      "state terminated\n",
      "episode 3010, reward 1548.0, memory_length 2000, epsilon 0.5477196325626303\n",
      "state terminated\n",
      "episode 3011, reward 1305.0, memory_length 2000, epsilon 0.5476101015895801\n",
      "state terminated\n",
      "episode 3012, reward 1226.0, memory_length 2000, epsilon 0.5475005925205342\n",
      "state terminated\n",
      "episode 3013, reward 1453.0, memory_length 2000, epsilon 0.5473911053511119\n",
      "state terminated\n",
      "episode 3014, reward 1342.0, memory_length 2000, epsilon 0.547281640076934\n",
      "state terminated\n",
      "episode 3015, reward 1095.0, memory_length 2000, epsilon 0.5471721966936218\n",
      "state terminated\n",
      "episode 3016, reward 1450.0, memory_length 2000, epsilon 0.5470627751967975\n",
      "state terminated\n",
      "episode 3017, reward 1223.0, memory_length 2000, epsilon 0.5469533755820842\n",
      "state terminated\n",
      "episode 3018, reward 1244.0, memory_length 2000, epsilon 0.5468439978451061\n",
      "state terminated\n",
      "episode 3019, reward 1315.0, memory_length 2000, epsilon 0.546734641981488\n",
      "state terminated\n",
      "episode 3020, reward 1534.0, memory_length 2000, epsilon 0.5466253079868557\n",
      "state terminated\n",
      "episode 3021, reward 1194.0, memory_length 2000, epsilon 0.5465159958568356\n",
      "state terminated\n",
      "episode 3022, reward 1384.0, memory_length 2000, epsilon 0.5464067055870555\n",
      "state terminated\n",
      "episode 3023, reward 963.0, memory_length 2000, epsilon 0.5462974371731438\n",
      "state terminated\n",
      "episode 3024, reward 1422.0, memory_length 2000, epsilon 0.5461881906107294\n",
      "state terminated\n",
      "episode 3025, reward 1092.0, memory_length 2000, epsilon 0.546078965895443\n",
      "state terminated\n",
      "episode 3026, reward 1190.0, memory_length 2000, epsilon 0.5459697630229151\n",
      "state terminated\n",
      "episode 3027, reward 1023.0, memory_length 2000, epsilon 0.545860581988778\n",
      "state terminated\n",
      "episode 3028, reward 1290.0, memory_length 2000, epsilon 0.5457514227886641\n",
      "state terminated\n",
      "episode 3029, reward 1255.0, memory_length 2000, epsilon 0.5456422854182073\n",
      "state terminated\n",
      "episode 3030, reward 1091.0, memory_length 2000, epsilon 0.5455331698730417\n",
      "state terminated\n",
      "episode 3031, reward 1425.0, memory_length 2000, epsilon 0.5454240761488032\n",
      "state terminated\n",
      "episode 3032, reward 1242.0, memory_length 2000, epsilon 0.5453150042411278\n",
      "state terminated\n",
      "episode 3033, reward 1099.0, memory_length 2000, epsilon 0.5452059541456526\n",
      "state terminated\n",
      "episode 3034, reward 1191.0, memory_length 2000, epsilon 0.5450969258580156\n",
      "state terminated\n",
      "episode 3035, reward 1290.0, memory_length 2000, epsilon 0.5449879193738558\n",
      "state terminated\n",
      "episode 3036, reward 1341.0, memory_length 2000, epsilon 0.5448789346888128\n",
      "state terminated\n",
      "episode 3037, reward 1256.0, memory_length 2000, epsilon 0.5447699717985273\n",
      "state terminated\n",
      "episode 3038, reward 1104.0, memory_length 2000, epsilon 0.5446610306986407\n",
      "state terminated\n",
      "episode 3039, reward 1386.0, memory_length 2000, epsilon 0.5445521113847954\n",
      "state terminated\n",
      "episode 3040, reward 1027.0, memory_length 2000, epsilon 0.5444432138526347\n",
      "state terminated\n",
      "episode 3041, reward 1510.0, memory_length 2000, epsilon 0.5443343380978025\n",
      "state terminated\n",
      "episode 3042, reward 1080.0, memory_length 2000, epsilon 0.5442254841159441\n",
      "state terminated\n",
      "episode 3043, reward 1259.0, memory_length 2000, epsilon 0.544116651902705\n",
      "state terminated\n",
      "episode 3044, reward 1633.0, memory_length 2000, epsilon 0.544007841453732\n",
      "state terminated\n",
      "episode 3045, reward 1543.0, memory_length 2000, epsilon 0.5438990527646728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3046, reward 1563.0, memory_length 2000, epsilon 0.5437902858311758\n",
      "state terminated\n",
      "episode 3047, reward 1397.0, memory_length 2000, epsilon 0.5436815406488903\n",
      "state terminated\n",
      "episode 3048, reward 1048.0, memory_length 2000, epsilon 0.5435728172134664\n",
      "state terminated\n",
      "episode 3049, reward 1406.0, memory_length 2000, epsilon 0.5434641155205554\n",
      "state terminated\n",
      "episode 3050, reward 1434.0, memory_length 2000, epsilon 0.543355435565809\n",
      "state terminated\n",
      "episode 3051, reward 1370.0, memory_length 2000, epsilon 0.5432467773448801\n",
      "state terminated\n",
      "episode 3052, reward 1364.0, memory_length 2000, epsilon 0.5431381408534225\n",
      "state terminated\n",
      "episode 3053, reward 1291.0, memory_length 2000, epsilon 0.5430295260870904\n",
      "state terminated\n",
      "episode 3054, reward 1272.0, memory_length 2000, epsilon 0.5429209330415395\n",
      "state terminated\n",
      "episode 3055, reward 918.0, memory_length 2000, epsilon 0.5428123617124261\n",
      "state terminated\n",
      "episode 3056, reward 1376.0, memory_length 2000, epsilon 0.5427038120954071\n",
      "state terminated\n",
      "episode 3057, reward 1349.0, memory_length 2000, epsilon 0.5425952841861407\n",
      "state terminated\n",
      "episode 3058, reward 1115.0, memory_length 2000, epsilon 0.5424867779802857\n",
      "state terminated\n",
      "episode 3059, reward 1646.0, memory_length 2000, epsilon 0.542378293473502\n",
      "state terminated\n",
      "episode 3060, reward 1290.0, memory_length 2000, epsilon 0.5422698306614501\n",
      "state terminated\n",
      "episode 3061, reward 946.0, memory_length 2000, epsilon 0.5421613895397914\n",
      "state terminated\n",
      "episode 3062, reward 1137.0, memory_length 2000, epsilon 0.5420529701041884\n",
      "state terminated\n",
      "episode 3063, reward 1053.0, memory_length 2000, epsilon 0.5419445723503042\n",
      "state terminated\n",
      "episode 3064, reward 1213.0, memory_length 2000, epsilon 0.5418361962738031\n",
      "state terminated\n",
      "episode 3065, reward 1142.0, memory_length 2000, epsilon 0.54172784187035\n",
      "state terminated\n",
      "episode 3066, reward 935.0, memory_length 2000, epsilon 0.5416195091356103\n",
      "state terminated\n",
      "episode 3067, reward 1457.0, memory_length 2000, epsilon 0.5415111980652513\n",
      "state terminated\n",
      "episode 3068, reward 1482.0, memory_length 2000, epsilon 0.5414029086549402\n",
      "state terminated\n",
      "episode 3069, reward 1556.0, memory_length 2000, epsilon 0.5412946409003456\n",
      "state terminated\n",
      "episode 3070, reward 1494.0, memory_length 2000, epsilon 0.5411863947971367\n",
      "state terminated\n",
      "episode 3071, reward 1002.0, memory_length 2000, epsilon 0.5410781703409836\n",
      "state terminated\n",
      "episode 3072, reward 1045.0, memory_length 2000, epsilon 0.5409699675275574\n",
      "state terminated\n",
      "episode 3073, reward 1575.0, memory_length 2000, epsilon 0.5408617863525301\n",
      "state terminated\n",
      "episode 3074, reward 1056.0, memory_length 2000, epsilon 0.5407536268115742\n",
      "state terminated\n",
      "episode 3075, reward 1327.0, memory_length 2000, epsilon 0.5406454889003635\n",
      "state terminated\n",
      "episode 3076, reward 1131.0, memory_length 2000, epsilon 0.5405373726145724\n",
      "state terminated\n",
      "episode 3077, reward 1268.0, memory_length 2000, epsilon 0.5404292779498762\n",
      "state terminated\n",
      "episode 3078, reward 1090.0, memory_length 2000, epsilon 0.5403212049019512\n",
      "state terminated\n",
      "episode 3079, reward 1467.0, memory_length 2000, epsilon 0.5402131534664746\n",
      "state terminated\n",
      "episode 3080, reward 921.0, memory_length 2000, epsilon 0.5401051236391242\n",
      "state terminated\n",
      "episode 3081, reward 1178.0, memory_length 2000, epsilon 0.5399971154155787\n",
      "state terminated\n",
      "episode 3082, reward 1268.0, memory_length 2000, epsilon 0.5398891287915178\n",
      "state terminated\n",
      "episode 3083, reward 1366.0, memory_length 2000, epsilon 0.5397811637626224\n",
      "state terminated\n",
      "episode 3084, reward 1192.0, memory_length 2000, epsilon 0.5396732203245735\n",
      "state terminated\n",
      "episode 3085, reward 1527.0, memory_length 2000, epsilon 0.5395652984730535\n",
      "state terminated\n",
      "episode 3086, reward 1354.0, memory_length 2000, epsilon 0.5394573982037455\n",
      "state terminated\n",
      "episode 3087, reward 1357.0, memory_length 2000, epsilon 0.5393495195123333\n",
      "state terminated\n",
      "episode 3088, reward 1056.0, memory_length 2000, epsilon 0.5392416623945022\n",
      "state terminated\n",
      "episode 3089, reward 697.0, memory_length 2000, epsilon 0.5391338268459377\n",
      "state terminated\n",
      "episode 3090, reward 1383.0, memory_length 2000, epsilon 0.5390260128623262\n",
      "state terminated\n",
      "episode 3091, reward 1146.0, memory_length 2000, epsilon 0.5389182204393553\n",
      "state terminated\n",
      "episode 3092, reward 1415.0, memory_length 2000, epsilon 0.5388104495727134\n",
      "state terminated\n",
      "episode 3093, reward 1312.0, memory_length 2000, epsilon 0.5387027002580895\n",
      "state terminated\n",
      "episode 3094, reward 1434.0, memory_length 2000, epsilon 0.5385949724911737\n",
      "state terminated\n",
      "episode 3095, reward 1183.0, memory_length 2000, epsilon 0.5384872662676569\n",
      "state terminated\n",
      "episode 3096, reward 1263.0, memory_length 2000, epsilon 0.5383795815832306\n",
      "state terminated\n",
      "episode 3097, reward 1512.0, memory_length 2000, epsilon 0.5382719184335878\n",
      "state terminated\n",
      "episode 3098, reward 1435.0, memory_length 2000, epsilon 0.5381642768144219\n",
      "state terminated\n",
      "episode 3099, reward 1042.0, memory_length 2000, epsilon 0.5380566567214271\n",
      "state terminated\n",
      "episode 3100, reward 1111.0, memory_length 2000, epsilon 0.5379490581502985\n",
      "state terminated\n",
      "episode 3101, reward 1331.0, memory_length 2000, epsilon 0.5378414810967324\n",
      "state terminated\n",
      "episode 3102, reward 1386.0, memory_length 2000, epsilon 0.5377339255564255\n",
      "state terminated\n",
      "episode 3103, reward 915.0, memory_length 2000, epsilon 0.537626391525076\n",
      "state terminated\n",
      "episode 3104, reward 1487.0, memory_length 2000, epsilon 0.5375188789983819\n",
      "state terminated\n",
      "episode 3105, reward 1540.0, memory_length 2000, epsilon 0.5374113879720432\n",
      "state terminated\n",
      "episode 3106, reward 1361.0, memory_length 2000, epsilon 0.5373039184417601\n",
      "state terminated\n",
      "episode 3107, reward 1133.0, memory_length 2000, epsilon 0.5371964704032337\n",
      "state terminated\n",
      "episode 3108, reward 1418.0, memory_length 2000, epsilon 0.5370890438521662\n",
      "state terminated\n",
      "episode 3109, reward 1259.0, memory_length 2000, epsilon 0.5369816387842606\n",
      "state terminated\n",
      "episode 3110, reward 1376.0, memory_length 2000, epsilon 0.5368742551952206\n",
      "state terminated\n",
      "episode 3111, reward 1264.0, memory_length 2000, epsilon 0.5367668930807509\n",
      "state terminated\n",
      "episode 3112, reward 972.0, memory_length 2000, epsilon 0.5366595524365569\n",
      "state terminated\n",
      "episode 3113, reward 1214.0, memory_length 2000, epsilon 0.5365522332583452\n",
      "state terminated\n",
      "episode 3114, reward 1407.0, memory_length 2000, epsilon 0.5364449355418228\n",
      "state terminated\n",
      "episode 3115, reward 1418.0, memory_length 2000, epsilon 0.5363376592826979\n",
      "state terminated\n",
      "episode 3116, reward 1321.0, memory_length 2000, epsilon 0.5362304044766796\n",
      "state terminated\n",
      "episode 3117, reward 1363.0, memory_length 2000, epsilon 0.5361231711194774\n",
      "state terminated\n",
      "episode 3118, reward 1089.0, memory_length 2000, epsilon 0.5360159592068021\n",
      "state terminated\n",
      "episode 3119, reward 1057.0, memory_length 2000, epsilon 0.5359087687343653\n",
      "state terminated\n",
      "episode 3120, reward 1269.0, memory_length 2000, epsilon 0.5358015996978793\n",
      "state terminated\n",
      "episode 3121, reward 1198.0, memory_length 2000, epsilon 0.5356944520930574\n",
      "state terminated\n",
      "episode 3122, reward 1542.0, memory_length 2000, epsilon 0.5355873259156136\n",
      "state terminated\n",
      "episode 3123, reward 1087.0, memory_length 2000, epsilon 0.5354802211612629\n",
      "state terminated\n",
      "episode 3124, reward 1210.0, memory_length 2000, epsilon 0.5353731378257213\n",
      "state terminated\n",
      "episode 3125, reward 1445.0, memory_length 2000, epsilon 0.5352660759047051\n",
      "state terminated\n",
      "episode 3126, reward 1269.0, memory_length 2000, epsilon 0.535159035393932\n",
      "state terminated\n",
      "episode 3127, reward 1143.0, memory_length 2000, epsilon 0.5350520162891204\n",
      "state terminated\n",
      "episode 3128, reward 1615.0, memory_length 2000, epsilon 0.5349450185859895\n",
      "state terminated\n",
      "episode 3129, reward 1285.0, memory_length 2000, epsilon 0.5348380422802596\n",
      "state terminated\n",
      "episode 3130, reward 1101.0, memory_length 2000, epsilon 0.5347310873676512\n",
      "state terminated\n",
      "episode 3131, reward 999.0, memory_length 2000, epsilon 0.5346241538438865\n",
      "state terminated\n",
      "episode 3132, reward 1231.0, memory_length 2000, epsilon 0.5345172417046881\n",
      "state terminated\n",
      "episode 3133, reward 1156.0, memory_length 2000, epsilon 0.5344103509457793\n",
      "state terminated\n",
      "episode 3134, reward 1411.0, memory_length 2000, epsilon 0.5343034815628847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3135, reward 1411.0, memory_length 2000, epsilon 0.5341966335517294\n",
      "state terminated\n",
      "episode 3136, reward 1238.0, memory_length 2000, epsilon 0.5340898069080395\n",
      "state terminated\n",
      "episode 3137, reward 1268.0, memory_length 2000, epsilon 0.5339830016275419\n",
      "state terminated\n",
      "episode 3138, reward 1096.0, memory_length 2000, epsilon 0.5338762177059645\n",
      "state terminated\n",
      "episode 3139, reward 1398.0, memory_length 2000, epsilon 0.5337694551390358\n",
      "state terminated\n",
      "episode 3140, reward 983.0, memory_length 2000, epsilon 0.5336627139224855\n",
      "state terminated\n",
      "episode 3141, reward 1236.0, memory_length 2000, epsilon 0.5335559940520439\n",
      "state terminated\n",
      "episode 3142, reward 1420.0, memory_length 2000, epsilon 0.5334492955234419\n",
      "state terminated\n",
      "episode 3143, reward 1097.0, memory_length 2000, epsilon 0.5333426183324119\n",
      "state terminated\n",
      "episode 3144, reward 1414.0, memory_length 2000, epsilon 0.5332359624746867\n",
      "state terminated\n",
      "episode 3145, reward 1178.0, memory_length 2000, epsilon 0.5331293279460002\n",
      "state terminated\n",
      "episode 3146, reward 1521.0, memory_length 2000, epsilon 0.5330227147420867\n",
      "state terminated\n",
      "episode 3147, reward 1314.0, memory_length 2000, epsilon 0.532916122858682\n",
      "state terminated\n",
      "episode 3148, reward 1435.0, memory_length 2000, epsilon 0.5328095522915222\n",
      "state terminated\n",
      "episode 3149, reward 1897.0, memory_length 2000, epsilon 0.5327030030363445\n",
      "state terminated\n",
      "episode 3150, reward 1422.0, memory_length 2000, epsilon 0.5325964750888871\n",
      "state terminated\n",
      "episode 3151, reward 1284.0, memory_length 2000, epsilon 0.5324899684448888\n",
      "state terminated\n",
      "episode 3152, reward 1533.0, memory_length 2000, epsilon 0.5323834831000892\n",
      "state terminated\n",
      "episode 3153, reward 1549.0, memory_length 2000, epsilon 0.5322770190502291\n",
      "state terminated\n",
      "episode 3154, reward 1348.0, memory_length 2000, epsilon 0.5321705762910497\n",
      "state terminated\n",
      "episode 3155, reward 1396.0, memory_length 2000, epsilon 0.5320641548182935\n",
      "state terminated\n",
      "episode 3156, reward 1656.0, memory_length 2000, epsilon 0.5319577546277036\n",
      "state terminated\n",
      "episode 3157, reward 1115.0, memory_length 2000, epsilon 0.5318513757150238\n",
      "state terminated\n",
      "episode 3158, reward 1388.0, memory_length 2000, epsilon 0.5317450180759994\n",
      "state terminated\n",
      "episode 3159, reward 1331.0, memory_length 2000, epsilon 0.5316386817063755\n",
      "state terminated\n",
      "episode 3160, reward 1280.0, memory_length 2000, epsilon 0.5315323666018991\n",
      "state terminated\n",
      "episode 3161, reward 1225.0, memory_length 2000, epsilon 0.5314260727583174\n",
      "state terminated\n",
      "episode 3162, reward 1171.0, memory_length 2000, epsilon 0.5313198001713787\n",
      "state terminated\n",
      "episode 3163, reward 1628.0, memory_length 2000, epsilon 0.531213548836832\n",
      "state terminated\n",
      "episode 3164, reward 1170.0, memory_length 2000, epsilon 0.5311073187504274\n",
      "state terminated\n",
      "episode 3165, reward 1192.0, memory_length 2000, epsilon 0.5310011099079156\n",
      "state terminated\n",
      "episode 3166, reward 1472.0, memory_length 2000, epsilon 0.5308949223050482\n",
      "state terminated\n",
      "episode 3167, reward 1461.0, memory_length 2000, epsilon 0.5307887559375778\n",
      "state terminated\n",
      "episode 3168, reward 1654.0, memory_length 2000, epsilon 0.5306826108012578\n",
      "state terminated\n",
      "episode 3169, reward 1231.0, memory_length 2000, epsilon 0.5305764868918422\n",
      "state terminated\n",
      "episode 3170, reward 1392.0, memory_length 2000, epsilon 0.5304703842050862\n",
      "state terminated\n",
      "episode 3171, reward 1245.0, memory_length 2000, epsilon 0.5303643027367456\n",
      "state terminated\n",
      "episode 3172, reward 1197.0, memory_length 2000, epsilon 0.5302582424825772\n",
      "state terminated\n",
      "episode 3173, reward 1378.0, memory_length 2000, epsilon 0.5301522034383387\n",
      "state terminated\n",
      "episode 3174, reward 1030.0, memory_length 2000, epsilon 0.5300461855997882\n",
      "state terminated\n",
      "episode 3175, reward 1453.0, memory_length 2000, epsilon 0.5299401889626854\n",
      "state terminated\n",
      "episode 3176, reward 1107.0, memory_length 2000, epsilon 0.5298342135227899\n",
      "state terminated\n",
      "episode 3177, reward 1407.0, memory_length 2000, epsilon 0.5297282592758633\n",
      "state terminated\n",
      "episode 3178, reward 1306.0, memory_length 2000, epsilon 0.529622326217667\n",
      "state terminated\n",
      "episode 3179, reward 1506.0, memory_length 2000, epsilon 0.5295164143439639\n",
      "state terminated\n",
      "episode 3180, reward 1490.0, memory_length 2000, epsilon 0.5294105236505174\n",
      "state terminated\n",
      "episode 3181, reward 1291.0, memory_length 2000, epsilon 0.529304654133092\n",
      "state terminated\n",
      "episode 3182, reward 1186.0, memory_length 2000, epsilon 0.5291988057874527\n",
      "state terminated\n",
      "episode 3183, reward 1286.0, memory_length 2000, epsilon 0.5290929786093659\n",
      "state terminated\n",
      "episode 3184, reward 1518.0, memory_length 2000, epsilon 0.528987172594598\n",
      "state terminated\n",
      "episode 3185, reward 1209.0, memory_length 2000, epsilon 0.5288813877389174\n",
      "state terminated\n",
      "episode 3186, reward 1089.0, memory_length 2000, epsilon 0.5287756240380923\n",
      "state terminated\n",
      "episode 3187, reward 1433.0, memory_length 2000, epsilon 0.5286698814878921\n",
      "state terminated\n",
      "episode 3188, reward 1127.0, memory_length 2000, epsilon 0.5285641600840872\n",
      "state terminated\n",
      "episode 3189, reward 1530.0, memory_length 2000, epsilon 0.528458459822449\n",
      "state terminated\n",
      "episode 3190, reward 998.0, memory_length 2000, epsilon 0.5283527806987491\n",
      "state terminated\n",
      "episode 3191, reward 1128.0, memory_length 2000, epsilon 0.5282471227087606\n",
      "state terminated\n",
      "episode 3192, reward 1408.0, memory_length 2000, epsilon 0.528141485848257\n",
      "state terminated\n",
      "episode 3193, reward 1283.0, memory_length 2000, epsilon 0.5280358701130129\n",
      "state terminated\n",
      "episode 3194, reward 1492.0, memory_length 2000, epsilon 0.5279302754988038\n",
      "state terminated\n",
      "episode 3195, reward 1407.0, memory_length 2000, epsilon 0.5278247020014056\n",
      "state terminated\n",
      "episode 3196, reward 1579.0, memory_length 2000, epsilon 0.5277191496165957\n",
      "state terminated\n",
      "episode 3197, reward 1457.0, memory_length 2000, epsilon 0.5276136183401517\n",
      "state terminated\n",
      "episode 3198, reward 1488.0, memory_length 2000, epsilon 0.5275081081678527\n",
      "state terminated\n",
      "episode 3199, reward 1287.0, memory_length 2000, epsilon 0.527402619095478\n",
      "state terminated\n",
      "episode 3200, reward 1289.0, memory_length 2000, epsilon 0.5272971511188081\n",
      "state terminated\n",
      "episode 3201, reward 1340.0, memory_length 2000, epsilon 0.5271917042336244\n",
      "state terminated\n",
      "episode 3202, reward 1332.0, memory_length 2000, epsilon 0.5270862784357088\n",
      "state terminated\n",
      "episode 3203, reward 1632.0, memory_length 2000, epsilon 0.5269808737208446\n",
      "state terminated\n",
      "episode 3204, reward 1417.0, memory_length 2000, epsilon 0.5268754900848153\n",
      "state terminated\n",
      "episode 3205, reward 1161.0, memory_length 2000, epsilon 0.5267701275234057\n",
      "state terminated\n",
      "episode 3206, reward 1764.0, memory_length 2000, epsilon 0.5266647860324012\n",
      "state terminated\n",
      "episode 3207, reward 1505.0, memory_length 2000, epsilon 0.5265594656075883\n",
      "state terminated\n",
      "episode 3208, reward 1434.0, memory_length 2000, epsilon 0.5264541662447539\n",
      "state terminated\n",
      "episode 3209, reward 1511.0, memory_length 2000, epsilon 0.5263488879396865\n",
      "state terminated\n",
      "episode 3210, reward 1480.0, memory_length 2000, epsilon 0.5262436306881746\n",
      "state terminated\n",
      "episode 3211, reward 1498.0, memory_length 2000, epsilon 0.526138394486008\n",
      "state terminated\n",
      "episode 3212, reward 1212.0, memory_length 2000, epsilon 0.5260331793289772\n",
      "state terminated\n",
      "episode 3213, reward 1646.0, memory_length 2000, epsilon 0.5259279852128735\n",
      "state terminated\n",
      "episode 3214, reward 1279.0, memory_length 2000, epsilon 0.5258228121334896\n",
      "state terminated\n",
      "episode 3215, reward 1833.0, memory_length 2000, epsilon 0.5257176600866181\n",
      "state terminated\n",
      "episode 3216, reward 1246.0, memory_length 2000, epsilon 0.5256125290680531\n",
      "state terminated\n",
      "episode 3217, reward 1353.0, memory_length 2000, epsilon 0.5255074190735892\n",
      "state terminated\n",
      "episode 3218, reward 1339.0, memory_length 2000, epsilon 0.5254023300990223\n",
      "state terminated\n",
      "episode 3219, reward 1277.0, memory_length 2000, epsilon 0.5252972621401486\n",
      "state terminated\n",
      "episode 3220, reward 1385.0, memory_length 2000, epsilon 0.5251922151927655\n",
      "state terminated\n",
      "episode 3221, reward 1282.0, memory_length 2000, epsilon 0.5250871892526711\n",
      "state terminated\n",
      "episode 3222, reward 1296.0, memory_length 2000, epsilon 0.5249821843156641\n",
      "state terminated\n",
      "episode 3223, reward 1566.0, memory_length 2000, epsilon 0.5248772003775447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3224, reward 1637.0, memory_length 2000, epsilon 0.5247722374341135\n",
      "state terminated\n",
      "episode 3225, reward 1184.0, memory_length 2000, epsilon 0.5246672954811719\n",
      "state terminated\n",
      "episode 3226, reward 963.0, memory_length 2000, epsilon 0.524562374514522\n",
      "state terminated\n",
      "episode 3227, reward 883.0, memory_length 2000, epsilon 0.5244574745299672\n",
      "state terminated\n",
      "episode 3228, reward 1548.0, memory_length 2000, epsilon 0.5243525955233114\n",
      "state terminated\n",
      "episode 3229, reward 1115.0, memory_length 2000, epsilon 0.5242477374903596\n",
      "state terminated\n",
      "episode 3230, reward 1388.0, memory_length 2000, epsilon 0.5241429004269172\n",
      "state terminated\n",
      "episode 3231, reward 1305.0, memory_length 2000, epsilon 0.5240380843287912\n",
      "state terminated\n",
      "episode 3232, reward 1367.0, memory_length 2000, epsilon 0.5239332891917884\n",
      "state terminated\n",
      "episode 3233, reward 1070.0, memory_length 2000, epsilon 0.5238285150117172\n",
      "state terminated\n",
      "episode 3234, reward 1197.0, memory_length 2000, epsilon 0.5237237617843868\n",
      "state terminated\n",
      "episode 3235, reward 1393.0, memory_length 2000, epsilon 0.523619029505607\n",
      "state terminated\n",
      "episode 3236, reward 1069.0, memory_length 2000, epsilon 0.5235143181711883\n",
      "state terminated\n",
      "episode 3237, reward 1559.0, memory_length 2000, epsilon 0.5234096277769424\n",
      "state terminated\n",
      "episode 3238, reward 1160.0, memory_length 2000, epsilon 0.5233049583186818\n",
      "state terminated\n",
      "episode 3239, reward 1361.0, memory_length 2000, epsilon 0.5232003097922195\n",
      "state terminated\n",
      "episode 3240, reward 1420.0, memory_length 2000, epsilon 0.5230956821933698\n",
      "state terminated\n",
      "episode 3241, reward 1219.0, memory_length 2000, epsilon 0.5229910755179473\n",
      "state terminated\n",
      "episode 3242, reward 1689.0, memory_length 2000, epsilon 0.522886489761768\n",
      "state terminated\n",
      "episode 3243, reward 1702.0, memory_length 2000, epsilon 0.5227819249206482\n",
      "state terminated\n",
      "episode 3244, reward 1335.0, memory_length 2000, epsilon 0.5226773809904056\n",
      "state terminated\n",
      "episode 3245, reward 1326.0, memory_length 2000, epsilon 0.5225728579668583\n",
      "state terminated\n",
      "episode 3246, reward 1446.0, memory_length 2000, epsilon 0.5224683558458254\n",
      "state terminated\n",
      "episode 3247, reward 976.0, memory_length 2000, epsilon 0.5223638746231268\n",
      "state terminated\n",
      "episode 3248, reward 1546.0, memory_length 2000, epsilon 0.5222594142945832\n",
      "state terminated\n",
      "episode 3249, reward 1063.0, memory_length 2000, epsilon 0.5221549748560163\n",
      "state terminated\n",
      "episode 3250, reward 1690.0, memory_length 2000, epsilon 0.5220505563032484\n",
      "state terminated\n",
      "episode 3251, reward 1413.0, memory_length 2000, epsilon 0.5219461586321029\n",
      "state terminated\n",
      "episode 3252, reward 1320.0, memory_length 2000, epsilon 0.5218417818384037\n",
      "state terminated\n",
      "episode 3253, reward 1648.0, memory_length 2000, epsilon 0.5217374259179759\n",
      "state terminated\n",
      "episode 3254, reward 1277.0, memory_length 2000, epsilon 0.5216330908666452\n",
      "state terminated\n",
      "episode 3255, reward 1160.0, memory_length 2000, epsilon 0.5215287766802383\n",
      "state terminated\n",
      "episode 3256, reward 1172.0, memory_length 2000, epsilon 0.5214244833545825\n",
      "state terminated\n",
      "episode 3257, reward 1433.0, memory_length 2000, epsilon 0.5213202108855061\n",
      "state terminated\n",
      "episode 3258, reward 1314.0, memory_length 2000, epsilon 0.5212159592688381\n",
      "state terminated\n",
      "episode 3259, reward 1062.0, memory_length 2000, epsilon 0.5211117285004087\n",
      "state terminated\n",
      "episode 3260, reward 1367.0, memory_length 2000, epsilon 0.5210075185760483\n",
      "state terminated\n",
      "episode 3261, reward 1512.0, memory_length 2000, epsilon 0.5209033294915889\n",
      "state terminated\n",
      "episode 3262, reward 1269.0, memory_length 2000, epsilon 0.5207991612428626\n",
      "state terminated\n",
      "episode 3263, reward 1248.0, memory_length 2000, epsilon 0.5206950138257029\n",
      "state terminated\n",
      "episode 3264, reward 1602.0, memory_length 2000, epsilon 0.5205908872359439\n",
      "state terminated\n",
      "episode 3265, reward 1591.0, memory_length 2000, epsilon 0.5204867814694203\n",
      "state terminated\n",
      "episode 3266, reward 1328.0, memory_length 2000, epsilon 0.5203826965219681\n",
      "state terminated\n",
      "episode 3267, reward 1356.0, memory_length 2000, epsilon 0.520278632389424\n",
      "state terminated\n",
      "episode 3268, reward 1008.0, memory_length 2000, epsilon 0.520174589067625\n",
      "state terminated\n",
      "episode 3269, reward 1245.0, memory_length 2000, epsilon 0.5200705665524098\n",
      "state terminated\n",
      "episode 3270, reward 1245.0, memory_length 2000, epsilon 0.5199665648396172\n",
      "state terminated\n",
      "episode 3271, reward 1381.0, memory_length 2000, epsilon 0.5198625839250873\n",
      "state terminated\n",
      "episode 3272, reward 1458.0, memory_length 2000, epsilon 0.519758623804661\n",
      "state terminated\n",
      "episode 3273, reward 1405.0, memory_length 2000, epsilon 0.5196546844741795\n",
      "state terminated\n",
      "episode 3274, reward 1389.0, memory_length 2000, epsilon 0.5195507659294855\n",
      "state terminated\n",
      "episode 3275, reward 1420.0, memory_length 2000, epsilon 0.5194468681664223\n",
      "state terminated\n",
      "episode 3276, reward 1152.0, memory_length 2000, epsilon 0.5193429911808338\n",
      "state terminated\n",
      "episode 3277, reward 1305.0, memory_length 2000, epsilon 0.519239134968565\n",
      "state terminated\n",
      "episode 3278, reward 1645.0, memory_length 2000, epsilon 0.5191352995254617\n",
      "state terminated\n",
      "episode 3279, reward 1340.0, memory_length 2000, epsilon 0.5190314848473705\n",
      "state terminated\n",
      "episode 3280, reward 1721.0, memory_length 2000, epsilon 0.5189276909301388\n",
      "state terminated\n",
      "episode 3281, reward 1151.0, memory_length 2000, epsilon 0.5188239177696147\n",
      "state terminated\n",
      "episode 3282, reward 1449.0, memory_length 2000, epsilon 0.5187201653616473\n",
      "state terminated\n",
      "episode 3283, reward 1437.0, memory_length 2000, epsilon 0.5186164337020868\n",
      "state terminated\n",
      "episode 3284, reward 1196.0, memory_length 2000, epsilon 0.5185127227867836\n",
      "state terminated\n",
      "episode 3285, reward 1098.0, memory_length 2000, epsilon 0.5184090326115893\n",
      "state terminated\n",
      "episode 3286, reward 1316.0, memory_length 2000, epsilon 0.5183053631723566\n",
      "state terminated\n",
      "episode 3287, reward 1401.0, memory_length 2000, epsilon 0.5182017144649385\n",
      "state terminated\n",
      "episode 3288, reward 1570.0, memory_length 2000, epsilon 0.5180980864851886\n",
      "state terminated\n",
      "episode 3289, reward 1516.0, memory_length 2000, epsilon 0.5179944792289627\n",
      "state terminated\n",
      "episode 3290, reward 1398.0, memory_length 2000, epsilon 0.5178908926921159\n",
      "state terminated\n",
      "episode 3291, reward 1303.0, memory_length 2000, epsilon 0.5177873268705049\n",
      "state terminated\n",
      "episode 3292, reward 1294.0, memory_length 2000, epsilon 0.517683781759987\n",
      "state terminated\n",
      "episode 3293, reward 1335.0, memory_length 2000, epsilon 0.5175802573564203\n",
      "state terminated\n",
      "episode 3294, reward 1482.0, memory_length 2000, epsilon 0.5174767536556641\n",
      "state terminated\n",
      "episode 3295, reward 1419.0, memory_length 2000, epsilon 0.5173732706535783\n",
      "state terminated\n",
      "episode 3296, reward 1300.0, memory_length 2000, epsilon 0.5172698083460231\n",
      "state terminated\n",
      "episode 3297, reward 1317.0, memory_length 2000, epsilon 0.5171663667288605\n",
      "state terminated\n",
      "episode 3298, reward 1137.0, memory_length 2000, epsilon 0.5170629457979524\n",
      "state terminated\n",
      "episode 3299, reward 1384.0, memory_length 2000, epsilon 0.5169595455491625\n",
      "state terminated\n",
      "episode 3300, reward 1467.0, memory_length 2000, epsilon 0.5168561659783543\n",
      "state terminated\n",
      "episode 3301, reward 1388.0, memory_length 2000, epsilon 0.5167528070813929\n",
      "state terminated\n",
      "episode 3302, reward 1084.0, memory_length 2000, epsilon 0.5166494688541438\n",
      "state terminated\n",
      "episode 3303, reward 1834.0, memory_length 2000, epsilon 0.5165461512924734\n",
      "state terminated\n",
      "episode 3304, reward 1359.0, memory_length 2000, epsilon 0.5164428543922494\n",
      "state terminated\n",
      "episode 3305, reward 1417.0, memory_length 2000, epsilon 0.5163395781493394\n",
      "state terminated\n",
      "episode 3306, reward 1118.0, memory_length 2000, epsilon 0.5162363225596127\n",
      "state terminated\n",
      "episode 3307, reward 1191.0, memory_length 2000, epsilon 0.5161330876189391\n",
      "state terminated\n",
      "episode 3308, reward 1276.0, memory_length 2000, epsilon 0.5160298733231888\n",
      "state terminated\n",
      "episode 3309, reward 1294.0, memory_length 2000, epsilon 0.5159266796682337\n",
      "state terminated\n",
      "episode 3310, reward 1255.0, memory_length 2000, epsilon 0.5158235066499457\n",
      "state terminated\n",
      "episode 3311, reward 1652.0, memory_length 2000, epsilon 0.5157203542641982\n",
      "state terminated\n",
      "episode 3312, reward 1561.0, memory_length 2000, epsilon 0.5156172225068648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3313, reward 1235.0, memory_length 2000, epsilon 0.5155141113738204\n",
      "state terminated\n",
      "episode 3314, reward 1714.0, memory_length 2000, epsilon 0.5154110208609406\n",
      "state terminated\n",
      "episode 3315, reward 1359.0, memory_length 2000, epsilon 0.5153079509641018\n",
      "state terminated\n",
      "episode 3316, reward 1353.0, memory_length 2000, epsilon 0.5152049016791809\n",
      "state terminated\n",
      "episode 3317, reward 1677.0, memory_length 2000, epsilon 0.5151018730020562\n",
      "state terminated\n",
      "episode 3318, reward 1380.0, memory_length 2000, epsilon 0.5149988649286065\n",
      "state terminated\n",
      "episode 3319, reward 1396.0, memory_length 2000, epsilon 0.5148958774547114\n",
      "state terminated\n",
      "episode 3320, reward 1377.0, memory_length 2000, epsilon 0.5147929105762515\n",
      "state terminated\n",
      "episode 3321, reward 1436.0, memory_length 2000, epsilon 0.5146899642891082\n",
      "state terminated\n",
      "episode 3322, reward 1426.0, memory_length 2000, epsilon 0.5145870385891634\n",
      "state terminated\n",
      "episode 3323, reward 1433.0, memory_length 2000, epsilon 0.5144841334723003\n",
      "state terminated\n",
      "episode 3324, reward 981.0, memory_length 2000, epsilon 0.5143812489344026\n",
      "state terminated\n",
      "episode 3325, reward 1190.0, memory_length 2000, epsilon 0.5142783849713548\n",
      "state terminated\n",
      "episode 3326, reward 1359.0, memory_length 2000, epsilon 0.5141755415790427\n",
      "state terminated\n",
      "episode 3327, reward 1388.0, memory_length 2000, epsilon 0.5140727187533523\n",
      "state terminated\n",
      "episode 3328, reward 1449.0, memory_length 2000, epsilon 0.5139699164901704\n",
      "state terminated\n",
      "episode 3329, reward 1301.0, memory_length 2000, epsilon 0.5138671347853855\n",
      "state terminated\n",
      "episode 3330, reward 1442.0, memory_length 2000, epsilon 0.513764373634886\n",
      "state terminated\n",
      "episode 3331, reward 1341.0, memory_length 2000, epsilon 0.5136616330345616\n",
      "state terminated\n",
      "episode 3332, reward 1448.0, memory_length 2000, epsilon 0.5135589129803024\n",
      "state terminated\n",
      "episode 3333, reward 1312.0, memory_length 2000, epsilon 0.5134562134679999\n",
      "state terminated\n",
      "episode 3334, reward 1194.0, memory_length 2000, epsilon 0.5133535344935461\n",
      "state terminated\n",
      "episode 3335, reward 1601.0, memory_length 2000, epsilon 0.5132508760528336\n",
      "state terminated\n",
      "episode 3336, reward 1510.0, memory_length 2000, epsilon 0.5131482381417563\n",
      "state terminated\n",
      "episode 3337, reward 1458.0, memory_length 2000, epsilon 0.5130456207562086\n",
      "state terminated\n",
      "episode 3338, reward 1467.0, memory_length 2000, epsilon 0.5129430238920857\n",
      "state terminated\n",
      "episode 3339, reward 1225.0, memory_length 2000, epsilon 0.5128404475452839\n",
      "state terminated\n",
      "episode 3340, reward 1376.0, memory_length 2000, epsilon 0.5127378917117\n",
      "state terminated\n",
      "episode 3341, reward 1378.0, memory_length 2000, epsilon 0.512635356387232\n",
      "state terminated\n",
      "episode 3342, reward 1358.0, memory_length 2000, epsilon 0.5125328415677782\n",
      "state terminated\n",
      "episode 3343, reward 1116.0, memory_length 2000, epsilon 0.5124303472492381\n",
      "state terminated\n",
      "episode 3344, reward 1538.0, memory_length 2000, epsilon 0.512327873427512\n",
      "state terminated\n",
      "episode 3345, reward 1576.0, memory_length 2000, epsilon 0.5122254200985009\n",
      "state terminated\n",
      "episode 3346, reward 1425.0, memory_length 2000, epsilon 0.5121229872581067\n",
      "state terminated\n",
      "episode 3347, reward 1492.0, memory_length 2000, epsilon 0.5120205749022321\n",
      "state terminated\n",
      "episode 3348, reward 1380.0, memory_length 2000, epsilon 0.5119181830267804\n",
      "state terminated\n",
      "episode 3349, reward 1384.0, memory_length 2000, epsilon 0.5118158116276562\n",
      "state terminated\n",
      "episode 3350, reward 1581.0, memory_length 2000, epsilon 0.5117134607007645\n",
      "state terminated\n",
      "episode 3351, reward 1107.0, memory_length 2000, epsilon 0.5116111302420114\n",
      "state terminated\n",
      "episode 3352, reward 1564.0, memory_length 2000, epsilon 0.5115088202473035\n",
      "state terminated\n",
      "episode 3353, reward 1291.0, memory_length 2000, epsilon 0.5114065307125484\n",
      "state terminated\n",
      "episode 3354, reward 1494.0, memory_length 2000, epsilon 0.5113042616336547\n",
      "state terminated\n",
      "episode 3355, reward 1459.0, memory_length 2000, epsilon 0.5112020130065316\n",
      "state terminated\n",
      "episode 3356, reward 1399.0, memory_length 2000, epsilon 0.511099784827089\n",
      "state terminated\n",
      "episode 3357, reward 1651.0, memory_length 2000, epsilon 0.5109975770912378\n",
      "state terminated\n",
      "episode 3358, reward 1387.0, memory_length 2000, epsilon 0.5108953897948898\n",
      "state terminated\n",
      "episode 3359, reward 1183.0, memory_length 2000, epsilon 0.5107932229339576\n",
      "state terminated\n",
      "episode 3360, reward 1601.0, memory_length 2000, epsilon 0.5106910765043542\n",
      "state terminated\n",
      "episode 3361, reward 1531.0, memory_length 2000, epsilon 0.5105889505019939\n",
      "state terminated\n",
      "episode 3362, reward 1193.0, memory_length 2000, epsilon 0.5104868449227918\n",
      "state terminated\n",
      "episode 3363, reward 1052.0, memory_length 2000, epsilon 0.5103847597626635\n",
      "state terminated\n",
      "episode 3364, reward 1623.0, memory_length 2000, epsilon 0.5102826950175258\n",
      "state terminated\n",
      "episode 3365, reward 1434.0, memory_length 2000, epsilon 0.5101806506832958\n",
      "state terminated\n",
      "episode 3366, reward 1468.0, memory_length 2000, epsilon 0.510078626755892\n",
      "state terminated\n",
      "episode 3367, reward 1061.0, memory_length 2000, epsilon 0.5099766232312333\n",
      "state terminated\n",
      "episode 3368, reward 1420.0, memory_length 2000, epsilon 0.5098746401052396\n",
      "state terminated\n",
      "episode 3369, reward 1482.0, memory_length 2000, epsilon 0.5097726773738316\n",
      "state terminated\n",
      "episode 3370, reward 1251.0, memory_length 2000, epsilon 0.5096707350329306\n",
      "state terminated\n",
      "episode 3371, reward 1766.0, memory_length 2000, epsilon 0.5095688130784594\n",
      "state terminated\n",
      "episode 3372, reward 1530.0, memory_length 2000, epsilon 0.5094669115063405\n",
      "state terminated\n",
      "episode 3373, reward 1286.0, memory_length 2000, epsilon 0.5093650303124982\n",
      "state terminated\n",
      "episode 3374, reward 1416.0, memory_length 2000, epsilon 0.5092631694928572\n",
      "state terminated\n",
      "episode 3375, reward 1421.0, memory_length 2000, epsilon 0.5091613290433431\n",
      "state terminated\n",
      "episode 3376, reward 1349.0, memory_length 2000, epsilon 0.5090595089598821\n",
      "state terminated\n",
      "episode 3377, reward 1493.0, memory_length 2000, epsilon 0.5089577092384017\n",
      "state terminated\n",
      "episode 3378, reward 1124.0, memory_length 2000, epsilon 0.5088559298748295\n",
      "state terminated\n",
      "episode 3379, reward 1578.0, memory_length 2000, epsilon 0.5087541708650948\n",
      "state terminated\n",
      "episode 3380, reward 1910.0, memory_length 2000, epsilon 0.5086524322051268\n",
      "state terminated\n",
      "episode 3381, reward 1486.0, memory_length 2000, epsilon 0.5085507138908563\n",
      "state terminated\n",
      "episode 3382, reward 1439.0, memory_length 2000, epsilon 0.5084490159182145\n",
      "state terminated\n",
      "episode 3383, reward 1107.0, memory_length 2000, epsilon 0.5083473382831333\n",
      "state terminated\n",
      "episode 3384, reward 1321.0, memory_length 2000, epsilon 0.5082456809815455\n",
      "state terminated\n",
      "episode 3385, reward 1408.0, memory_length 2000, epsilon 0.5081440440093853\n",
      "state terminated\n",
      "episode 3386, reward 1228.0, memory_length 2000, epsilon 0.5080424273625868\n",
      "state terminated\n",
      "episode 3387, reward 1353.0, memory_length 2000, epsilon 0.5079408310370854\n",
      "state terminated\n",
      "episode 3388, reward 1137.0, memory_length 2000, epsilon 0.5078392550288175\n",
      "state terminated\n",
      "episode 3389, reward 1240.0, memory_length 2000, epsilon 0.5077376993337198\n",
      "state terminated\n",
      "episode 3390, reward 1474.0, memory_length 2000, epsilon 0.5076361639477301\n",
      "state terminated\n",
      "episode 3391, reward 1477.0, memory_length 2000, epsilon 0.507534648866787\n",
      "state terminated\n",
      "episode 3392, reward 1010.0, memory_length 2000, epsilon 0.50743315408683\n",
      "state terminated\n",
      "episode 3393, reward 1717.0, memory_length 2000, epsilon 0.5073316796037991\n",
      "state terminated\n",
      "episode 3394, reward 936.0, memory_length 2000, epsilon 0.5072302254136356\n",
      "state terminated\n",
      "episode 3395, reward 1457.0, memory_length 2000, epsilon 0.5071287915122811\n",
      "state terminated\n",
      "episode 3396, reward 1296.0, memory_length 2000, epsilon 0.5070273778956784\n",
      "state terminated\n",
      "episode 3397, reward 1287.0, memory_length 2000, epsilon 0.5069259845597708\n",
      "state terminated\n",
      "episode 3398, reward 1411.0, memory_length 2000, epsilon 0.5068246115005027\n",
      "state terminated\n",
      "episode 3399, reward 1256.0, memory_length 2000, epsilon 0.5067232587138191\n",
      "state terminated\n",
      "episode 3400, reward 1242.0, memory_length 2000, epsilon 0.5066219261956658\n",
      "state terminated\n",
      "episode 3401, reward 1476.0, memory_length 2000, epsilon 0.5065206139419899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3402, reward 1501.0, memory_length 2000, epsilon 0.5064193219487384\n",
      "state terminated\n",
      "episode 3403, reward 1452.0, memory_length 2000, epsilon 0.50631805021186\n",
      "state terminated\n",
      "episode 3404, reward 1579.0, memory_length 2000, epsilon 0.5062167987273035\n",
      "state terminated\n",
      "episode 3405, reward 1394.0, memory_length 2000, epsilon 0.5061155674910192\n",
      "state terminated\n",
      "episode 3406, reward 1162.0, memory_length 2000, epsilon 0.5060143564989575\n",
      "state terminated\n",
      "episode 3407, reward 1646.0, memory_length 2000, epsilon 0.5059131657470702\n",
      "state terminated\n",
      "episode 3408, reward 1431.0, memory_length 2000, epsilon 0.5058119952313096\n",
      "state terminated\n",
      "episode 3409, reward 1462.0, memory_length 2000, epsilon 0.5057108449476287\n",
      "state terminated\n",
      "episode 3410, reward 1463.0, memory_length 2000, epsilon 0.505609714891982\n",
      "state terminated\n",
      "episode 3411, reward 1429.0, memory_length 2000, epsilon 0.5055086050603238\n",
      "state terminated\n",
      "episode 3412, reward 1246.0, memory_length 2000, epsilon 0.5054075154486098\n",
      "state terminated\n",
      "episode 3413, reward 1349.0, memory_length 2000, epsilon 0.5053064460527966\n",
      "state terminated\n",
      "episode 3414, reward 1341.0, memory_length 2000, epsilon 0.5052053968688412\n",
      "state terminated\n",
      "episode 3415, reward 1369.0, memory_length 2000, epsilon 0.505104367892702\n",
      "state terminated\n",
      "episode 3416, reward 1106.0, memory_length 2000, epsilon 0.5050033591203373\n",
      "state terminated\n",
      "episode 3417, reward 1583.0, memory_length 2000, epsilon 0.5049023705477071\n",
      "state terminated\n",
      "episode 3418, reward 1340.0, memory_length 2000, epsilon 0.504801402170772\n",
      "state terminated\n",
      "episode 3419, reward 1449.0, memory_length 2000, epsilon 0.5047004539854927\n",
      "state terminated\n",
      "episode 3420, reward 1600.0, memory_length 2000, epsilon 0.5045995259878319\n",
      "state terminated\n",
      "episode 3421, reward 1350.0, memory_length 2000, epsilon 0.504498618173752\n",
      "state terminated\n",
      "episode 3422, reward 1555.0, memory_length 2000, epsilon 0.504397730539217\n",
      "state terminated\n",
      "episode 3423, reward 1542.0, memory_length 2000, epsilon 0.5042968630801913\n",
      "state terminated\n",
      "episode 3424, reward 1476.0, memory_length 2000, epsilon 0.5041960157926401\n",
      "state terminated\n",
      "episode 3425, reward 1476.0, memory_length 2000, epsilon 0.5040951886725298\n",
      "state terminated\n",
      "episode 3426, reward 1398.0, memory_length 2000, epsilon 0.5039943817158269\n",
      "state terminated\n",
      "episode 3427, reward 1656.0, memory_length 2000, epsilon 0.5038935949184994\n",
      "state terminated\n",
      "episode 3428, reward 1597.0, memory_length 2000, epsilon 0.5037928282765158\n",
      "state terminated\n",
      "episode 3429, reward 1334.0, memory_length 2000, epsilon 0.5036920817858453\n",
      "state terminated\n",
      "episode 3430, reward 1497.0, memory_length 2000, epsilon 0.5035913554424583\n",
      "state terminated\n",
      "episode 3431, reward 1474.0, memory_length 2000, epsilon 0.5034906492423256\n",
      "state terminated\n",
      "episode 3432, reward 1323.0, memory_length 2000, epsilon 0.5033899631814188\n",
      "state terminated\n",
      "episode 3433, reward 1449.0, memory_length 2000, epsilon 0.5032892972557106\n",
      "state terminated\n",
      "episode 3434, reward 1111.0, memory_length 2000, epsilon 0.5031886514611744\n",
      "state terminated\n",
      "episode 3435, reward 1208.0, memory_length 2000, epsilon 0.5030880257937843\n",
      "state terminated\n",
      "episode 3436, reward 1250.0, memory_length 2000, epsilon 0.5029874202495154\n",
      "state terminated\n",
      "episode 3437, reward 1475.0, memory_length 2000, epsilon 0.5028868348243433\n",
      "state terminated\n",
      "episode 3438, reward 1087.0, memory_length 2000, epsilon 0.5027862695142447\n",
      "state terminated\n",
      "episode 3439, reward 1641.0, memory_length 2000, epsilon 0.5026857243151968\n",
      "state terminated\n",
      "episode 3440, reward 1532.0, memory_length 2000, epsilon 0.502585199223178\n",
      "state terminated\n",
      "episode 3441, reward 1507.0, memory_length 2000, epsilon 0.5024846942341673\n",
      "state terminated\n",
      "episode 3442, reward 1491.0, memory_length 2000, epsilon 0.5023842093441445\n",
      "state terminated\n",
      "episode 3443, reward 1168.0, memory_length 2000, epsilon 0.5022837445490901\n",
      "state terminated\n",
      "episode 3444, reward 1278.0, memory_length 2000, epsilon 0.5021832998449854\n",
      "state terminated\n",
      "episode 3445, reward 1286.0, memory_length 2000, epsilon 0.5020828752278129\n",
      "state terminated\n",
      "episode 3446, reward 1408.0, memory_length 2000, epsilon 0.5019824706935555\n",
      "state terminated\n",
      "episode 3447, reward 1254.0, memory_length 2000, epsilon 0.501882086238197\n",
      "state terminated\n",
      "episode 3448, reward 1106.0, memory_length 2000, epsilon 0.5017817218577219\n",
      "state terminated\n",
      "episode 3449, reward 1318.0, memory_length 2000, epsilon 0.5016813775481158\n",
      "state terminated\n",
      "episode 3450, reward 1300.0, memory_length 2000, epsilon 0.5015810533053647\n",
      "state terminated\n",
      "episode 3451, reward 1619.0, memory_length 2000, epsilon 0.5014807491254561\n",
      "state terminated\n",
      "episode 3452, reward 1089.0, memory_length 2000, epsilon 0.5013804650043774\n",
      "state terminated\n",
      "episode 3453, reward 1444.0, memory_length 2000, epsilon 0.5012802009381173\n",
      "state terminated\n",
      "episode 3454, reward 1332.0, memory_length 2000, epsilon 0.5011799569226654\n",
      "state terminated\n",
      "episode 3455, reward 1384.0, memory_length 2000, epsilon 0.5010797329540119\n",
      "state terminated\n",
      "episode 3456, reward 1668.0, memory_length 2000, epsilon 0.5009795290281476\n",
      "state terminated\n",
      "episode 3457, reward 1435.0, memory_length 2000, epsilon 0.5008793451410647\n",
      "state terminated\n",
      "episode 3458, reward 1378.0, memory_length 2000, epsilon 0.5007791812887555\n",
      "state terminated\n",
      "episode 3459, reward 1485.0, memory_length 2000, epsilon 0.5006790374672138\n",
      "state terminated\n",
      "episode 3460, reward 1358.0, memory_length 2000, epsilon 0.5005789136724336\n",
      "state terminated\n",
      "episode 3461, reward 1276.0, memory_length 2000, epsilon 0.5004788099004099\n",
      "state terminated\n",
      "episode 3462, reward 1299.0, memory_length 2000, epsilon 0.5003787261471389\n",
      "state terminated\n",
      "episode 3463, reward 1443.0, memory_length 2000, epsilon 0.5002786624086168\n",
      "state terminated\n",
      "episode 3464, reward 1341.0, memory_length 2000, epsilon 0.5001786186808413\n",
      "state terminated\n",
      "episode 3465, reward 1482.0, memory_length 2000, epsilon 0.5000785949598107\n",
      "state terminated\n",
      "episode 3466, reward 1406.0, memory_length 2000, epsilon 0.49997859124152394\n",
      "state terminated\n",
      "episode 3467, reward 1515.0, memory_length 2000, epsilon 0.4998786075219808\n",
      "state terminated\n",
      "episode 3468, reward 1420.0, memory_length 2000, epsilon 0.4997786437971822\n",
      "state terminated\n",
      "episode 3469, reward 1529.0, memory_length 2000, epsilon 0.49967870006312926\n",
      "state terminated\n",
      "episode 3470, reward 1479.0, memory_length 2000, epsilon 0.4995787763158244\n",
      "state terminated\n",
      "episode 3471, reward 1125.0, memory_length 2000, epsilon 0.49947887255127077\n",
      "state terminated\n",
      "episode 3472, reward 1513.0, memory_length 2000, epsilon 0.49937898876547204\n",
      "state terminated\n",
      "episode 3473, reward 1623.0, memory_length 2000, epsilon 0.49927912495443294\n",
      "state terminated\n",
      "episode 3474, reward 1039.0, memory_length 2000, epsilon 0.4991792811141588\n",
      "state terminated\n",
      "episode 3475, reward 1519.0, memory_length 2000, epsilon 0.4990794572406561\n",
      "state terminated\n",
      "episode 3476, reward 1403.0, memory_length 2000, epsilon 0.4989796533299317\n",
      "state terminated\n",
      "episode 3477, reward 1396.0, memory_length 2000, epsilon 0.4988798693779936\n",
      "state terminated\n",
      "episode 3478, reward 1430.0, memory_length 2000, epsilon 0.49878010538085027\n",
      "state terminated\n",
      "episode 3479, reward 1327.0, memory_length 2000, epsilon 0.49868036133451116\n",
      "state terminated\n",
      "episode 3480, reward 1568.0, memory_length 2000, epsilon 0.49858063723498663\n",
      "state terminated\n",
      "episode 3481, reward 1631.0, memory_length 2000, epsilon 0.4984809330782876\n",
      "state terminated\n",
      "episode 3482, reward 1755.0, memory_length 2000, epsilon 0.49838124886042606\n",
      "state terminated\n",
      "episode 3483, reward 1140.0, memory_length 2000, epsilon 0.4982815845774145\n",
      "state terminated\n",
      "episode 3484, reward 1487.0, memory_length 2000, epsilon 0.49818194022526635\n",
      "state terminated\n",
      "episode 3485, reward 1754.0, memory_length 2000, epsilon 0.49808231579999596\n",
      "state terminated\n",
      "episode 3486, reward 1457.0, memory_length 2000, epsilon 0.4979827112976182\n",
      "state terminated\n",
      "episode 3487, reward 1740.0, memory_length 2000, epsilon 0.49788312671414897\n",
      "state terminated\n",
      "episode 3488, reward 1261.0, memory_length 2000, epsilon 0.4977835620456049\n",
      "state terminated\n",
      "episode 3489, reward 1179.0, memory_length 2000, epsilon 0.49768401728800327\n",
      "state terminated\n",
      "episode 3490, reward 1402.0, memory_length 2000, epsilon 0.4975844924373625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3491, reward 1240.0, memory_length 2000, epsilon 0.49748498748970155\n",
      "state terminated\n",
      "episode 3492, reward 1392.0, memory_length 2000, epsilon 0.4973855024410401\n",
      "state terminated\n",
      "episode 3493, reward 1556.0, memory_length 2000, epsilon 0.49728603728739873\n",
      "state terminated\n",
      "episode 3494, reward 1312.0, memory_length 2000, epsilon 0.49718659202479903\n",
      "state terminated\n",
      "episode 3495, reward 1471.0, memory_length 2000, epsilon 0.497087166649263\n",
      "state terminated\n",
      "episode 3496, reward 1842.0, memory_length 2000, epsilon 0.4969877611568138\n",
      "state terminated\n",
      "episode 3497, reward 904.0, memory_length 2000, epsilon 0.49688837554347504\n",
      "state terminated\n",
      "episode 3498, reward 1255.0, memory_length 2000, epsilon 0.4967890098052714\n",
      "state terminated\n",
      "episode 3499, reward 1645.0, memory_length 2000, epsilon 0.49668966393822817\n",
      "state terminated\n",
      "episode 3500, reward 1620.0, memory_length 2000, epsilon 0.4965903379383716\n",
      "state terminated\n",
      "episode 3501, reward 1758.0, memory_length 2000, epsilon 0.4964910318017286\n",
      "state terminated\n",
      "episode 3502, reward 1458.0, memory_length 2000, epsilon 0.496391745524327\n",
      "state terminated\n",
      "episode 3503, reward 1469.0, memory_length 2000, epsilon 0.4962924791021952\n",
      "state terminated\n",
      "episode 3504, reward 1579.0, memory_length 2000, epsilon 0.4961932325313627\n",
      "state terminated\n",
      "episode 3505, reward 1359.0, memory_length 2000, epsilon 0.4960940058078595\n",
      "state terminated\n",
      "episode 3506, reward 1723.0, memory_length 2000, epsilon 0.49599479892771664\n",
      "state terminated\n",
      "episode 3507, reward 1565.0, memory_length 2000, epsilon 0.4958956118869658\n",
      "state terminated\n",
      "episode 3508, reward 1340.0, memory_length 2000, epsilon 0.4957964446816395\n",
      "state terminated\n",
      "episode 3509, reward 1700.0, memory_length 2000, epsilon 0.49569729730777107\n",
      "state terminated\n",
      "episode 3510, reward 1187.0, memory_length 2000, epsilon 0.49559816976139454\n",
      "state terminated\n",
      "episode 3511, reward 1070.0, memory_length 2000, epsilon 0.4954990620385449\n",
      "state terminated\n",
      "episode 3512, reward 1579.0, memory_length 2000, epsilon 0.4953999741352578\n",
      "state terminated\n",
      "episode 3513, reward 1251.0, memory_length 2000, epsilon 0.49530090604756977\n",
      "state terminated\n",
      "episode 3514, reward 1638.0, memory_length 2000, epsilon 0.4952018577715181\n",
      "state terminated\n",
      "episode 3515, reward 1351.0, memory_length 2000, epsilon 0.49510282930314065\n",
      "state terminated\n",
      "episode 3516, reward 1646.0, memory_length 2000, epsilon 0.49500382063847653\n",
      "state terminated\n",
      "episode 3517, reward 1660.0, memory_length 2000, epsilon 0.4949048317735653\n",
      "state terminated\n",
      "episode 3518, reward 1645.0, memory_length 2000, epsilon 0.4948058627044474\n",
      "state terminated\n",
      "episode 3519, reward 1394.0, memory_length 2000, epsilon 0.4947069134271641\n",
      "state terminated\n",
      "episode 3520, reward 1342.0, memory_length 2000, epsilon 0.49460798393775735\n",
      "state terminated\n",
      "episode 3521, reward 1371.0, memory_length 2000, epsilon 0.49450907423227\n",
      "state terminated\n",
      "episode 3522, reward 1474.0, memory_length 2000, epsilon 0.49441018430674577\n",
      "state terminated\n",
      "episode 3523, reward 1443.0, memory_length 2000, epsilon 0.49431131415722895\n",
      "state terminated\n",
      "episode 3524, reward 1506.0, memory_length 2000, epsilon 0.4942124637797648\n",
      "state terminated\n",
      "episode 3525, reward 1699.0, memory_length 2000, epsilon 0.4941136331703991\n",
      "state terminated\n",
      "episode 3526, reward 1420.0, memory_length 2000, epsilon 0.49401482232517896\n",
      "state terminated\n",
      "episode 3527, reward 1614.0, memory_length 2000, epsilon 0.49391603124015176\n",
      "state terminated\n",
      "episode 3528, reward 1399.0, memory_length 2000, epsilon 0.4938172599113658\n",
      "state terminated\n",
      "episode 3529, reward 1381.0, memory_length 2000, epsilon 0.4937185083348704\n",
      "state terminated\n",
      "episode 3530, reward 1193.0, memory_length 2000, epsilon 0.4936197765067153\n",
      "state terminated\n",
      "episode 3531, reward 1582.0, memory_length 2000, epsilon 0.49352106442295135\n",
      "state terminated\n",
      "episode 3532, reward 1484.0, memory_length 2000, epsilon 0.4934223720796301\n",
      "state terminated\n",
      "episode 3533, reward 1667.0, memory_length 2000, epsilon 0.4933236994728038\n",
      "state terminated\n",
      "episode 3534, reward 1351.0, memory_length 2000, epsilon 0.49322504659852545\n",
      "state terminated\n",
      "episode 3535, reward 1592.0, memory_length 2000, epsilon 0.4931264134528491\n",
      "state terminated\n",
      "episode 3536, reward 1992.0, memory_length 2000, epsilon 0.49302780003182933\n",
      "state terminated\n",
      "episode 3537, reward 1649.0, memory_length 2000, epsilon 0.49292920633152165\n",
      "state terminated\n",
      "episode 3538, reward 1623.0, memory_length 2000, epsilon 0.4928306323479823\n",
      "state terminated\n",
      "episode 3539, reward 1613.0, memory_length 2000, epsilon 0.49273207807726827\n",
      "state terminated\n",
      "episode 3540, reward 1506.0, memory_length 2000, epsilon 0.4926335435154374\n",
      "state terminated\n",
      "episode 3541, reward 1596.0, memory_length 2000, epsilon 0.4925350286585484\n",
      "state terminated\n",
      "episode 3542, reward 1245.0, memory_length 2000, epsilon 0.49243653350266064\n",
      "state terminated\n",
      "episode 3543, reward 1531.0, memory_length 2000, epsilon 0.49233805804383424\n",
      "state terminated\n",
      "episode 3544, reward 1777.0, memory_length 2000, epsilon 0.49223960227813024\n",
      "state terminated\n",
      "episode 3545, reward 1412.0, memory_length 2000, epsilon 0.49214116620161036\n",
      "state terminated\n",
      "episode 3546, reward 1330.0, memory_length 2000, epsilon 0.49204274981033724\n",
      "state terminated\n",
      "episode 3547, reward 1309.0, memory_length 2000, epsilon 0.49194435310037415\n",
      "state terminated\n",
      "episode 3548, reward 1372.0, memory_length 2000, epsilon 0.4918459760677853\n",
      "state terminated\n",
      "episode 3549, reward 1413.0, memory_length 2000, epsilon 0.49174761870863554\n",
      "state terminated\n",
      "episode 3550, reward 1741.0, memory_length 2000, epsilon 0.49164928101899047\n",
      "state terminated\n",
      "episode 3551, reward 1584.0, memory_length 2000, epsilon 0.49155096299491685\n",
      "state terminated\n",
      "episode 3552, reward 1456.0, memory_length 2000, epsilon 0.4914526646324818\n",
      "state terminated\n",
      "episode 3553, reward 1417.0, memory_length 2000, epsilon 0.4913543859277533\n",
      "state terminated\n",
      "episode 3554, reward 1178.0, memory_length 2000, epsilon 0.4912561268768004\n",
      "state terminated\n",
      "episode 3555, reward 1465.0, memory_length 2000, epsilon 0.4911578874756926\n",
      "state terminated\n",
      "episode 3556, reward 1425.0, memory_length 2000, epsilon 0.49105966772050036\n",
      "state terminated\n",
      "episode 3557, reward 1163.0, memory_length 2000, epsilon 0.490961467607295\n",
      "state terminated\n",
      "episode 3558, reward 1194.0, memory_length 2000, epsilon 0.4908632871321483\n",
      "state terminated\n",
      "episode 3559, reward 1599.0, memory_length 2000, epsilon 0.49076512629113317\n",
      "state terminated\n",
      "episode 3560, reward 1502.0, memory_length 2000, epsilon 0.49066698508032314\n",
      "state terminated\n",
      "episode 3561, reward 1318.0, memory_length 2000, epsilon 0.49056886349579265\n",
      "state terminated\n",
      "episode 3562, reward 1444.0, memory_length 2000, epsilon 0.4904707615336167\n",
      "state terminated\n",
      "episode 3563, reward 1399.0, memory_length 2000, epsilon 0.4903726791898713\n",
      "state terminated\n",
      "episode 3564, reward 1582.0, memory_length 2000, epsilon 0.4902746164606331\n",
      "state terminated\n",
      "episode 3565, reward 1573.0, memory_length 2000, epsilon 0.4901765733419796\n",
      "state terminated\n",
      "episode 3566, reward 1568.0, memory_length 2000, epsilon 0.4900785498299892\n",
      "state terminated\n",
      "episode 3567, reward 1548.0, memory_length 2000, epsilon 0.4899805459207408\n",
      "state terminated\n",
      "episode 3568, reward 1677.0, memory_length 2000, epsilon 0.48988256161031435\n",
      "state terminated\n",
      "episode 3569, reward 1395.0, memory_length 2000, epsilon 0.48978459689479037\n",
      "state terminated\n",
      "episode 3570, reward 1578.0, memory_length 2000, epsilon 0.48968665177025034\n",
      "state terminated\n",
      "episode 3571, reward 1300.0, memory_length 2000, epsilon 0.48958872623277644\n",
      "state terminated\n",
      "episode 3572, reward 1835.0, memory_length 2000, epsilon 0.4894908202784517\n",
      "state terminated\n",
      "episode 3573, reward 1300.0, memory_length 2000, epsilon 0.4893929339033598\n",
      "state terminated\n",
      "episode 3574, reward 1287.0, memory_length 2000, epsilon 0.48929506710358533\n",
      "state terminated\n",
      "episode 3575, reward 1394.0, memory_length 2000, epsilon 0.48919721987521353\n",
      "state terminated\n",
      "episode 3576, reward 1260.0, memory_length 2000, epsilon 0.4890993922143307\n",
      "state terminated\n",
      "episode 3577, reward 1755.0, memory_length 2000, epsilon 0.4890015841170236\n",
      "state terminated\n",
      "episode 3578, reward 1023.0, memory_length 2000, epsilon 0.48890379557937996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3579, reward 1458.0, memory_length 2000, epsilon 0.4888060265974882\n",
      "state terminated\n",
      "episode 3580, reward 1645.0, memory_length 2000, epsilon 0.4887082771674375\n",
      "state terminated\n",
      "episode 3581, reward 1534.0, memory_length 2000, epsilon 0.488610547285318\n",
      "state terminated\n",
      "episode 3582, reward 1466.0, memory_length 2000, epsilon 0.4885128369472204\n",
      "state terminated\n",
      "episode 3583, reward 1341.0, memory_length 2000, epsilon 0.4884151461492364\n",
      "state terminated\n",
      "episode 3584, reward 1411.0, memory_length 2000, epsilon 0.4883174748874583\n",
      "state terminated\n",
      "episode 3585, reward 1209.0, memory_length 2000, epsilon 0.48821982315797924\n",
      "state terminated\n",
      "episode 3586, reward 1390.0, memory_length 2000, epsilon 0.48812219095689324\n",
      "state terminated\n",
      "episode 3587, reward 1546.0, memory_length 2000, epsilon 0.4880245782802949\n",
      "state terminated\n",
      "episode 3588, reward 1335.0, memory_length 2000, epsilon 0.4879269851242798\n",
      "state terminated\n",
      "episode 3589, reward 1395.0, memory_length 2000, epsilon 0.4878294114849441\n",
      "state terminated\n",
      "episode 3590, reward 1549.0, memory_length 2000, epsilon 0.4877318573583849\n",
      "state terminated\n",
      "episode 3591, reward 1552.0, memory_length 2000, epsilon 0.4876343227407001\n",
      "state terminated\n",
      "episode 3592, reward 1816.0, memory_length 2000, epsilon 0.4875368076279883\n",
      "state terminated\n",
      "episode 3593, reward 1398.0, memory_length 2000, epsilon 0.4874393120163488\n",
      "state terminated\n",
      "episode 3594, reward 1327.0, memory_length 2000, epsilon 0.48734183590188196\n",
      "state terminated\n",
      "episode 3595, reward 1559.0, memory_length 2000, epsilon 0.4872443792806885\n",
      "state terminated\n",
      "episode 3596, reward 1543.0, memory_length 2000, epsilon 0.4871469421488704\n",
      "state terminated\n",
      "episode 3597, reward 1650.0, memory_length 2000, epsilon 0.48704952450253\n",
      "state terminated\n",
      "episode 3598, reward 1562.0, memory_length 2000, epsilon 0.48695212633777063\n",
      "state terminated\n",
      "episode 3599, reward 1530.0, memory_length 2000, epsilon 0.48685474765069636\n",
      "state terminated\n",
      "episode 3600, reward 1377.0, memory_length 2000, epsilon 0.48675738843741206\n",
      "state terminated\n",
      "episode 3601, reward 1368.0, memory_length 2000, epsilon 0.4866600486940234\n",
      "state terminated\n",
      "episode 3602, reward 1574.0, memory_length 2000, epsilon 0.48656272841663667\n",
      "state terminated\n",
      "episode 3603, reward 1458.0, memory_length 2000, epsilon 0.48646542760135925\n",
      "state terminated\n",
      "episode 3604, reward 1341.0, memory_length 2000, epsilon 0.48636814624429897\n",
      "state terminated\n",
      "episode 3605, reward 1419.0, memory_length 2000, epsilon 0.48627088434156457\n",
      "state terminated\n",
      "episode 3606, reward 1223.0, memory_length 2000, epsilon 0.48617364188926565\n",
      "state terminated\n",
      "episode 3607, reward 1503.0, memory_length 2000, epsilon 0.48607641888351244\n",
      "state terminated\n",
      "episode 3608, reward 941.0, memory_length 2000, epsilon 0.48597921532041605\n",
      "state terminated\n",
      "episode 3609, reward 1371.0, memory_length 2000, epsilon 0.4858820311960884\n",
      "state terminated\n",
      "episode 3610, reward 1547.0, memory_length 2000, epsilon 0.48578486650664193\n",
      "state terminated\n",
      "episode 3611, reward 1200.0, memory_length 2000, epsilon 0.48568772124819026\n",
      "state terminated\n",
      "episode 3612, reward 1528.0, memory_length 2000, epsilon 0.4855905954168475\n",
      "state terminated\n",
      "episode 3613, reward 1521.0, memory_length 2000, epsilon 0.4854934890087287\n",
      "state terminated\n",
      "episode 3614, reward 1367.0, memory_length 2000, epsilon 0.4853964020199495\n",
      "state terminated\n",
      "episode 3615, reward 1647.0, memory_length 2000, epsilon 0.4852993344466263\n",
      "state terminated\n",
      "episode 3616, reward 1433.0, memory_length 2000, epsilon 0.48520228628487666\n",
      "state terminated\n",
      "episode 3617, reward 1457.0, memory_length 2000, epsilon 0.48510525753081857\n",
      "state terminated\n",
      "episode 3618, reward 1111.0, memory_length 2000, epsilon 0.48500824818057076\n",
      "state terminated\n",
      "episode 3619, reward 1304.0, memory_length 2000, epsilon 0.484911258230253\n",
      "state terminated\n",
      "episode 3620, reward 1586.0, memory_length 2000, epsilon 0.48481428767598556\n",
      "state terminated\n",
      "episode 3621, reward 1507.0, memory_length 2000, epsilon 0.48471733651388976\n",
      "state terminated\n",
      "episode 3622, reward 1656.0, memory_length 2000, epsilon 0.4846204047400875\n",
      "state terminated\n",
      "episode 3623, reward 1435.0, memory_length 2000, epsilon 0.4845234923507014\n",
      "state terminated\n",
      "episode 3624, reward 1367.0, memory_length 2000, epsilon 0.4844265993418552\n",
      "state terminated\n",
      "episode 3625, reward 1843.0, memory_length 2000, epsilon 0.48432972570967286\n",
      "state terminated\n",
      "episode 3626, reward 1150.0, memory_length 2000, epsilon 0.48423287145027977\n",
      "state terminated\n",
      "episode 3627, reward 1420.0, memory_length 2000, epsilon 0.4841360365598016\n",
      "state terminated\n",
      "episode 3628, reward 1609.0, memory_length 2000, epsilon 0.48403922103436486\n",
      "state terminated\n",
      "episode 3629, reward 1528.0, memory_length 2000, epsilon 0.4839424248700971\n",
      "state terminated\n",
      "episode 3630, reward 1615.0, memory_length 2000, epsilon 0.4838456480631263\n",
      "state terminated\n",
      "episode 3631, reward 1615.0, memory_length 2000, epsilon 0.48374889060958154\n",
      "state terminated\n",
      "episode 3632, reward 1458.0, memory_length 2000, epsilon 0.4836521525055925\n",
      "state terminated\n",
      "episode 3633, reward 1286.0, memory_length 2000, epsilon 0.48355543374728965\n",
      "state terminated\n",
      "episode 3634, reward 1450.0, memory_length 2000, epsilon 0.48345873433080416\n",
      "state terminated\n",
      "episode 3635, reward 1521.0, memory_length 2000, epsilon 0.48336205425226814\n",
      "state terminated\n",
      "episode 3636, reward 1809.0, memory_length 2000, epsilon 0.4832653935078143\n",
      "state terminated\n",
      "episode 3637, reward 1557.0, memory_length 2000, epsilon 0.48316875209357635\n",
      "state terminated\n",
      "episode 3638, reward 1494.0, memory_length 2000, epsilon 0.4830721300056885\n",
      "state terminated\n",
      "episode 3639, reward 1449.0, memory_length 2000, epsilon 0.4829755272402859\n",
      "state terminated\n",
      "episode 3640, reward 1509.0, memory_length 2000, epsilon 0.4828789437935045\n",
      "state terminated\n",
      "episode 3641, reward 1369.0, memory_length 2000, epsilon 0.4827823796614808\n",
      "state terminated\n",
      "episode 3642, reward 1561.0, memory_length 2000, epsilon 0.48268583484035243\n",
      "state terminated\n",
      "episode 3643, reward 1418.0, memory_length 2000, epsilon 0.48258930932625754\n",
      "state terminated\n",
      "episode 3644, reward 1278.0, memory_length 2000, epsilon 0.4824928031153351\n",
      "state terminated\n",
      "episode 3645, reward 1437.0, memory_length 2000, epsilon 0.4823963162037248\n",
      "state terminated\n",
      "episode 3646, reward 1490.0, memory_length 2000, epsilon 0.4822998485875672\n",
      "state terminated\n",
      "episode 3647, reward 1393.0, memory_length 2000, epsilon 0.4822034002630037\n",
      "state terminated\n",
      "episode 3648, reward 1300.0, memory_length 2000, epsilon 0.4821069712261762\n",
      "state terminated\n",
      "episode 3649, reward 1401.0, memory_length 2000, epsilon 0.48201056147322763\n",
      "state terminated\n",
      "episode 3650, reward 1577.0, memory_length 2000, epsilon 0.4819141710003016\n",
      "state terminated\n",
      "episode 3651, reward 1379.0, memory_length 2000, epsilon 0.4818177998035424\n",
      "state terminated\n",
      "episode 3652, reward 1524.0, memory_length 2000, epsilon 0.4817214478790953\n",
      "state terminated\n",
      "episode 3653, reward 1493.0, memory_length 2000, epsilon 0.4816251152231062\n",
      "state terminated\n",
      "episode 3654, reward 1533.0, memory_length 2000, epsilon 0.4815288018317218\n",
      "state terminated\n",
      "episode 3655, reward 1569.0, memory_length 2000, epsilon 0.4814325077010895\n",
      "state terminated\n",
      "episode 3656, reward 1725.0, memory_length 2000, epsilon 0.4813362328273575\n",
      "state terminated\n",
      "episode 3657, reward 1628.0, memory_length 2000, epsilon 0.481239977206675\n",
      "state terminated\n",
      "episode 3658, reward 1269.0, memory_length 2000, epsilon 0.4811437408351916\n",
      "state terminated\n",
      "episode 3659, reward 1251.0, memory_length 2000, epsilon 0.48104752370905784\n",
      "state terminated\n",
      "episode 3660, reward 1448.0, memory_length 2000, epsilon 0.4809513258244252\n",
      "state terminated\n",
      "episode 3661, reward 1777.0, memory_length 2000, epsilon 0.4808551471774456\n",
      "state terminated\n",
      "episode 3662, reward 1089.0, memory_length 2000, epsilon 0.48075898776427195\n",
      "state terminated\n",
      "episode 3663, reward 1424.0, memory_length 2000, epsilon 0.4806628475810579\n",
      "state terminated\n",
      "episode 3664, reward 1557.0, memory_length 2000, epsilon 0.48056672662395783\n",
      "state terminated\n",
      "episode 3665, reward 1339.0, memory_length 2000, epsilon 0.48047062488912684\n",
      "state terminated\n",
      "episode 3666, reward 1358.0, memory_length 2000, epsilon 0.4803745423727209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3667, reward 1438.0, memory_length 2000, epsilon 0.48027847907089677\n",
      "state terminated\n",
      "episode 3668, reward 1038.0, memory_length 2000, epsilon 0.48018243497981183\n",
      "state terminated\n",
      "episode 3669, reward 1601.0, memory_length 2000, epsilon 0.48008641009562436\n",
      "state terminated\n",
      "episode 3670, reward 1565.0, memory_length 2000, epsilon 0.47999040441449337\n",
      "state terminated\n",
      "episode 3671, reward 1604.0, memory_length 2000, epsilon 0.47989441793257864\n",
      "state terminated\n",
      "episode 3672, reward 1476.0, memory_length 2000, epsilon 0.47979845064604065\n",
      "state terminated\n",
      "episode 3673, reward 1471.0, memory_length 2000, epsilon 0.4797025025510408\n",
      "state terminated\n",
      "episode 3674, reward 1589.0, memory_length 2000, epsilon 0.47960657364374104\n",
      "state terminated\n",
      "episode 3675, reward 1723.0, memory_length 2000, epsilon 0.4795106639203044\n",
      "state terminated\n",
      "episode 3676, reward 1588.0, memory_length 2000, epsilon 0.47941477337689425\n",
      "state terminated\n",
      "episode 3677, reward 1476.0, memory_length 2000, epsilon 0.4793189020096752\n",
      "state terminated\n",
      "episode 3678, reward 1539.0, memory_length 2000, epsilon 0.47922304981481223\n",
      "state terminated\n",
      "episode 3679, reward 1441.0, memory_length 2000, epsilon 0.47912721678847137\n",
      "state terminated\n",
      "episode 3680, reward 1630.0, memory_length 2000, epsilon 0.4790314029268193\n",
      "state terminated\n",
      "episode 3681, reward 1471.0, memory_length 2000, epsilon 0.4789356082260232\n",
      "state terminated\n",
      "episode 3682, reward 1605.0, memory_length 2000, epsilon 0.47883983268225166\n",
      "state terminated\n",
      "episode 3683, reward 1836.0, memory_length 2000, epsilon 0.4787440762916734\n",
      "state terminated\n",
      "episode 3684, reward 1386.0, memory_length 2000, epsilon 0.4786483390504584\n",
      "state terminated\n",
      "episode 3685, reward 1622.0, memory_length 2000, epsilon 0.47855262095477696\n",
      "state terminated\n",
      "episode 3686, reward 1219.0, memory_length 2000, epsilon 0.4784569220008003\n",
      "state terminated\n",
      "episode 3687, reward 1587.0, memory_length 2000, epsilon 0.4783612421847007\n",
      "state terminated\n",
      "episode 3688, reward 1588.0, memory_length 2000, epsilon 0.47826558150265086\n",
      "state terminated\n",
      "episode 3689, reward 1447.0, memory_length 2000, epsilon 0.47816993995082435\n",
      "state terminated\n",
      "episode 3690, reward 1474.0, memory_length 2000, epsilon 0.4780743175253955\n",
      "state terminated\n",
      "episode 3691, reward 1547.0, memory_length 2000, epsilon 0.4779787142225393\n",
      "state terminated\n",
      "episode 3692, reward 1573.0, memory_length 2000, epsilon 0.4778831300384318\n",
      "state terminated\n",
      "episode 3693, reward 1812.0, memory_length 2000, epsilon 0.4777875649692496\n",
      "state terminated\n",
      "episode 3694, reward 1546.0, memory_length 2000, epsilon 0.4776920190111701\n",
      "state terminated\n",
      "episode 3695, reward 1521.0, memory_length 2000, epsilon 0.47759649216037137\n",
      "state terminated\n",
      "episode 3696, reward 1267.0, memory_length 2000, epsilon 0.4775009844130323\n",
      "state terminated\n",
      "episode 3697, reward 1204.0, memory_length 2000, epsilon 0.4774054957653328\n",
      "state terminated\n",
      "episode 3698, reward 1606.0, memory_length 2000, epsilon 0.4773100262134532\n",
      "state terminated\n",
      "episode 3699, reward 1462.0, memory_length 2000, epsilon 0.4772145757535747\n",
      "state terminated\n",
      "episode 3700, reward 1428.0, memory_length 2000, epsilon 0.4771191443818792\n",
      "state terminated\n",
      "episode 3701, reward 1665.0, memory_length 2000, epsilon 0.47702373209454957\n",
      "state terminated\n",
      "episode 3702, reward 1632.0, memory_length 2000, epsilon 0.4769283388877693\n",
      "state terminated\n",
      "episode 3703, reward 1839.0, memory_length 2000, epsilon 0.4768329647577227\n",
      "state terminated\n",
      "episode 3704, reward 1675.0, memory_length 2000, epsilon 0.4767376097005947\n",
      "state terminated\n",
      "episode 3705, reward 1612.0, memory_length 2000, epsilon 0.47664227371257123\n",
      "state terminated\n",
      "episode 3706, reward 1790.0, memory_length 2000, epsilon 0.47654695678983866\n",
      "state terminated\n",
      "episode 3707, reward 1413.0, memory_length 2000, epsilon 0.4764516589285845\n",
      "state terminated\n",
      "episode 3708, reward 1610.0, memory_length 2000, epsilon 0.4763563801249967\n",
      "state terminated\n",
      "episode 3709, reward 1690.0, memory_length 2000, epsilon 0.47626112037526425\n",
      "state terminated\n",
      "episode 3710, reward 1559.0, memory_length 2000, epsilon 0.47616587967557666\n",
      "state terminated\n",
      "episode 3711, reward 1843.0, memory_length 2000, epsilon 0.4760706580221242\n",
      "state terminated\n",
      "episode 3712, reward 1858.0, memory_length 2000, epsilon 0.47597545541109826\n",
      "state terminated\n",
      "episode 3713, reward 1654.0, memory_length 2000, epsilon 0.4758802718386906\n",
      "state terminated\n",
      "episode 3714, reward 1371.0, memory_length 2000, epsilon 0.4757851073010938\n",
      "state terminated\n",
      "episode 3715, reward 1745.0, memory_length 2000, epsilon 0.47568996179450146\n",
      "state terminated\n",
      "episode 3716, reward 1735.0, memory_length 2000, epsilon 0.4755948353151075\n",
      "state terminated\n",
      "episode 3717, reward 1858.0, memory_length 2000, epsilon 0.4754997278591071\n",
      "state terminated\n",
      "episode 3718, reward 1111.0, memory_length 2000, epsilon 0.47540463942269595\n",
      "state terminated\n",
      "episode 3719, reward 1443.0, memory_length 2000, epsilon 0.47530957000207036\n",
      "state terminated\n",
      "episode 3720, reward 1826.0, memory_length 2000, epsilon 0.47521451959342764\n",
      "state terminated\n",
      "episode 3721, reward 1695.0, memory_length 2000, epsilon 0.47511948819296573\n",
      "state terminated\n",
      "episode 3722, reward 1115.0, memory_length 2000, epsilon 0.47502447579688345\n",
      "state terminated\n",
      "episode 3723, reward 1016.0, memory_length 2000, epsilon 0.4749294824013803\n",
      "state terminated\n",
      "episode 3724, reward 1479.0, memory_length 2000, epsilon 0.4748345080026565\n",
      "state terminated\n",
      "episode 3725, reward 1574.0, memory_length 2000, epsilon 0.47473955259691303\n",
      "state terminated\n",
      "episode 3726, reward 1557.0, memory_length 2000, epsilon 0.4746446161803517\n",
      "state terminated\n",
      "episode 3727, reward 1599.0, memory_length 2000, epsilon 0.4745496987491752\n",
      "state terminated\n",
      "episode 3728, reward 1467.0, memory_length 2000, epsilon 0.47445480029958664\n",
      "state terminated\n",
      "episode 3729, reward 1584.0, memory_length 2000, epsilon 0.4743599208277902\n",
      "state terminated\n",
      "episode 3730, reward 1224.0, memory_length 2000, epsilon 0.47426506032999066\n",
      "state terminated\n",
      "episode 3731, reward 1309.0, memory_length 2000, epsilon 0.47417021880239346\n",
      "state terminated\n",
      "episode 3732, reward 1511.0, memory_length 2000, epsilon 0.4740753962412052\n",
      "state terminated\n",
      "episode 3733, reward 1353.0, memory_length 2000, epsilon 0.47398059264263287\n",
      "state terminated\n",
      "episode 3734, reward 1669.0, memory_length 2000, epsilon 0.4738858080028842\n",
      "state terminated\n",
      "episode 3735, reward 1136.0, memory_length 2000, epsilon 0.47379104231816804\n",
      "state terminated\n",
      "episode 3736, reward 1905.0, memory_length 2000, epsilon 0.4736962955846935\n",
      "state terminated\n",
      "episode 3737, reward 1468.0, memory_length 2000, epsilon 0.47360156779867096\n",
      "state terminated\n",
      "episode 3738, reward 1242.0, memory_length 2000, epsilon 0.47350685895631117\n",
      "state terminated\n",
      "episode 3739, reward 1649.0, memory_length 2000, epsilon 0.47341216905382577\n",
      "state terminated\n",
      "episode 3740, reward 1543.0, memory_length 2000, epsilon 0.47331749808742724\n",
      "state terminated\n",
      "episode 3741, reward 1228.0, memory_length 2000, epsilon 0.47322284605332865\n",
      "state terminated\n",
      "episode 3742, reward 1255.0, memory_length 2000, epsilon 0.47312821294774404\n",
      "state terminated\n",
      "episode 3743, reward 1582.0, memory_length 2000, epsilon 0.47303359876688794\n",
      "state terminated\n",
      "episode 3744, reward 1421.0, memory_length 2000, epsilon 0.4729390035069759\n",
      "state terminated\n",
      "episode 3745, reward 1354.0, memory_length 2000, epsilon 0.47284442716422403\n",
      "state terminated\n",
      "episode 3746, reward 1466.0, memory_length 2000, epsilon 0.4727498697348492\n",
      "state terminated\n",
      "episode 3747, reward 1179.0, memory_length 2000, epsilon 0.47265533121506936\n",
      "state terminated\n",
      "episode 3748, reward 1524.0, memory_length 2000, epsilon 0.47256081160110286\n",
      "state terminated\n",
      "episode 3749, reward 1521.0, memory_length 2000, epsilon 0.4724663108891688\n",
      "state terminated\n",
      "episode 3750, reward 1619.0, memory_length 2000, epsilon 0.4723718290754873\n",
      "state terminated\n",
      "episode 3751, reward 1269.0, memory_length 2000, epsilon 0.47227736615627897\n",
      "state terminated\n",
      "episode 3752, reward 1615.0, memory_length 2000, epsilon 0.4721829221277654\n",
      "state terminated\n",
      "episode 3753, reward 1178.0, memory_length 2000, epsilon 0.4720884969861688\n",
      "state terminated\n",
      "episode 3754, reward 1350.0, memory_length 2000, epsilon 0.4719940907277121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3755, reward 1564.0, memory_length 2000, epsilon 0.47189970334861914\n",
      "state terminated\n",
      "episode 3756, reward 1510.0, memory_length 2000, epsilon 0.4718053348451142\n",
      "state terminated\n",
      "episode 3757, reward 1374.0, memory_length 2000, epsilon 0.47171098521342286\n",
      "state terminated\n",
      "episode 3758, reward 1317.0, memory_length 2000, epsilon 0.471616654449771\n",
      "state terminated\n",
      "episode 3759, reward 1784.0, memory_length 2000, epsilon 0.4715223425503854\n",
      "state terminated\n",
      "episode 3760, reward 1521.0, memory_length 2000, epsilon 0.47142804951149353\n",
      "state terminated\n",
      "episode 3761, reward 1491.0, memory_length 2000, epsilon 0.47133377532932363\n",
      "state terminated\n",
      "episode 3762, reward 1384.0, memory_length 2000, epsilon 0.4712395200001049\n",
      "state terminated\n",
      "episode 3763, reward 1455.0, memory_length 2000, epsilon 0.471145283520067\n",
      "state terminated\n",
      "episode 3764, reward 1473.0, memory_length 2000, epsilon 0.47105106588544055\n",
      "state terminated\n",
      "episode 3765, reward 1194.0, memory_length 2000, epsilon 0.4709568670924567\n",
      "state terminated\n",
      "episode 3766, reward 1610.0, memory_length 2000, epsilon 0.47086268713734775\n",
      "state terminated\n",
      "episode 3767, reward 1762.0, memory_length 2000, epsilon 0.47076852601634617\n",
      "state terminated\n",
      "episode 3768, reward 1299.0, memory_length 2000, epsilon 0.47067438372568576\n",
      "state terminated\n",
      "episode 3769, reward 1710.0, memory_length 2000, epsilon 0.47058026026160077\n",
      "state terminated\n",
      "episode 3770, reward 1463.0, memory_length 2000, epsilon 0.4704861556203263\n",
      "state terminated\n",
      "episode 3771, reward 1368.0, memory_length 2000, epsilon 0.47039206979809806\n",
      "state terminated\n",
      "episode 3772, reward 1757.0, memory_length 2000, epsilon 0.4702980027911527\n",
      "state terminated\n",
      "episode 3773, reward 1596.0, memory_length 2000, epsilon 0.47020395459572745\n",
      "state terminated\n",
      "episode 3774, reward 1209.0, memory_length 2000, epsilon 0.47010992520806055\n",
      "state terminated\n",
      "episode 3775, reward 1476.0, memory_length 2000, epsilon 0.4700159146243907\n",
      "state terminated\n",
      "episode 3776, reward 1432.0, memory_length 2000, epsilon 0.4699219228409575\n",
      "state terminated\n",
      "episode 3777, reward 1551.0, memory_length 2000, epsilon 0.46982794985400117\n",
      "state terminated\n",
      "episode 3778, reward 1369.0, memory_length 2000, epsilon 0.46973399565976304\n",
      "state terminated\n",
      "episode 3779, reward 1525.0, memory_length 2000, epsilon 0.4696400602544847\n",
      "state terminated\n",
      "episode 3780, reward 1737.0, memory_length 2000, epsilon 0.46954614363440883\n",
      "state terminated\n",
      "episode 3781, reward 1244.0, memory_length 2000, epsilon 0.4694522457957788\n",
      "state terminated\n",
      "episode 3782, reward 1587.0, memory_length 2000, epsilon 0.4693583667348387\n",
      "state terminated\n",
      "episode 3783, reward 1589.0, memory_length 2000, epsilon 0.4692645064478333\n",
      "state terminated\n",
      "episode 3784, reward 1422.0, memory_length 2000, epsilon 0.46917066493100823\n",
      "state terminated\n",
      "episode 3785, reward 1918.0, memory_length 2000, epsilon 0.4690768421806098\n",
      "state terminated\n",
      "episode 3786, reward 1417.0, memory_length 2000, epsilon 0.46898303819288517\n",
      "state terminated\n",
      "episode 3787, reward 1534.0, memory_length 2000, epsilon 0.468889252964082\n",
      "state terminated\n",
      "episode 3788, reward 1757.0, memory_length 2000, epsilon 0.46879548649044916\n",
      "state terminated\n",
      "episode 3789, reward 1732.0, memory_length 2000, epsilon 0.4687017387682358\n",
      "state terminated\n",
      "episode 3790, reward 1520.0, memory_length 2000, epsilon 0.46860800979369205\n",
      "state terminated\n",
      "episode 3791, reward 1528.0, memory_length 2000, epsilon 0.4685142995630687\n",
      "state terminated\n",
      "episode 3792, reward 1282.0, memory_length 2000, epsilon 0.46842060807261743\n",
      "state terminated\n",
      "episode 3793, reward 1356.0, memory_length 2000, epsilon 0.46832693531859054\n",
      "state terminated\n",
      "episode 3794, reward 1194.0, memory_length 2000, epsilon 0.4682332812972412\n",
      "state terminated\n",
      "episode 3795, reward 1629.0, memory_length 2000, epsilon 0.46813964600482305\n",
      "state terminated\n",
      "episode 3796, reward 1325.0, memory_length 2000, epsilon 0.4680460294375909\n",
      "state terminated\n",
      "episode 3797, reward 1451.0, memory_length 2000, epsilon 0.46795243159179994\n",
      "state terminated\n",
      "episode 3798, reward 1498.0, memory_length 2000, epsilon 0.46785885246370634\n",
      "state terminated\n",
      "episode 3799, reward 1430.0, memory_length 2000, epsilon 0.46776529204956685\n",
      "state terminated\n",
      "episode 3800, reward 1470.0, memory_length 2000, epsilon 0.4676717503456392\n",
      "state terminated\n",
      "episode 3801, reward 1188.0, memory_length 2000, epsilon 0.46757822734818155\n",
      "state terminated\n",
      "episode 3802, reward 1575.0, memory_length 2000, epsilon 0.467484723053453\n",
      "state terminated\n",
      "episode 3803, reward 1587.0, memory_length 2000, epsilon 0.46739123745771355\n",
      "state terminated\n",
      "episode 3804, reward 1443.0, memory_length 2000, epsilon 0.4672977705572236\n",
      "state terminated\n",
      "episode 3805, reward 1475.0, memory_length 2000, epsilon 0.46720432234824455\n",
      "state terminated\n",
      "episode 3806, reward 1689.0, memory_length 2000, epsilon 0.4671108928270385\n",
      "state terminated\n",
      "episode 3807, reward 1452.0, memory_length 2000, epsilon 0.4670174819898681\n",
      "state terminated\n",
      "episode 3808, reward 1957.0, memory_length 2000, epsilon 0.46692408983299716\n",
      "state terminated\n",
      "episode 3809, reward 1619.0, memory_length 2000, epsilon 0.4668307163526898\n",
      "state terminated\n",
      "episode 3810, reward 1377.0, memory_length 2000, epsilon 0.4667373615452112\n",
      "state terminated\n",
      "episode 3811, reward 1838.0, memory_length 2000, epsilon 0.46664402540682715\n",
      "state terminated\n",
      "episode 3812, reward 1665.0, memory_length 2000, epsilon 0.4665507079338041\n",
      "state terminated\n",
      "episode 3813, reward 1185.0, memory_length 2000, epsilon 0.4664574091224095\n",
      "state terminated\n",
      "episode 3814, reward 1358.0, memory_length 2000, epsilon 0.4663641289689113\n",
      "state terminated\n",
      "episode 3815, reward 1537.0, memory_length 2000, epsilon 0.4662708674695783\n",
      "state terminated\n",
      "episode 3816, reward 1449.0, memory_length 2000, epsilon 0.46617762462068013\n",
      "state terminated\n",
      "episode 3817, reward 1656.0, memory_length 2000, epsilon 0.4660844004184869\n",
      "state terminated\n",
      "episode 3818, reward 1638.0, memory_length 2000, epsilon 0.4659911948592699\n",
      "state terminated\n",
      "episode 3819, reward 1781.0, memory_length 2000, epsilon 0.46589800793930064\n",
      "state terminated\n",
      "episode 3820, reward 1483.0, memory_length 2000, epsilon 0.4658048396548518\n",
      "state terminated\n",
      "episode 3821, reward 1704.0, memory_length 2000, epsilon 0.4657116900021966\n",
      "state terminated\n",
      "episode 3822, reward 1260.0, memory_length 2000, epsilon 0.465618558977609\n",
      "state terminated\n",
      "episode 3823, reward 1390.0, memory_length 2000, epsilon 0.4655254465773639\n",
      "state terminated\n",
      "episode 3824, reward 1754.0, memory_length 2000, epsilon 0.46543235279773665\n",
      "state terminated\n",
      "episode 3825, reward 1556.0, memory_length 2000, epsilon 0.4653392776350037\n",
      "state terminated\n",
      "episode 3826, reward 1580.0, memory_length 2000, epsilon 0.46524622108544184\n",
      "state terminated\n",
      "episode 3827, reward 1532.0, memory_length 2000, epsilon 0.46515318314532883\n",
      "state terminated\n",
      "episode 3828, reward 1047.0, memory_length 2000, epsilon 0.4650601638109433\n",
      "state terminated\n",
      "episode 3829, reward 1843.0, memory_length 2000, epsilon 0.46496716307856434\n",
      "state terminated\n",
      "episode 3830, reward 1237.0, memory_length 2000, epsilon 0.46487418094447197\n",
      "state terminated\n",
      "episode 3831, reward 1823.0, memory_length 2000, epsilon 0.46478121740494693\n",
      "state terminated\n",
      "episode 3832, reward 1564.0, memory_length 2000, epsilon 0.4646882724562706\n",
      "state terminated\n",
      "episode 3833, reward 1711.0, memory_length 2000, epsilon 0.46459534609472525\n",
      "state terminated\n",
      "episode 3834, reward 1715.0, memory_length 2000, epsilon 0.4645024383165938\n",
      "state terminated\n",
      "episode 3835, reward 1412.0, memory_length 2000, epsilon 0.46440954911816\n",
      "state terminated\n",
      "episode 3836, reward 1294.0, memory_length 2000, epsilon 0.4643166784957082\n",
      "state terminated\n",
      "episode 3837, reward 1615.0, memory_length 2000, epsilon 0.46422382644552357\n",
      "state terminated\n",
      "episode 3838, reward 1809.0, memory_length 2000, epsilon 0.46413099296389204\n",
      "state terminated\n",
      "episode 3839, reward 1344.0, memory_length 2000, epsilon 0.4640381780471003\n",
      "state terminated\n",
      "episode 3840, reward 1692.0, memory_length 2000, epsilon 0.46394538169143584\n",
      "state terminated\n",
      "episode 3841, reward 1785.0, memory_length 2000, epsilon 0.4638526038931866\n",
      "state terminated\n",
      "episode 3842, reward 1605.0, memory_length 2000, epsilon 0.46375984464864156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3843, reward 1519.0, memory_length 2000, epsilon 0.4636671039540905\n",
      "state terminated\n",
      "episode 3844, reward 1638.0, memory_length 2000, epsilon 0.46357438180582355\n",
      "state terminated\n",
      "episode 3845, reward 1538.0, memory_length 2000, epsilon 0.463481678200132\n",
      "state terminated\n",
      "episode 3846, reward 1586.0, memory_length 2000, epsilon 0.46338899313330756\n",
      "state terminated\n",
      "episode 3847, reward 1217.0, memory_length 2000, epsilon 0.463296326601643\n",
      "state terminated\n",
      "episode 3848, reward 1575.0, memory_length 2000, epsilon 0.46320367860143147\n",
      "state terminated\n",
      "episode 3849, reward 1493.0, memory_length 2000, epsilon 0.4631110491289672\n",
      "state terminated\n",
      "episode 3850, reward 1623.0, memory_length 2000, epsilon 0.463018438180545\n",
      "state terminated\n",
      "episode 3851, reward 1741.0, memory_length 2000, epsilon 0.4629258457524604\n",
      "state terminated\n",
      "episode 3852, reward 1420.0, memory_length 2000, epsilon 0.46283327184100953\n",
      "state terminated\n",
      "episode 3853, reward 1323.0, memory_length 2000, epsilon 0.4627407164424897\n",
      "state terminated\n",
      "episode 3854, reward 1444.0, memory_length 2000, epsilon 0.4626481795531986\n",
      "state terminated\n",
      "episode 3855, reward 1412.0, memory_length 2000, epsilon 0.4625556611694347\n",
      "state terminated\n",
      "episode 3856, reward 1453.0, memory_length 2000, epsilon 0.46246316128749737\n",
      "state terminated\n",
      "episode 3857, reward 1423.0, memory_length 2000, epsilon 0.4623706799036865\n",
      "state terminated\n",
      "episode 3858, reward 1584.0, memory_length 2000, epsilon 0.46227821701430294\n",
      "state terminated\n",
      "episode 3859, reward 1549.0, memory_length 2000, epsilon 0.4621857726156481\n",
      "state terminated\n",
      "episode 3860, reward 1488.0, memory_length 2000, epsilon 0.4620933467040242\n",
      "state terminated\n",
      "episode 3861, reward 1244.0, memory_length 2000, epsilon 0.46200093927573427\n",
      "state terminated\n",
      "episode 3862, reward 1294.0, memory_length 2000, epsilon 0.4619085503270819\n",
      "state terminated\n",
      "episode 3863, reward 1228.0, memory_length 2000, epsilon 0.46181617985437173\n",
      "state terminated\n",
      "episode 3864, reward 1872.0, memory_length 2000, epsilon 0.4617238278539087\n",
      "state terminated\n",
      "episode 3865, reward 1169.0, memory_length 2000, epsilon 0.4616314943219989\n",
      "state terminated\n",
      "episode 3866, reward 1543.0, memory_length 2000, epsilon 0.4615391792549489\n",
      "state terminated\n",
      "episode 3867, reward 1420.0, memory_length 2000, epsilon 0.46144688264906614\n",
      "state terminated\n",
      "episode 3868, reward 1604.0, memory_length 2000, epsilon 0.4613546045006588\n",
      "state terminated\n",
      "episode 3869, reward 1748.0, memory_length 2000, epsilon 0.4612623448060357\n",
      "state terminated\n",
      "episode 3870, reward 1712.0, memory_length 2000, epsilon 0.4611701035615064\n",
      "state terminated\n",
      "episode 3871, reward 1337.0, memory_length 2000, epsilon 0.4610778807633813\n",
      "state terminated\n",
      "episode 3872, reward 1493.0, memory_length 2000, epsilon 0.46098567640797145\n",
      "state terminated\n",
      "episode 3873, reward 1473.0, memory_length 2000, epsilon 0.46089349049158884\n",
      "state terminated\n",
      "episode 3874, reward 1359.0, memory_length 2000, epsilon 0.4608013230105458\n",
      "state terminated\n",
      "episode 3875, reward 1582.0, memory_length 2000, epsilon 0.46070917396115585\n",
      "state terminated\n",
      "episode 3876, reward 1618.0, memory_length 2000, epsilon 0.46061704333973286\n",
      "state terminated\n",
      "episode 3877, reward 1586.0, memory_length 2000, epsilon 0.46052493114259163\n",
      "state terminated\n",
      "episode 3878, reward 1471.0, memory_length 2000, epsilon 0.46043283736604773\n",
      "state terminated\n",
      "episode 3879, reward 1280.0, memory_length 2000, epsilon 0.46034076200641744\n",
      "state terminated\n",
      "episode 3880, reward 1586.0, memory_length 2000, epsilon 0.46024870506001764\n",
      "state terminated\n",
      "episode 3881, reward 1420.0, memory_length 2000, epsilon 0.46015666652316617\n",
      "state terminated\n",
      "episode 3882, reward 1805.0, memory_length 2000, epsilon 0.4600646463921813\n",
      "state terminated\n",
      "episode 3883, reward 1466.0, memory_length 2000, epsilon 0.45997264466338245\n",
      "state terminated\n",
      "episode 3884, reward 1561.0, memory_length 2000, epsilon 0.4598806613330894\n",
      "state terminated\n",
      "episode 3885, reward 1251.0, memory_length 2000, epsilon 0.45978869639762293\n",
      "state terminated\n",
      "episode 3886, reward 1624.0, memory_length 2000, epsilon 0.4596967498533043\n",
      "state terminated\n",
      "episode 3887, reward 1478.0, memory_length 2000, epsilon 0.4596048216964557\n",
      "state terminated\n",
      "episode 3888, reward 1563.0, memory_length 2000, epsilon 0.4595129119234001\n",
      "state terminated\n",
      "episode 3889, reward 1554.0, memory_length 2000, epsilon 0.459421020530461\n",
      "state terminated\n",
      "episode 3890, reward 1379.0, memory_length 2000, epsilon 0.45932914751396287\n",
      "state terminated\n",
      "episode 3891, reward 1708.0, memory_length 2000, epsilon 0.45923729287023063\n",
      "state terminated\n",
      "episode 3892, reward 1406.0, memory_length 2000, epsilon 0.45914545659559014\n",
      "state terminated\n",
      "episode 3893, reward 1816.0, memory_length 2000, epsilon 0.459053638686368\n",
      "state terminated\n",
      "episode 3894, reward 1767.0, memory_length 2000, epsilon 0.4589618391388915\n",
      "state terminated\n",
      "episode 3895, reward 1773.0, memory_length 2000, epsilon 0.45887005794948854\n",
      "state terminated\n",
      "episode 3896, reward 1367.0, memory_length 2000, epsilon 0.4587782951144881\n",
      "state terminated\n",
      "episode 3897, reward 1541.0, memory_length 2000, epsilon 0.4586865506302194\n",
      "state terminated\n",
      "episode 3898, reward 1467.0, memory_length 2000, epsilon 0.4585948244930128\n",
      "state terminated\n",
      "episode 3899, reward 1681.0, memory_length 2000, epsilon 0.4585031166991993\n",
      "state terminated\n",
      "episode 3900, reward 1840.0, memory_length 2000, epsilon 0.45841142724511047\n",
      "state terminated\n",
      "episode 3901, reward 1619.0, memory_length 2000, epsilon 0.45831975612707887\n",
      "state terminated\n",
      "episode 3902, reward 1719.0, memory_length 2000, epsilon 0.45822810334143754\n",
      "state terminated\n",
      "episode 3903, reward 1302.0, memory_length 2000, epsilon 0.45813646888452036\n",
      "state terminated\n",
      "episode 3904, reward 1641.0, memory_length 2000, epsilon 0.45804485275266205\n",
      "state terminated\n",
      "episode 3905, reward 1835.0, memory_length 2000, epsilon 0.45795325494219785\n",
      "state terminated\n",
      "episode 3906, reward 1717.0, memory_length 2000, epsilon 0.457861675449464\n",
      "state terminated\n",
      "episode 3907, reward 1619.0, memory_length 2000, epsilon 0.4577701142707972\n",
      "state terminated\n",
      "episode 3908, reward 1360.0, memory_length 2000, epsilon 0.457678571402535\n",
      "state terminated\n",
      "episode 3909, reward 1298.0, memory_length 2000, epsilon 0.4575870468410157\n",
      "state terminated\n",
      "episode 3910, reward 1675.0, memory_length 2000, epsilon 0.45749554058257835\n",
      "state terminated\n",
      "episode 3911, reward 1697.0, memory_length 2000, epsilon 0.4574040526235627\n",
      "state terminated\n",
      "episode 3912, reward 1777.0, memory_length 2000, epsilon 0.4573125829603092\n",
      "state terminated\n",
      "episode 3913, reward 1599.0, memory_length 2000, epsilon 0.4572211315891591\n",
      "state terminated\n",
      "episode 3914, reward 1487.0, memory_length 2000, epsilon 0.4571296985064543\n",
      "state terminated\n",
      "episode 3915, reward 1520.0, memory_length 2000, epsilon 0.45703828370853755\n",
      "state terminated\n",
      "episode 3916, reward 1389.0, memory_length 2000, epsilon 0.45694688719175214\n",
      "state terminated\n",
      "episode 3917, reward 1723.0, memory_length 2000, epsilon 0.45685550895244237\n",
      "state terminated\n",
      "episode 3918, reward 1721.0, memory_length 2000, epsilon 0.4567641489869529\n",
      "state terminated\n",
      "episode 3919, reward 1452.0, memory_length 2000, epsilon 0.4566728072916295\n",
      "state terminated\n",
      "episode 3920, reward 1469.0, memory_length 2000, epsilon 0.4565814838628185\n",
      "state terminated\n",
      "episode 3921, reward 1749.0, memory_length 2000, epsilon 0.45649017869686687\n",
      "state terminated\n",
      "episode 3922, reward 1495.0, memory_length 2000, epsilon 0.4563988917901225\n",
      "state terminated\n",
      "episode 3923, reward 1431.0, memory_length 2000, epsilon 0.4563076231389338\n",
      "state terminated\n",
      "episode 3924, reward 1241.0, memory_length 2000, epsilon 0.4562163727396501\n",
      "state terminated\n",
      "episode 3925, reward 1523.0, memory_length 2000, epsilon 0.45612514058862136\n",
      "state terminated\n",
      "episode 3926, reward 1402.0, memory_length 2000, epsilon 0.45603392668219833\n",
      "state terminated\n",
      "episode 3927, reward 1719.0, memory_length 2000, epsilon 0.45594273101673244\n",
      "state terminated\n",
      "episode 3928, reward 1692.0, memory_length 2000, epsilon 0.4558515535885758\n",
      "state terminated\n",
      "episode 3929, reward 1560.0, memory_length 2000, epsilon 0.45576039439408145\n",
      "state terminated\n",
      "episode 3930, reward 1363.0, memory_length 2000, epsilon 0.45566925342960285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 3931, reward 1577.0, memory_length 2000, epsilon 0.45557813069149455\n",
      "state terminated\n",
      "episode 3932, reward 1683.0, memory_length 2000, epsilon 0.4554870261761114\n",
      "state terminated\n",
      "episode 3933, reward 1750.0, memory_length 2000, epsilon 0.4553959398798095\n",
      "state terminated\n",
      "episode 3934, reward 1406.0, memory_length 2000, epsilon 0.45530487179894513\n",
      "state terminated\n",
      "episode 3935, reward 1474.0, memory_length 2000, epsilon 0.45521382192987575\n",
      "state terminated\n",
      "episode 3936, reward 1712.0, memory_length 2000, epsilon 0.4551227902689593\n",
      "state terminated\n",
      "episode 3937, reward 1625.0, memory_length 2000, epsilon 0.4550317768125546\n",
      "state terminated\n",
      "episode 3938, reward 1774.0, memory_length 2000, epsilon 0.4549407815570209\n",
      "state terminated\n",
      "episode 3939, reward 1784.0, memory_length 2000, epsilon 0.45484980449871854\n",
      "state terminated\n",
      "episode 3940, reward 1543.0, memory_length 2000, epsilon 0.45475884563400853\n",
      "state terminated\n",
      "episode 3941, reward 1718.0, memory_length 2000, epsilon 0.4546679049592523\n",
      "state terminated\n",
      "episode 3942, reward 1242.0, memory_length 2000, epsilon 0.4545769824708124\n",
      "state terminated\n",
      "episode 3943, reward 1728.0, memory_length 2000, epsilon 0.4544860781650518\n",
      "state terminated\n",
      "episode 3944, reward 1372.0, memory_length 2000, epsilon 0.45439519203833445\n",
      "state terminated\n",
      "episode 3945, reward 1558.0, memory_length 2000, epsilon 0.45430432408702476\n",
      "state terminated\n",
      "episode 3946, reward 1443.0, memory_length 2000, epsilon 0.45421347430748815\n",
      "state terminated\n",
      "episode 3947, reward 1599.0, memory_length 2000, epsilon 0.4541226426960906\n",
      "state terminated\n",
      "episode 3948, reward 1468.0, memory_length 2000, epsilon 0.4540318292491987\n",
      "state terminated\n",
      "episode 3949, reward 1624.0, memory_length 2000, epsilon 0.45394103396318014\n",
      "state terminated\n",
      "episode 3950, reward 1343.0, memory_length 2000, epsilon 0.45385025683440305\n",
      "state terminated\n",
      "episode 3951, reward 1623.0, memory_length 2000, epsilon 0.4537594978592362\n",
      "state terminated\n",
      "episode 3952, reward 1530.0, memory_length 2000, epsilon 0.45366875703404935\n",
      "state terminated\n",
      "episode 3953, reward 1523.0, memory_length 2000, epsilon 0.45357803435521277\n",
      "state terminated\n",
      "episode 3954, reward 1656.0, memory_length 2000, epsilon 0.4534873298190977\n",
      "state terminated\n",
      "episode 3955, reward 1682.0, memory_length 2000, epsilon 0.4533966434220759\n",
      "state terminated\n",
      "episode 3956, reward 1569.0, memory_length 2000, epsilon 0.45330597516051985\n",
      "state terminated\n",
      "episode 3957, reward 1683.0, memory_length 2000, epsilon 0.4532153250308029\n",
      "state terminated\n",
      "episode 3958, reward 1588.0, memory_length 2000, epsilon 0.453124693029299\n",
      "state terminated\n",
      "episode 3959, reward 1452.0, memory_length 2000, epsilon 0.45303407915238286\n",
      "state terminated\n",
      "episode 3960, reward 1287.0, memory_length 2000, epsilon 0.45294348339643\n",
      "state terminated\n",
      "episode 3961, reward 1803.0, memory_length 2000, epsilon 0.4528529057578165\n",
      "state terminated\n",
      "episode 3962, reward 1521.0, memory_length 2000, epsilon 0.4527623462329193\n",
      "state terminated\n",
      "episode 3963, reward 1476.0, memory_length 2000, epsilon 0.4526718048181159\n",
      "state terminated\n",
      "episode 3964, reward 1910.0, memory_length 2000, epsilon 0.45258128150978494\n",
      "state terminated\n",
      "episode 3965, reward 1675.0, memory_length 2000, epsilon 0.4524907763043052\n",
      "state terminated\n",
      "episode 3966, reward 1272.0, memory_length 2000, epsilon 0.4524002891980566\n",
      "state terminated\n",
      "episode 3967, reward 1632.0, memory_length 2000, epsilon 0.4523098201874196\n",
      "state terminated\n",
      "episode 3968, reward 1666.0, memory_length 2000, epsilon 0.4522193692687755\n",
      "state terminated\n",
      "episode 3969, reward 1787.0, memory_length 2000, epsilon 0.45212893643850616\n",
      "state terminated\n",
      "episode 3970, reward 1471.0, memory_length 2000, epsilon 0.45203852169299447\n",
      "state terminated\n",
      "episode 3971, reward 1514.0, memory_length 2000, epsilon 0.4519481250286236\n",
      "state terminated\n",
      "episode 3972, reward 1570.0, memory_length 2000, epsilon 0.45185774644177784\n",
      "state terminated\n",
      "episode 3973, reward 1651.0, memory_length 2000, epsilon 0.4517673859288419\n",
      "state terminated\n",
      "episode 3974, reward 1619.0, memory_length 2000, epsilon 0.4516770434862016\n",
      "state terminated\n",
      "episode 3975, reward 1771.0, memory_length 2000, epsilon 0.451586719110243\n",
      "state terminated\n",
      "episode 3976, reward 1494.0, memory_length 2000, epsilon 0.4514964127973533\n",
      "state terminated\n",
      "episode 3977, reward 1775.0, memory_length 2000, epsilon 0.45140612454392015\n",
      "state terminated\n",
      "episode 3978, reward 1280.0, memory_length 2000, epsilon 0.451315854346332\n",
      "state terminated\n",
      "episode 3979, reward 1840.0, memory_length 2000, epsilon 0.45122560220097807\n",
      "state terminated\n",
      "episode 3980, reward 1586.0, memory_length 2000, epsilon 0.4511353681042483\n",
      "state terminated\n",
      "episode 3981, reward 1370.0, memory_length 2000, epsilon 0.4510451520525334\n",
      "state terminated\n",
      "episode 3982, reward 1658.0, memory_length 2000, epsilon 0.4509549540422246\n",
      "state terminated\n",
      "episode 3983, reward 1313.0, memory_length 2000, epsilon 0.450864774069714\n",
      "state terminated\n",
      "episode 3984, reward 1393.0, memory_length 2000, epsilon 0.4507746121313944\n",
      "state terminated\n",
      "episode 3985, reward 1628.0, memory_length 2000, epsilon 0.4506844682236594\n",
      "state terminated\n",
      "episode 3986, reward 1097.0, memory_length 2000, epsilon 0.4505943423429032\n",
      "state terminated\n",
      "episode 3987, reward 1476.0, memory_length 2000, epsilon 0.45050423448552074\n",
      "state terminated\n",
      "episode 3988, reward 1692.0, memory_length 2000, epsilon 0.4504141446479076\n",
      "state terminated\n",
      "episode 3989, reward 1820.0, memory_length 2000, epsilon 0.4503240728264604\n",
      "state terminated\n",
      "episode 3990, reward 1395.0, memory_length 2000, epsilon 0.45023401901757626\n",
      "state terminated\n",
      "episode 3991, reward 1622.0, memory_length 2000, epsilon 0.45014398321765287\n",
      "state terminated\n",
      "episode 3992, reward 1613.0, memory_length 2000, epsilon 0.45005396542308884\n",
      "state terminated\n",
      "episode 3993, reward 1429.0, memory_length 2000, epsilon 0.4499639656302834\n",
      "state terminated\n",
      "episode 3994, reward 1352.0, memory_length 2000, epsilon 0.4498739838356368\n",
      "state terminated\n",
      "episode 3995, reward 1788.0, memory_length 2000, epsilon 0.44978402003554957\n",
      "state terminated\n",
      "episode 3996, reward 1660.0, memory_length 2000, epsilon 0.4496940742264232\n",
      "state terminated\n",
      "episode 3997, reward 1911.0, memory_length 2000, epsilon 0.44960414640465984\n",
      "state terminated\n",
      "episode 3998, reward 1128.0, memory_length 2000, epsilon 0.44951423656666234\n",
      "state terminated\n",
      "episode 3999, reward 1656.0, memory_length 2000, epsilon 0.4494243447088345\n",
      "state terminated\n",
      "episode 4000, reward 1348.0, memory_length 2000, epsilon 0.44933447082758043\n",
      "Total time taken  23492.926718711853\n",
      "state terminated\n",
      "episode 4001, reward 1788.0, memory_length 2000, epsilon 0.4492446149193053\n",
      "state terminated\n",
      "episode 4002, reward 1799.0, memory_length 2000, epsilon 0.4491547769804148\n",
      "state terminated\n",
      "episode 4003, reward 1907.0, memory_length 2000, epsilon 0.44906495700731536\n",
      "state terminated\n",
      "episode 4004, reward 1384.0, memory_length 2000, epsilon 0.4489751549964143\n",
      "state terminated\n",
      "episode 4005, reward 1681.0, memory_length 2000, epsilon 0.4488853709441196\n",
      "state terminated\n",
      "episode 4006, reward 1793.0, memory_length 2000, epsilon 0.4487956048468397\n",
      "state terminated\n",
      "episode 4007, reward 1412.0, memory_length 2000, epsilon 0.4487058567009841\n",
      "state terminated\n",
      "episode 4008, reward 1644.0, memory_length 2000, epsilon 0.44861612650296273\n",
      "state terminated\n",
      "episode 4009, reward 1532.0, memory_length 2000, epsilon 0.4485264142491866\n",
      "state terminated\n",
      "episode 4010, reward 1456.0, memory_length 2000, epsilon 0.44843671993606704\n",
      "state terminated\n",
      "episode 4011, reward 1561.0, memory_length 2000, epsilon 0.4483470435600164\n",
      "state terminated\n",
      "episode 4012, reward 1702.0, memory_length 2000, epsilon 0.4482573851174475\n",
      "state terminated\n",
      "episode 4013, reward 1750.0, memory_length 2000, epsilon 0.44816774460477404\n",
      "state terminated\n",
      "episode 4014, reward 1394.0, memory_length 2000, epsilon 0.44807812201841046\n",
      "state terminated\n",
      "episode 4015, reward 1604.0, memory_length 2000, epsilon 0.44798851735477185\n",
      "state terminated\n",
      "episode 4016, reward 1381.0, memory_length 2000, epsilon 0.44789893061027397\n",
      "state terminated\n",
      "episode 4017, reward 1810.0, memory_length 2000, epsilon 0.44780936178133335\n",
      "state terminated\n",
      "episode 4018, reward 1631.0, memory_length 2000, epsilon 0.4477198108643673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4019, reward 1489.0, memory_length 2000, epsilon 0.44763027785579373\n",
      "state terminated\n",
      "episode 4020, reward 1768.0, memory_length 2000, epsilon 0.44754076275203136\n",
      "state terminated\n",
      "episode 4021, reward 1650.0, memory_length 2000, epsilon 0.44745126554949954\n",
      "state terminated\n",
      "episode 4022, reward 1467.0, memory_length 2000, epsilon 0.4473617862446184\n",
      "state terminated\n",
      "episode 4023, reward 1656.0, memory_length 2000, epsilon 0.4472723248338087\n",
      "state terminated\n",
      "episode 4024, reward 1636.0, memory_length 2000, epsilon 0.4471828813134921\n",
      "state terminated\n",
      "episode 4025, reward 1587.0, memory_length 2000, epsilon 0.44709345568009085\n",
      "state terminated\n",
      "episode 4026, reward 1422.0, memory_length 2000, epsilon 0.4470040479300279\n",
      "state terminated\n",
      "episode 4027, reward 1691.0, memory_length 2000, epsilon 0.44691465805972685\n",
      "state terminated\n",
      "episode 4028, reward 1551.0, memory_length 2000, epsilon 0.4468252860656122\n",
      "state terminated\n",
      "episode 4029, reward 1464.0, memory_length 2000, epsilon 0.4467359319441091\n",
      "state terminated\n",
      "episode 4030, reward 1695.0, memory_length 2000, epsilon 0.44664659569164333\n",
      "state terminated\n",
      "episode 4031, reward 1467.0, memory_length 2000, epsilon 0.4465572773046414\n",
      "state terminated\n",
      "episode 4032, reward 1586.0, memory_length 2000, epsilon 0.4464679767795307\n",
      "state terminated\n",
      "episode 4033, reward 1276.0, memory_length 2000, epsilon 0.4463786941127391\n",
      "state terminated\n",
      "episode 4034, reward 1588.0, memory_length 2000, epsilon 0.44628942930069526\n",
      "state terminated\n",
      "episode 4035, reward 1484.0, memory_length 2000, epsilon 0.4462001823398287\n",
      "state terminated\n",
      "episode 4036, reward 1746.0, memory_length 2000, epsilon 0.44611095322656946\n",
      "state terminated\n",
      "episode 4037, reward 1731.0, memory_length 2000, epsilon 0.4460217419573485\n",
      "state terminated\n",
      "episode 4038, reward 1718.0, memory_length 2000, epsilon 0.4459325485285972\n",
      "state terminated\n",
      "episode 4039, reward 1590.0, memory_length 2000, epsilon 0.44584337293674786\n",
      "state terminated\n",
      "episode 4040, reward 1672.0, memory_length 2000, epsilon 0.4457542151782336\n",
      "state terminated\n",
      "episode 4041, reward 1692.0, memory_length 2000, epsilon 0.44566507524948795\n",
      "state terminated\n",
      "episode 4042, reward 1100.0, memory_length 2000, epsilon 0.4455759531469454\n",
      "state terminated\n",
      "episode 4043, reward 1659.0, memory_length 2000, epsilon 0.44548684886704104\n",
      "state terminated\n",
      "episode 4044, reward 1695.0, memory_length 2000, epsilon 0.44539776240621065\n",
      "state terminated\n",
      "episode 4045, reward 1206.0, memory_length 2000, epsilon 0.44530869376089083\n",
      "state terminated\n",
      "episode 4046, reward 1662.0, memory_length 2000, epsilon 0.4452196429275188\n",
      "state terminated\n",
      "episode 4047, reward 1423.0, memory_length 2000, epsilon 0.4451306099025326\n",
      "state terminated\n",
      "episode 4048, reward 2067.0, memory_length 2000, epsilon 0.44504159468237087\n",
      "state terminated\n",
      "episode 4049, reward 1618.0, memory_length 2000, epsilon 0.4449525972634729\n",
      "state terminated\n",
      "episode 4050, reward 1438.0, memory_length 2000, epsilon 0.4448636176422789\n",
      "state terminated\n",
      "episode 4051, reward 1613.0, memory_length 2000, epsilon 0.44477465581522974\n",
      "state terminated\n",
      "episode 4052, reward 1690.0, memory_length 2000, epsilon 0.4446857117787668\n",
      "state terminated\n",
      "episode 4053, reward 1604.0, memory_length 2000, epsilon 0.4445967855293324\n",
      "state terminated\n",
      "episode 4054, reward 1471.0, memory_length 2000, epsilon 0.44450787706336947\n",
      "state terminated\n",
      "episode 4055, reward 1539.0, memory_length 2000, epsilon 0.4444189863773217\n",
      "state terminated\n",
      "episode 4056, reward 1602.0, memory_length 2000, epsilon 0.4443301134676335\n",
      "state terminated\n",
      "episode 4057, reward 1524.0, memory_length 2000, epsilon 0.44424125833074984\n",
      "state terminated\n",
      "episode 4058, reward 1307.0, memory_length 2000, epsilon 0.4441524209631166\n",
      "state terminated\n",
      "episode 4059, reward 1920.0, memory_length 2000, epsilon 0.44406360136118017\n",
      "state terminated\n",
      "episode 4060, reward 1727.0, memory_length 2000, epsilon 0.44397479952138796\n",
      "state terminated\n",
      "episode 4061, reward 1607.0, memory_length 2000, epsilon 0.44388601544018774\n",
      "state terminated\n",
      "episode 4062, reward 1198.0, memory_length 2000, epsilon 0.44379724911402824\n",
      "state terminated\n",
      "episode 4063, reward 2086.0, memory_length 2000, epsilon 0.4437085005393587\n",
      "state terminated\n",
      "episode 4064, reward 1759.0, memory_length 2000, epsilon 0.44361976971262923\n",
      "state terminated\n",
      "episode 4065, reward 1073.0, memory_length 2000, epsilon 0.4435310566302907\n",
      "state terminated\n",
      "episode 4066, reward 1825.0, memory_length 2000, epsilon 0.44344236128879444\n",
      "state terminated\n",
      "episode 4067, reward 1600.0, memory_length 2000, epsilon 0.4433536836845927\n",
      "state terminated\n",
      "episode 4068, reward 1287.0, memory_length 2000, epsilon 0.44326502381413835\n",
      "state terminated\n",
      "episode 4069, reward 1570.0, memory_length 2000, epsilon 0.44317638167388496\n",
      "state terminated\n",
      "episode 4070, reward 1300.0, memory_length 2000, epsilon 0.443087757260287\n",
      "state terminated\n",
      "episode 4071, reward 1494.0, memory_length 2000, epsilon 0.4429991505697994\n",
      "state terminated\n",
      "episode 4072, reward 1641.0, memory_length 2000, epsilon 0.4429105615988778\n",
      "state terminated\n",
      "episode 4073, reward 1714.0, memory_length 2000, epsilon 0.44282199034397873\n",
      "state terminated\n",
      "episode 4074, reward 1458.0, memory_length 2000, epsilon 0.4427334368015593\n",
      "state terminated\n",
      "episode 4075, reward 1844.0, memory_length 2000, epsilon 0.4426449009680775\n",
      "state terminated\n",
      "episode 4076, reward 1682.0, memory_length 2000, epsilon 0.44255638283999177\n",
      "state terminated\n",
      "episode 4077, reward 1753.0, memory_length 2000, epsilon 0.44246788241376145\n",
      "state terminated\n",
      "episode 4078, reward 1146.0, memory_length 2000, epsilon 0.4423793996858464\n",
      "state terminated\n",
      "episode 4079, reward 1602.0, memory_length 2000, epsilon 0.44229093465270736\n",
      "state terminated\n",
      "episode 4080, reward 1525.0, memory_length 2000, epsilon 0.44220248731080586\n",
      "state terminated\n",
      "episode 4081, reward 1660.0, memory_length 2000, epsilon 0.4421140576566039\n",
      "state terminated\n",
      "episode 4082, reward 1443.0, memory_length 2000, epsilon 0.44202564568656433\n",
      "state terminated\n",
      "episode 4083, reward 1670.0, memory_length 2000, epsilon 0.44193725139715057\n",
      "state terminated\n",
      "episode 4084, reward 1683.0, memory_length 2000, epsilon 0.44184887478482693\n",
      "state terminated\n",
      "episode 4085, reward 1623.0, memory_length 2000, epsilon 0.44176051584605835\n",
      "state terminated\n",
      "episode 4086, reward 1980.0, memory_length 2000, epsilon 0.44167217457731056\n",
      "state terminated\n",
      "episode 4087, reward 1629.0, memory_length 2000, epsilon 0.4415838509750497\n",
      "state terminated\n",
      "episode 4088, reward 1342.0, memory_length 2000, epsilon 0.44149554503574295\n",
      "state terminated\n",
      "episode 4089, reward 1493.0, memory_length 2000, epsilon 0.44140725675585807\n",
      "state terminated\n",
      "episode 4090, reward 1143.0, memory_length 2000, epsilon 0.44131898613186354\n",
      "state terminated\n",
      "episode 4091, reward 1632.0, memory_length 2000, epsilon 0.44123073316022854\n",
      "state terminated\n",
      "episode 4092, reward 1597.0, memory_length 2000, epsilon 0.4411424978374229\n",
      "state terminated\n",
      "episode 4093, reward 1485.0, memory_length 2000, epsilon 0.4410542801599172\n",
      "state terminated\n",
      "episode 4094, reward 1352.0, memory_length 2000, epsilon 0.44096608012418276\n",
      "state terminated\n",
      "episode 4095, reward 1699.0, memory_length 2000, epsilon 0.44087789772669167\n",
      "state terminated\n",
      "episode 4096, reward 1235.0, memory_length 2000, epsilon 0.4407897329639165\n",
      "state terminated\n",
      "episode 4097, reward 1594.0, memory_length 2000, epsilon 0.44070158583233066\n",
      "state terminated\n",
      "episode 4098, reward 1350.0, memory_length 2000, epsilon 0.44061345632840837\n",
      "state terminated\n",
      "episode 4099, reward 1564.0, memory_length 2000, epsilon 0.44052534444862435\n",
      "state terminated\n",
      "episode 4100, reward 1691.0, memory_length 2000, epsilon 0.44043725018945423\n",
      "state terminated\n",
      "episode 4101, reward 1684.0, memory_length 2000, epsilon 0.44034917354737413\n",
      "state terminated\n",
      "episode 4102, reward 1474.0, memory_length 2000, epsilon 0.4402611145188611\n",
      "state terminated\n",
      "episode 4103, reward 1810.0, memory_length 2000, epsilon 0.44017307310039255\n",
      "state terminated\n",
      "episode 4104, reward 1973.0, memory_length 2000, epsilon 0.4400850492884471\n",
      "state terminated\n",
      "episode 4105, reward 1985.0, memory_length 2000, epsilon 0.43999704307950366\n",
      "state terminated\n",
      "episode 4106, reward 1605.0, memory_length 2000, epsilon 0.43990905447004197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4107, reward 1953.0, memory_length 2000, epsilon 0.4398210834565426\n",
      "state terminated\n",
      "episode 4108, reward 1798.0, memory_length 2000, epsilon 0.4397331300354866\n",
      "state terminated\n",
      "episode 4109, reward 1586.0, memory_length 2000, epsilon 0.43964519420335574\n",
      "state terminated\n",
      "episode 4110, reward 1584.0, memory_length 2000, epsilon 0.43955727595663285\n",
      "state terminated\n",
      "episode 4111, reward 1456.0, memory_length 2000, epsilon 0.43946937529180097\n",
      "state terminated\n",
      "episode 4112, reward 1413.0, memory_length 2000, epsilon 0.4393814922053442\n",
      "state terminated\n",
      "episode 4113, reward 1752.0, memory_length 2000, epsilon 0.4392936266937472\n",
      "state terminated\n",
      "episode 4114, reward 1901.0, memory_length 2000, epsilon 0.4392057787534953\n",
      "state terminated\n",
      "episode 4115, reward 1422.0, memory_length 2000, epsilon 0.43911794838107465\n",
      "state terminated\n",
      "episode 4116, reward 1784.0, memory_length 2000, epsilon 0.43903013557297194\n",
      "state terminated\n",
      "episode 4117, reward 1765.0, memory_length 2000, epsilon 0.43894234032567475\n",
      "state terminated\n",
      "episode 4118, reward 1678.0, memory_length 2000, epsilon 0.4388545626356712\n",
      "state terminated\n",
      "episode 4119, reward 1788.0, memory_length 2000, epsilon 0.4387668024994502\n",
      "state terminated\n",
      "episode 4120, reward 1316.0, memory_length 2000, epsilon 0.43867905991350137\n",
      "state terminated\n",
      "episode 4121, reward 1301.0, memory_length 2000, epsilon 0.438591334874315\n",
      "state terminated\n",
      "episode 4122, reward 1408.0, memory_length 2000, epsilon 0.4385036273783821\n",
      "state terminated\n",
      "episode 4123, reward 1692.0, memory_length 2000, epsilon 0.43841593742219437\n",
      "state terminated\n",
      "episode 4124, reward 1291.0, memory_length 2000, epsilon 0.4383282650022441\n",
      "state terminated\n",
      "episode 4125, reward 1895.0, memory_length 2000, epsilon 0.4382406101150246\n",
      "state terminated\n",
      "episode 4126, reward 1404.0, memory_length 2000, epsilon 0.4381529727570295\n",
      "state terminated\n",
      "episode 4127, reward 1596.0, memory_length 2000, epsilon 0.4380653529247534\n",
      "state terminated\n",
      "episode 4128, reward 1325.0, memory_length 2000, epsilon 0.43797775061469146\n",
      "state terminated\n",
      "episode 4129, reward 1813.0, memory_length 2000, epsilon 0.43789016582333956\n",
      "state terminated\n",
      "episode 4130, reward 1639.0, memory_length 2000, epsilon 0.43780259854719444\n",
      "state terminated\n",
      "episode 4131, reward 2031.0, memory_length 2000, epsilon 0.43771504878275325\n",
      "state terminated\n",
      "episode 4132, reward 1599.0, memory_length 2000, epsilon 0.4376275165265141\n",
      "state terminated\n",
      "episode 4133, reward 1606.0, memory_length 2000, epsilon 0.4375400017749757\n",
      "state terminated\n",
      "episode 4134, reward 1642.0, memory_length 2000, epsilon 0.43745250452463735\n",
      "state terminated\n",
      "episode 4135, reward 1777.0, memory_length 2000, epsilon 0.43736502477199934\n",
      "state terminated\n",
      "episode 4136, reward 1538.0, memory_length 2000, epsilon 0.4372775625135623\n",
      "state terminated\n",
      "episode 4137, reward 1610.0, memory_length 2000, epsilon 0.4371901177458279\n",
      "state terminated\n",
      "episode 4138, reward 1632.0, memory_length 2000, epsilon 0.4371026904652982\n",
      "state terminated\n",
      "episode 4139, reward 1842.0, memory_length 2000, epsilon 0.43701528066847617\n",
      "state terminated\n",
      "episode 4140, reward 1829.0, memory_length 2000, epsilon 0.4369278883518654\n",
      "state terminated\n",
      "episode 4141, reward 2080.0, memory_length 2000, epsilon 0.43684051351197034\n",
      "state terminated\n",
      "episode 4142, reward 1582.0, memory_length 2000, epsilon 0.43675315614529575\n",
      "state terminated\n",
      "episode 4143, reward 1503.0, memory_length 2000, epsilon 0.43666581624834755\n",
      "state terminated\n",
      "episode 4144, reward 1671.0, memory_length 2000, epsilon 0.436578493817632\n",
      "state terminated\n",
      "episode 4145, reward 1660.0, memory_length 2000, epsilon 0.4364911888496563\n",
      "state terminated\n",
      "episode 4146, reward 1649.0, memory_length 2000, epsilon 0.4364039013409282\n",
      "state terminated\n",
      "episode 4147, reward 1567.0, memory_length 2000, epsilon 0.4363166312879562\n",
      "state terminated\n",
      "episode 4148, reward 1578.0, memory_length 2000, epsilon 0.43622937868724954\n",
      "state terminated\n",
      "episode 4149, reward 1718.0, memory_length 2000, epsilon 0.43614214353531805\n",
      "state terminated\n",
      "episode 4150, reward 1680.0, memory_length 2000, epsilon 0.4360549258286724\n",
      "state terminated\n",
      "episode 4151, reward 1749.0, memory_length 2000, epsilon 0.4359677255638238\n",
      "state terminated\n",
      "episode 4152, reward 1435.0, memory_length 2000, epsilon 0.4358805427372843\n",
      "state terminated\n",
      "episode 4153, reward 1296.0, memory_length 2000, epsilon 0.4357933773455666\n",
      "state terminated\n",
      "episode 4154, reward 2044.0, memory_length 2000, epsilon 0.435706229385184\n",
      "state terminated\n",
      "episode 4155, reward 1926.0, memory_length 2000, epsilon 0.4356190988526506\n",
      "state terminated\n",
      "episode 4156, reward 1961.0, memory_length 2000, epsilon 0.43553198574448126\n",
      "state terminated\n",
      "episode 4157, reward 1260.0, memory_length 2000, epsilon 0.4354448900571915\n",
      "state terminated\n",
      "episode 4158, reward 1769.0, memory_length 2000, epsilon 0.43535781178729727\n",
      "state terminated\n",
      "episode 4159, reward 1455.0, memory_length 2000, epsilon 0.43527075093131556\n",
      "state terminated\n",
      "episode 4160, reward 2042.0, memory_length 2000, epsilon 0.435183707485764\n",
      "state terminated\n",
      "episode 4161, reward 1573.0, memory_length 2000, epsilon 0.4350966814471608\n",
      "state terminated\n",
      "episode 4162, reward 1497.0, memory_length 2000, epsilon 0.4350096728120249\n",
      "state terminated\n",
      "episode 4163, reward 1633.0, memory_length 2000, epsilon 0.434922681576876\n",
      "state terminated\n",
      "episode 4164, reward 1786.0, memory_length 2000, epsilon 0.4348357077382345\n",
      "state terminated\n",
      "episode 4165, reward 2010.0, memory_length 2000, epsilon 0.4347487512926212\n",
      "state terminated\n",
      "episode 4166, reward 1665.0, memory_length 2000, epsilon 0.43466181223655803\n",
      "state terminated\n",
      "episode 4167, reward 1721.0, memory_length 2000, epsilon 0.4345748905665675\n",
      "state terminated\n",
      "episode 4168, reward 1333.0, memory_length 2000, epsilon 0.4344879862791726\n",
      "state terminated\n",
      "episode 4169, reward 1448.0, memory_length 2000, epsilon 0.43440109937089727\n",
      "state terminated\n",
      "episode 4170, reward 1413.0, memory_length 2000, epsilon 0.43431422983826584\n",
      "state terminated\n",
      "episode 4171, reward 1389.0, memory_length 2000, epsilon 0.4342273776778038\n",
      "state terminated\n",
      "episode 4172, reward 1795.0, memory_length 2000, epsilon 0.4341405428860369\n",
      "state terminated\n",
      "episode 4173, reward 1233.0, memory_length 2000, epsilon 0.43405372545949167\n",
      "state terminated\n",
      "episode 4174, reward 1560.0, memory_length 2000, epsilon 0.4339669253946956\n",
      "state terminated\n",
      "episode 4175, reward 1520.0, memory_length 2000, epsilon 0.4338801426881766\n",
      "state terminated\n",
      "episode 4176, reward 1714.0, memory_length 2000, epsilon 0.43379337733646334\n",
      "state terminated\n",
      "episode 4177, reward 1625.0, memory_length 2000, epsilon 0.4337066293360852\n",
      "state terminated\n",
      "episode 4178, reward 1606.0, memory_length 2000, epsilon 0.4336198986835724\n",
      "state terminated\n",
      "episode 4179, reward 1418.0, memory_length 2000, epsilon 0.43353318537545554\n",
      "state terminated\n",
      "episode 4180, reward 1267.0, memory_length 2000, epsilon 0.43344648940826613\n",
      "state terminated\n",
      "episode 4181, reward 1188.0, memory_length 2000, epsilon 0.43335981077853636\n",
      "state terminated\n",
      "episode 4182, reward 1863.0, memory_length 2000, epsilon 0.4332731494827991\n",
      "state terminated\n",
      "episode 4183, reward 1538.0, memory_length 2000, epsilon 0.4331865055175879\n",
      "state terminated\n",
      "episode 4184, reward 1528.0, memory_length 2000, epsilon 0.433099878879437\n",
      "state terminated\n",
      "episode 4185, reward 1918.0, memory_length 2000, epsilon 0.43301326956488123\n",
      "state terminated\n",
      "episode 4186, reward 1741.0, memory_length 2000, epsilon 0.43292667757045633\n",
      "state terminated\n",
      "episode 4187, reward 1873.0, memory_length 2000, epsilon 0.4328401028926986\n",
      "state terminated\n",
      "episode 4188, reward 1068.0, memory_length 2000, epsilon 0.43275354552814504\n",
      "state terminated\n",
      "episode 4189, reward 1218.0, memory_length 2000, epsilon 0.43266700547333337\n",
      "state terminated\n",
      "episode 4190, reward 1286.0, memory_length 2000, epsilon 0.43258048272480193\n",
      "state terminated\n",
      "episode 4191, reward 1769.0, memory_length 2000, epsilon 0.4324939772790899\n",
      "state terminated\n",
      "episode 4192, reward 1548.0, memory_length 2000, epsilon 0.432407489132737\n",
      "state terminated\n",
      "episode 4193, reward 1459.0, memory_length 2000, epsilon 0.4323210182822838\n",
      "state terminated\n",
      "episode 4194, reward 1426.0, memory_length 2000, epsilon 0.4322345647242713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4195, reward 1670.0, memory_length 2000, epsilon 0.4321481284552414\n",
      "state terminated\n",
      "episode 4196, reward 1823.0, memory_length 2000, epsilon 0.4320617094717368\n",
      "state terminated\n",
      "episode 4197, reward 1555.0, memory_length 2000, epsilon 0.43197530777030063\n",
      "state terminated\n",
      "episode 4198, reward 1610.0, memory_length 2000, epsilon 0.43188892334747675\n",
      "state terminated\n",
      "episode 4199, reward 1557.0, memory_length 2000, epsilon 0.43180255619980995\n",
      "state terminated\n",
      "episode 4200, reward 1235.0, memory_length 2000, epsilon 0.4317162063238454\n",
      "state terminated\n",
      "episode 4201, reward 1489.0, memory_length 2000, epsilon 0.4316298737161292\n",
      "state terminated\n",
      "episode 4202, reward 1344.0, memory_length 2000, epsilon 0.43154355837320796\n",
      "state terminated\n",
      "episode 4203, reward 1494.0, memory_length 2000, epsilon 0.4314572602916292\n",
      "state terminated\n",
      "episode 4204, reward 1431.0, memory_length 2000, epsilon 0.43137097946794084\n",
      "state terminated\n",
      "episode 4205, reward 1482.0, memory_length 2000, epsilon 0.43128471589869166\n",
      "state terminated\n",
      "episode 4206, reward 1737.0, memory_length 2000, epsilon 0.43119846958043123\n",
      "state terminated\n",
      "episode 4207, reward 1265.0, memory_length 2000, epsilon 0.43111224050970964\n",
      "state terminated\n",
      "episode 4208, reward 1649.0, memory_length 2000, epsilon 0.43102602868307777\n",
      "state terminated\n",
      "episode 4209, reward 1794.0, memory_length 2000, epsilon 0.4309398340970871\n",
      "state terminated\n",
      "episode 4210, reward 1866.0, memory_length 2000, epsilon 0.43085365674828974\n",
      "state terminated\n",
      "episode 4211, reward 1659.0, memory_length 2000, epsilon 0.4307674966332388\n",
      "state terminated\n",
      "episode 4212, reward 1322.0, memory_length 2000, epsilon 0.4306813537484878\n",
      "state terminated\n",
      "episode 4213, reward 1511.0, memory_length 2000, epsilon 0.430595228090591\n",
      "state terminated\n",
      "episode 4214, reward 1421.0, memory_length 2000, epsilon 0.4305091196561034\n",
      "state terminated\n",
      "episode 4215, reward 1523.0, memory_length 2000, epsilon 0.43042302844158054\n",
      "state terminated\n",
      "episode 4216, reward 1762.0, memory_length 2000, epsilon 0.4303369544435789\n",
      "state terminated\n",
      "episode 4217, reward 1606.0, memory_length 2000, epsilon 0.4302508976586556\n",
      "state terminated\n",
      "episode 4218, reward 1586.0, memory_length 2000, epsilon 0.43016485808336813\n",
      "state terminated\n",
      "episode 4219, reward 1395.0, memory_length 2000, epsilon 0.4300788357142752\n",
      "state terminated\n",
      "episode 4220, reward 1255.0, memory_length 2000, epsilon 0.4299928305479356\n",
      "state terminated\n",
      "episode 4221, reward 2087.0, memory_length 2000, epsilon 0.42990684258090933\n",
      "state terminated\n",
      "episode 4222, reward 1606.0, memory_length 2000, epsilon 0.4298208718097568\n",
      "state terminated\n",
      "episode 4223, reward 1653.0, memory_length 2000, epsilon 0.42973491823103926\n",
      "state terminated\n",
      "episode 4224, reward 1799.0, memory_length 2000, epsilon 0.42964898184131856\n",
      "state terminated\n",
      "episode 4225, reward 1737.0, memory_length 2000, epsilon 0.429563062637157\n",
      "state terminated\n",
      "episode 4226, reward 1537.0, memory_length 2000, epsilon 0.42947716061511815\n",
      "state terminated\n",
      "episode 4227, reward 1541.0, memory_length 2000, epsilon 0.4293912757717657\n",
      "state terminated\n",
      "episode 4228, reward 1525.0, memory_length 2000, epsilon 0.42930540810366447\n",
      "state terminated\n",
      "episode 4229, reward 1563.0, memory_length 2000, epsilon 0.4292195576073795\n",
      "state terminated\n",
      "episode 4230, reward 1507.0, memory_length 2000, epsilon 0.42913372427947694\n",
      "state terminated\n",
      "episode 4231, reward 1794.0, memory_length 2000, epsilon 0.4290479081165234\n",
      "state terminated\n",
      "episode 4232, reward 1438.0, memory_length 2000, epsilon 0.4289621091150862\n",
      "state terminated\n",
      "episode 4233, reward 1672.0, memory_length 2000, epsilon 0.42887632727173347\n",
      "state terminated\n",
      "episode 4234, reward 1768.0, memory_length 2000, epsilon 0.4287905625830339\n",
      "state terminated\n",
      "episode 4235, reward 1478.0, memory_length 2000, epsilon 0.42870481504555685\n",
      "state terminated\n",
      "episode 4236, reward 1592.0, memory_length 2000, epsilon 0.42861908465587245\n",
      "state terminated\n",
      "episode 4237, reward 1597.0, memory_length 2000, epsilon 0.42853337141055153\n",
      "state terminated\n",
      "episode 4238, reward 1676.0, memory_length 2000, epsilon 0.42844767530616557\n",
      "state terminated\n",
      "episode 4239, reward 1791.0, memory_length 2000, epsilon 0.42836199633928657\n",
      "state terminated\n",
      "episode 4240, reward 1836.0, memory_length 2000, epsilon 0.42827633450648755\n",
      "state terminated\n",
      "episode 4241, reward 1493.0, memory_length 2000, epsilon 0.42819068980434194\n",
      "state terminated\n",
      "episode 4242, reward 1461.0, memory_length 2000, epsilon 0.428105062229424\n",
      "state terminated\n",
      "episode 4243, reward 1568.0, memory_length 2000, epsilon 0.4280194517783086\n",
      "state terminated\n",
      "episode 4244, reward 1752.0, memory_length 2000, epsilon 0.42793385844757137\n",
      "state terminated\n",
      "episode 4245, reward 1469.0, memory_length 2000, epsilon 0.4278482822337884\n",
      "state terminated\n",
      "episode 4246, reward 1442.0, memory_length 2000, epsilon 0.42776272313353686\n",
      "state terminated\n",
      "episode 4247, reward 1676.0, memory_length 2000, epsilon 0.42767718114339437\n",
      "state terminated\n",
      "episode 4248, reward 1901.0, memory_length 2000, epsilon 0.4275916562599391\n",
      "state terminated\n",
      "episode 4249, reward 1479.0, memory_length 2000, epsilon 0.42750614847975016\n",
      "state terminated\n",
      "episode 4250, reward 1380.0, memory_length 2000, epsilon 0.4274206577994072\n",
      "state terminated\n",
      "episode 4251, reward 1653.0, memory_length 2000, epsilon 0.4273351842154906\n",
      "state terminated\n",
      "episode 4252, reward 1577.0, memory_length 2000, epsilon 0.4272497277245815\n",
      "state terminated\n",
      "episode 4253, reward 1675.0, memory_length 2000, epsilon 0.4271642883232615\n",
      "state terminated\n",
      "episode 4254, reward 1633.0, memory_length 2000, epsilon 0.42707886600811307\n",
      "state terminated\n",
      "episode 4255, reward 1664.0, memory_length 2000, epsilon 0.42699346077571937\n",
      "state terminated\n",
      "episode 4256, reward 1837.0, memory_length 2000, epsilon 0.42690807262266417\n",
      "state terminated\n",
      "episode 4257, reward 1460.0, memory_length 2000, epsilon 0.4268227015455319\n",
      "state terminated\n",
      "episode 4258, reward 1419.0, memory_length 2000, epsilon 0.4267373475409078\n",
      "state terminated\n",
      "episode 4259, reward 1620.0, memory_length 2000, epsilon 0.4266520106053776\n",
      "state terminated\n",
      "episode 4260, reward 1326.0, memory_length 2000, epsilon 0.4265666907355279\n",
      "state terminated\n",
      "episode 4261, reward 1734.0, memory_length 2000, epsilon 0.42648138792794593\n",
      "state terminated\n",
      "episode 4262, reward 1796.0, memory_length 2000, epsilon 0.42639610217921947\n",
      "state terminated\n",
      "episode 4263, reward 1754.0, memory_length 2000, epsilon 0.42631083348593724\n",
      "state terminated\n",
      "episode 4264, reward 1505.0, memory_length 2000, epsilon 0.42622558184468834\n",
      "state terminated\n",
      "episode 4265, reward 1422.0, memory_length 2000, epsilon 0.42614034725206273\n",
      "state terminated\n",
      "episode 4266, reward 1637.0, memory_length 2000, epsilon 0.42605512970465115\n",
      "state terminated\n",
      "episode 4267, reward 1514.0, memory_length 2000, epsilon 0.4259699291990448\n",
      "state terminated\n",
      "episode 4268, reward 1836.0, memory_length 2000, epsilon 0.42588474573183566\n",
      "state terminated\n",
      "episode 4269, reward 1375.0, memory_length 2000, epsilon 0.42579957929961637\n",
      "state terminated\n",
      "episode 4270, reward 1629.0, memory_length 2000, epsilon 0.42571442989898034\n",
      "state terminated\n",
      "episode 4271, reward 1420.0, memory_length 2000, epsilon 0.4256292975265215\n",
      "state terminated\n",
      "episode 4272, reward 1900.0, memory_length 2000, epsilon 0.4255441821788348\n",
      "state terminated\n",
      "episode 4273, reward 1781.0, memory_length 2000, epsilon 0.4254590838525153\n",
      "state terminated\n",
      "episode 4274, reward 1653.0, memory_length 2000, epsilon 0.42537400254415925\n",
      "state terminated\n",
      "episode 4275, reward 1574.0, memory_length 2000, epsilon 0.4252889382503633\n",
      "state terminated\n",
      "episode 4276, reward 1672.0, memory_length 2000, epsilon 0.425203890967725\n",
      "state terminated\n",
      "episode 4277, reward 1356.0, memory_length 2000, epsilon 0.4251188606928423\n",
      "state terminated\n",
      "episode 4278, reward 1648.0, memory_length 2000, epsilon 0.42503384742231426\n",
      "state terminated\n",
      "episode 4279, reward 1541.0, memory_length 2000, epsilon 0.42494885115274006\n",
      "state terminated\n",
      "episode 4280, reward 1524.0, memory_length 2000, epsilon 0.42486387188071995\n",
      "state terminated\n",
      "episode 4281, reward 1931.0, memory_length 2000, epsilon 0.4247789096028548\n",
      "state terminated\n",
      "episode 4282, reward 1146.0, memory_length 2000, epsilon 0.4246939643157461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4283, reward 1532.0, memory_length 2000, epsilon 0.42460903601599603\n",
      "state terminated\n",
      "episode 4284, reward 1874.0, memory_length 2000, epsilon 0.4245241247002075\n",
      "state terminated\n",
      "episode 4285, reward 1461.0, memory_length 2000, epsilon 0.4244392303649839\n",
      "state terminated\n",
      "episode 4286, reward 1314.0, memory_length 2000, epsilon 0.42435435300692964\n",
      "state terminated\n",
      "episode 4287, reward 1494.0, memory_length 2000, epsilon 0.4242694926226495\n",
      "state terminated\n",
      "episode 4288, reward 1692.0, memory_length 2000, epsilon 0.4241846492087492\n",
      "state terminated\n",
      "episode 4289, reward 1433.0, memory_length 2000, epsilon 0.42409982276183494\n",
      "state terminated\n",
      "episode 4290, reward 1378.0, memory_length 2000, epsilon 0.42401501327851354\n",
      "state terminated\n",
      "episode 4291, reward 1768.0, memory_length 2000, epsilon 0.42393022075539283\n",
      "state terminated\n",
      "episode 4292, reward 1664.0, memory_length 2000, epsilon 0.42384544518908096\n",
      "state terminated\n",
      "episode 4293, reward 1741.0, memory_length 2000, epsilon 0.423760686576187\n",
      "state terminated\n",
      "episode 4294, reward 1601.0, memory_length 2000, epsilon 0.4236759449133205\n",
      "state terminated\n",
      "episode 4295, reward 1449.0, memory_length 2000, epsilon 0.4235912201970919\n",
      "state terminated\n",
      "episode 4296, reward 1923.0, memory_length 2000, epsilon 0.4235065124241121\n",
      "state terminated\n",
      "episode 4297, reward 1930.0, memory_length 2000, epsilon 0.4234218215909929\n",
      "state terminated\n",
      "episode 4298, reward 1200.0, memory_length 2000, epsilon 0.4233371476943466\n",
      "state terminated\n",
      "episode 4299, reward 1359.0, memory_length 2000, epsilon 0.4232524907307863\n",
      "state terminated\n",
      "episode 4300, reward 1474.0, memory_length 2000, epsilon 0.4231678506969257\n",
      "state terminated\n",
      "episode 4301, reward 1925.0, memory_length 2000, epsilon 0.4230832275893791\n",
      "state terminated\n",
      "episode 4302, reward 1245.0, memory_length 2000, epsilon 0.42299862140476174\n",
      "state terminated\n",
      "episode 4303, reward 1363.0, memory_length 2000, epsilon 0.4229140321396892\n",
      "state terminated\n",
      "episode 4304, reward 1890.0, memory_length 2000, epsilon 0.42282945979077813\n",
      "state terminated\n",
      "episode 4305, reward 1504.0, memory_length 2000, epsilon 0.4227449043546454\n",
      "state terminated\n",
      "episode 4306, reward 1771.0, memory_length 2000, epsilon 0.4226603658279089\n",
      "state terminated\n",
      "episode 4307, reward 1596.0, memory_length 2000, epsilon 0.42257584420718713\n",
      "state terminated\n",
      "episode 4308, reward 1134.0, memory_length 2000, epsilon 0.4224913394890992\n",
      "state terminated\n",
      "episode 4309, reward 1948.0, memory_length 2000, epsilon 0.4224068516702649\n",
      "state terminated\n",
      "episode 4310, reward 1885.0, memory_length 2000, epsilon 0.42232238074730477\n",
      "state terminated\n",
      "episode 4311, reward 1712.0, memory_length 2000, epsilon 0.4222379267168398\n",
      "state terminated\n",
      "episode 4312, reward 1897.0, memory_length 2000, epsilon 0.42215348957549204\n",
      "state terminated\n",
      "episode 4313, reward 1430.0, memory_length 2000, epsilon 0.4220690693198839\n",
      "state terminated\n",
      "episode 4314, reward 1597.0, memory_length 2000, epsilon 0.4219846659466386\n",
      "state terminated\n",
      "episode 4315, reward 1373.0, memory_length 2000, epsilon 0.42190027945237996\n",
      "state terminated\n",
      "episode 4316, reward 1926.0, memory_length 2000, epsilon 0.4218159098337326\n",
      "state terminated\n",
      "episode 4317, reward 1413.0, memory_length 2000, epsilon 0.4217315570873217\n",
      "state terminated\n",
      "episode 4318, reward 1448.0, memory_length 2000, epsilon 0.4216472212097731\n",
      "state terminated\n",
      "episode 4319, reward 1570.0, memory_length 2000, epsilon 0.4215629021977134\n",
      "state terminated\n",
      "episode 4320, reward 1596.0, memory_length 2000, epsilon 0.4214786000477699\n",
      "state terminated\n",
      "episode 4321, reward 1274.0, memory_length 2000, epsilon 0.4213943147565704\n",
      "state terminated\n",
      "episode 4322, reward 1651.0, memory_length 2000, epsilon 0.42131004632074354\n",
      "state terminated\n",
      "episode 4323, reward 1615.0, memory_length 2000, epsilon 0.4212257947369186\n",
      "state terminated\n",
      "episode 4324, reward 1633.0, memory_length 2000, epsilon 0.42114156000172553\n",
      "state terminated\n",
      "episode 4325, reward 1492.0, memory_length 2000, epsilon 0.42105734211179496\n",
      "state terminated\n",
      "episode 4326, reward 1836.0, memory_length 2000, epsilon 0.420973141063758\n",
      "state terminated\n",
      "episode 4327, reward 1811.0, memory_length 2000, epsilon 0.4208889568542468\n",
      "state terminated\n",
      "episode 4328, reward 1582.0, memory_length 2000, epsilon 0.42080478947989397\n",
      "state terminated\n",
      "episode 4329, reward 1759.0, memory_length 2000, epsilon 0.42072063893733275\n",
      "state terminated\n",
      "episode 4330, reward 1521.0, memory_length 2000, epsilon 0.4206365052231972\n",
      "state terminated\n",
      "episode 4331, reward 1605.0, memory_length 2000, epsilon 0.4205523883341218\n",
      "state terminated\n",
      "episode 4332, reward 1674.0, memory_length 2000, epsilon 0.42046828826674204\n",
      "state terminated\n",
      "episode 4333, reward 1531.0, memory_length 2000, epsilon 0.4203842050176939\n",
      "state terminated\n",
      "episode 4334, reward 1728.0, memory_length 2000, epsilon 0.420300138583614\n",
      "state terminated\n",
      "episode 4335, reward 1593.0, memory_length 2000, epsilon 0.42021608896113966\n",
      "state terminated\n",
      "episode 4336, reward 1178.0, memory_length 2000, epsilon 0.42013205614690896\n",
      "state terminated\n",
      "episode 4337, reward 1786.0, memory_length 2000, epsilon 0.4200480401375606\n",
      "state terminated\n",
      "episode 4338, reward 1489.0, memory_length 2000, epsilon 0.41996404092973383\n",
      "state terminated\n",
      "episode 4339, reward 1744.0, memory_length 2000, epsilon 0.4198800585200688\n",
      "state terminated\n",
      "episode 4340, reward 1719.0, memory_length 2000, epsilon 0.4197960929052062\n",
      "state terminated\n",
      "episode 4341, reward 1933.0, memory_length 2000, epsilon 0.4197121440817873\n",
      "state terminated\n",
      "episode 4342, reward 1694.0, memory_length 2000, epsilon 0.41962821204645423\n",
      "state terminated\n",
      "episode 4343, reward 1660.0, memory_length 2000, epsilon 0.4195442967958497\n",
      "state terminated\n",
      "episode 4344, reward 1494.0, memory_length 2000, epsilon 0.41946039832661713\n",
      "state terminated\n",
      "episode 4345, reward 1587.0, memory_length 2000, epsilon 0.41937651663540054\n",
      "state terminated\n",
      "episode 4346, reward 1846.0, memory_length 2000, epsilon 0.41929265171884467\n",
      "state terminated\n",
      "episode 4347, reward 1654.0, memory_length 2000, epsilon 0.4192088035735949\n",
      "state terminated\n",
      "episode 4348, reward 1539.0, memory_length 2000, epsilon 0.41912497219629735\n",
      "state terminated\n",
      "episode 4349, reward 1937.0, memory_length 2000, epsilon 0.4190411575835988\n",
      "state terminated\n",
      "episode 4350, reward 1510.0, memory_length 2000, epsilon 0.41895735973214654\n",
      "state terminated\n",
      "episode 4351, reward 1681.0, memory_length 2000, epsilon 0.4188735786385887\n",
      "state terminated\n",
      "episode 4352, reward 1711.0, memory_length 2000, epsilon 0.4187898142995741\n",
      "state terminated\n",
      "episode 4353, reward 1614.0, memory_length 2000, epsilon 0.41870606671175215\n",
      "state terminated\n",
      "episode 4354, reward 1801.0, memory_length 2000, epsilon 0.4186223358717729\n",
      "state terminated\n",
      "episode 4355, reward 1554.0, memory_length 2000, epsilon 0.41853862177628715\n",
      "state terminated\n",
      "episode 4356, reward 1860.0, memory_length 2000, epsilon 0.41845492442194626\n",
      "state terminated\n",
      "episode 4357, reward 1848.0, memory_length 2000, epsilon 0.41837124380540247\n",
      "state terminated\n",
      "episode 4358, reward 1410.0, memory_length 2000, epsilon 0.4182875799233085\n",
      "state terminated\n",
      "episode 4359, reward 1539.0, memory_length 2000, epsilon 0.4182039327723178\n",
      "state terminated\n",
      "episode 4360, reward 1656.0, memory_length 2000, epsilon 0.4181203023490844\n",
      "state terminated\n",
      "episode 4361, reward 1430.0, memory_length 2000, epsilon 0.4180366886502631\n",
      "state terminated\n",
      "episode 4362, reward 1674.0, memory_length 2000, epsilon 0.41795309167250955\n",
      "state terminated\n",
      "episode 4363, reward 1332.0, memory_length 2000, epsilon 0.41786951141247963\n",
      "state terminated\n",
      "episode 4364, reward 1529.0, memory_length 2000, epsilon 0.41778594786683027\n",
      "state terminated\n",
      "episode 4365, reward 1497.0, memory_length 2000, epsilon 0.41770240103221884\n",
      "state terminated\n",
      "episode 4366, reward 1760.0, memory_length 2000, epsilon 0.41761887090530353\n",
      "state terminated\n",
      "episode 4367, reward 1431.0, memory_length 2000, epsilon 0.4175353574827431\n",
      "state terminated\n",
      "episode 4368, reward 1657.0, memory_length 2000, epsilon 0.417451860761197\n",
      "state terminated\n",
      "episode 4369, reward 1475.0, memory_length 2000, epsilon 0.41736838073732546\n",
      "state terminated\n",
      "episode 4370, reward 1407.0, memory_length 2000, epsilon 0.41728491740778917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4371, reward 1581.0, memory_length 2000, epsilon 0.4172014707692496\n",
      "state terminated\n",
      "episode 4372, reward 1906.0, memory_length 2000, epsilon 0.41711804081836895\n",
      "state terminated\n",
      "episode 4373, reward 1983.0, memory_length 2000, epsilon 0.41703462755181\n",
      "state terminated\n",
      "episode 4374, reward 1486.0, memory_length 2000, epsilon 0.41695123096623615\n",
      "state terminated\n",
      "episode 4375, reward 1435.0, memory_length 2000, epsilon 0.41686785105831164\n",
      "state terminated\n",
      "episode 4376, reward 1647.0, memory_length 2000, epsilon 0.4167844878247012\n",
      "state terminated\n",
      "episode 4377, reward 1871.0, memory_length 2000, epsilon 0.4167011412620703\n",
      "state terminated\n",
      "episode 4378, reward 1530.0, memory_length 2000, epsilon 0.4166178113670852\n",
      "state terminated\n",
      "episode 4379, reward 1749.0, memory_length 2000, epsilon 0.4165344981364126\n",
      "state terminated\n",
      "episode 4380, reward 1453.0, memory_length 2000, epsilon 0.4164512015667199\n",
      "state terminated\n",
      "episode 4381, reward 1907.0, memory_length 2000, epsilon 0.41636792165467534\n",
      "state terminated\n",
      "episode 4382, reward 1296.0, memory_length 2000, epsilon 0.4162846583969477\n",
      "state terminated\n",
      "episode 4383, reward 1192.0, memory_length 2000, epsilon 0.41620141179020653\n",
      "state terminated\n",
      "episode 4384, reward 1732.0, memory_length 2000, epsilon 0.4161181818311218\n",
      "state terminated\n",
      "episode 4385, reward 1684.0, memory_length 2000, epsilon 0.41603496851636446\n",
      "state terminated\n",
      "episode 4386, reward 1530.0, memory_length 2000, epsilon 0.4159517718426059\n",
      "state terminated\n",
      "episode 4387, reward 1473.0, memory_length 2000, epsilon 0.41586859180651825\n",
      "state terminated\n",
      "episode 4388, reward 1773.0, memory_length 2000, epsilon 0.4157854284047743\n",
      "state terminated\n",
      "episode 4389, reward 1637.0, memory_length 2000, epsilon 0.41570228163404754\n",
      "state terminated\n",
      "episode 4390, reward 1425.0, memory_length 2000, epsilon 0.41561915149101214\n",
      "state terminated\n",
      "episode 4391, reward 1462.0, memory_length 2000, epsilon 0.4155360379723429\n",
      "state terminated\n",
      "episode 4392, reward 1538.0, memory_length 2000, epsilon 0.4154529410747152\n",
      "state terminated\n",
      "episode 4393, reward 1462.0, memory_length 2000, epsilon 0.41536986079480515\n",
      "state terminated\n",
      "episode 4394, reward 1705.0, memory_length 2000, epsilon 0.4152867971292896\n",
      "state terminated\n",
      "episode 4395, reward 1510.0, memory_length 2000, epsilon 0.41520375007484606\n",
      "state terminated\n",
      "episode 4396, reward 1922.0, memory_length 2000, epsilon 0.41512071962815245\n",
      "state terminated\n",
      "episode 4397, reward 1602.0, memory_length 2000, epsilon 0.4150377057858878\n",
      "state terminated\n",
      "episode 4398, reward 1725.0, memory_length 2000, epsilon 0.41495470854473143\n",
      "state terminated\n",
      "episode 4399, reward 1519.0, memory_length 2000, epsilon 0.4148717279013634\n",
      "state terminated\n",
      "episode 4400, reward 1624.0, memory_length 2000, epsilon 0.4147887638524646\n",
      "state terminated\n",
      "episode 4401, reward 1503.0, memory_length 2000, epsilon 0.4147058163947163\n",
      "state terminated\n",
      "episode 4402, reward 1750.0, memory_length 2000, epsilon 0.4146228855248008\n",
      "state terminated\n",
      "episode 4403, reward 1451.0, memory_length 2000, epsilon 0.4145399712394008\n",
      "state terminated\n",
      "episode 4404, reward 1779.0, memory_length 2000, epsilon 0.41445707353519967\n",
      "state terminated\n",
      "episode 4405, reward 1468.0, memory_length 2000, epsilon 0.41437419240888157\n",
      "state terminated\n",
      "episode 4406, reward 1519.0, memory_length 2000, epsilon 0.4142913278571311\n",
      "state terminated\n",
      "episode 4407, reward 1723.0, memory_length 2000, epsilon 0.4142084798766339\n",
      "state terminated\n",
      "episode 4408, reward 1844.0, memory_length 2000, epsilon 0.41412564846407596\n",
      "state terminated\n",
      "episode 4409, reward 1725.0, memory_length 2000, epsilon 0.41404283361614397\n",
      "state terminated\n",
      "episode 4410, reward 1963.0, memory_length 2000, epsilon 0.4139600353295254\n",
      "state terminated\n",
      "episode 4411, reward 1737.0, memory_length 2000, epsilon 0.41387725360090827\n",
      "state terminated\n",
      "episode 4412, reward 1608.0, memory_length 2000, epsilon 0.41379448842698136\n",
      "state terminated\n",
      "episode 4413, reward 1349.0, memory_length 2000, epsilon 0.41371173980443404\n",
      "state terminated\n",
      "episode 4414, reward 1250.0, memory_length 2000, epsilon 0.4136290077299564\n",
      "state terminated\n",
      "episode 4415, reward 1516.0, memory_length 2000, epsilon 0.41354629220023914\n",
      "state terminated\n",
      "episode 4416, reward 1268.0, memory_length 2000, epsilon 0.4134635932119735\n",
      "state terminated\n",
      "episode 4417, reward 1750.0, memory_length 2000, epsilon 0.41338091076185174\n",
      "state terminated\n",
      "episode 4418, reward 1191.0, memory_length 2000, epsilon 0.41329824484656646\n",
      "state terminated\n",
      "episode 4419, reward 1863.0, memory_length 2000, epsilon 0.41321559546281106\n",
      "state terminated\n",
      "episode 4420, reward 1574.0, memory_length 2000, epsilon 0.41313296260727944\n",
      "state terminated\n",
      "episode 4421, reward 2074.0, memory_length 2000, epsilon 0.4130503462766664\n",
      "state terminated\n",
      "episode 4422, reward 1641.0, memory_length 2000, epsilon 0.4129677464676674\n",
      "state terminated\n",
      "episode 4423, reward 1482.0, memory_length 2000, epsilon 0.4128851631769782\n",
      "state terminated\n",
      "episode 4424, reward 1498.0, memory_length 2000, epsilon 0.41280259640129563\n",
      "state terminated\n",
      "episode 4425, reward 1674.0, memory_length 2000, epsilon 0.41272004613731694\n",
      "state terminated\n",
      "episode 4426, reward 1712.0, memory_length 2000, epsilon 0.41263751238174007\n",
      "state terminated\n",
      "episode 4427, reward 1748.0, memory_length 2000, epsilon 0.4125549951312638\n",
      "state terminated\n",
      "episode 4428, reward 1645.0, memory_length 2000, epsilon 0.41247249438258743\n",
      "state terminated\n",
      "episode 4429, reward 1726.0, memory_length 2000, epsilon 0.4123900101324109\n",
      "state terminated\n",
      "episode 4430, reward 1614.0, memory_length 2000, epsilon 0.41230754237743483\n",
      "state terminated\n",
      "episode 4431, reward 1488.0, memory_length 2000, epsilon 0.4122250911143605\n",
      "state terminated\n",
      "episode 4432, reward 1582.0, memory_length 2000, epsilon 0.41214265633988983\n",
      "state terminated\n",
      "episode 4433, reward 1495.0, memory_length 2000, epsilon 0.41206023805072545\n",
      "state terminated\n",
      "episode 4434, reward 1530.0, memory_length 2000, epsilon 0.41197783624357076\n",
      "state terminated\n",
      "episode 4435, reward 1737.0, memory_length 2000, epsilon 0.4118954509151295\n",
      "state terminated\n",
      "episode 4436, reward 1573.0, memory_length 2000, epsilon 0.4118130820621063\n",
      "state terminated\n",
      "episode 4437, reward 1575.0, memory_length 2000, epsilon 0.4117307296812065\n",
      "state terminated\n",
      "episode 4438, reward 1862.0, memory_length 2000, epsilon 0.411648393769136\n",
      "state terminated\n",
      "episode 4439, reward 1721.0, memory_length 2000, epsilon 0.41156607432260117\n",
      "state terminated\n",
      "episode 4440, reward 1786.0, memory_length 2000, epsilon 0.41148377133830943\n",
      "state terminated\n",
      "episode 4441, reward 1611.0, memory_length 2000, epsilon 0.4114014848129686\n",
      "state terminated\n",
      "episode 4442, reward 1550.0, memory_length 2000, epsilon 0.41131921474328714\n",
      "state terminated\n",
      "episode 4443, reward 1637.0, memory_length 2000, epsilon 0.41123696112597447\n",
      "state terminated\n",
      "episode 4444, reward 1829.0, memory_length 2000, epsilon 0.41115472395774016\n",
      "state terminated\n",
      "episode 4445, reward 1592.0, memory_length 2000, epsilon 0.411072503235295\n",
      "state terminated\n",
      "episode 4446, reward 1334.0, memory_length 2000, epsilon 0.4109902989553499\n",
      "state terminated\n",
      "episode 4447, reward 1250.0, memory_length 2000, epsilon 0.4109081111146169\n",
      "state terminated\n",
      "episode 4448, reward 1555.0, memory_length 2000, epsilon 0.4108259397098083\n",
      "state terminated\n",
      "episode 4449, reward 2080.0, memory_length 2000, epsilon 0.41074378473763745\n",
      "state terminated\n",
      "episode 4450, reward 1284.0, memory_length 2000, epsilon 0.410661646194818\n",
      "state terminated\n",
      "episode 4451, reward 1533.0, memory_length 2000, epsilon 0.4105795240780645\n",
      "state terminated\n",
      "episode 4452, reward 1890.0, memory_length 2000, epsilon 0.4104974183840919\n",
      "state terminated\n",
      "episode 4453, reward 1665.0, memory_length 2000, epsilon 0.41041532910961614\n",
      "state terminated\n",
      "episode 4454, reward 1578.0, memory_length 2000, epsilon 0.41033325625135364\n",
      "state terminated\n",
      "episode 4455, reward 1321.0, memory_length 2000, epsilon 0.4102511998060214\n",
      "state terminated\n",
      "episode 4456, reward 1296.0, memory_length 2000, epsilon 0.4101691597703373\n",
      "state terminated\n",
      "episode 4457, reward 1695.0, memory_length 2000, epsilon 0.4100871361410195\n",
      "state terminated\n",
      "episode 4458, reward 1413.0, memory_length 2000, epsilon 0.4100051289147873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4459, reward 1413.0, memory_length 2000, epsilon 0.4099231380883603\n",
      "state terminated\n",
      "episode 4460, reward 1749.0, memory_length 2000, epsilon 0.40984116365845885\n",
      "state terminated\n",
      "episode 4461, reward 1596.0, memory_length 2000, epsilon 0.409759205621804\n",
      "state terminated\n",
      "episode 4462, reward 1611.0, memory_length 2000, epsilon 0.4096772639751175\n",
      "state terminated\n",
      "episode 4463, reward 1600.0, memory_length 2000, epsilon 0.40959533871512155\n",
      "state terminated\n",
      "episode 4464, reward 1516.0, memory_length 2000, epsilon 0.4095134298385392\n",
      "state terminated\n",
      "episode 4465, reward 1609.0, memory_length 2000, epsilon 0.4094315373420941\n",
      "state terminated\n",
      "episode 4466, reward 1324.0, memory_length 2000, epsilon 0.4093496612225106\n",
      "state terminated\n",
      "episode 4467, reward 1892.0, memory_length 2000, epsilon 0.40926780147651354\n",
      "state terminated\n",
      "episode 4468, reward 1958.0, memory_length 2000, epsilon 0.40918595810082864\n",
      "state terminated\n",
      "episode 4469, reward 1763.0, memory_length 2000, epsilon 0.4091041310921821\n",
      "state terminated\n",
      "episode 4470, reward 1449.0, memory_length 2000, epsilon 0.40902232044730086\n",
      "state terminated\n",
      "episode 4471, reward 1945.0, memory_length 2000, epsilon 0.40894052616291243\n",
      "state terminated\n",
      "episode 4472, reward 1797.0, memory_length 2000, epsilon 0.40885874823574514\n",
      "state terminated\n",
      "episode 4473, reward 1818.0, memory_length 2000, epsilon 0.4087769866625279\n",
      "state terminated\n",
      "episode 4474, reward 1560.0, memory_length 2000, epsilon 0.40869524143999014\n",
      "state terminated\n",
      "episode 4475, reward 1894.0, memory_length 2000, epsilon 0.40861351256486206\n",
      "state terminated\n",
      "episode 4476, reward 1822.0, memory_length 2000, epsilon 0.40853180003387457\n",
      "state terminated\n",
      "episode 4477, reward 1925.0, memory_length 2000, epsilon 0.4084501038437591\n",
      "state terminated\n",
      "episode 4478, reward 1316.0, memory_length 2000, epsilon 0.4083684239912479\n",
      "state terminated\n",
      "episode 4479, reward 1719.0, memory_length 2000, epsilon 0.40828676047307366\n",
      "state terminated\n",
      "episode 4480, reward 1664.0, memory_length 2000, epsilon 0.4082051132859699\n",
      "state terminated\n",
      "episode 4481, reward 2054.0, memory_length 2000, epsilon 0.4081234824266708\n",
      "state terminated\n",
      "episode 4482, reward 1793.0, memory_length 2000, epsilon 0.4080418678919109\n",
      "state terminated\n",
      "episode 4483, reward 1739.0, memory_length 2000, epsilon 0.4079602696784259\n",
      "state terminated\n",
      "episode 4484, reward 1618.0, memory_length 2000, epsilon 0.40787868778295167\n",
      "state terminated\n",
      "episode 4485, reward 1737.0, memory_length 2000, epsilon 0.4077971222022251\n",
      "state terminated\n",
      "episode 4486, reward 1713.0, memory_length 2000, epsilon 0.4077155729329834\n",
      "state terminated\n",
      "episode 4487, reward 1764.0, memory_length 2000, epsilon 0.4076340399719647\n",
      "state terminated\n",
      "episode 4488, reward 1743.0, memory_length 2000, epsilon 0.4075525233159076\n",
      "state terminated\n",
      "episode 4489, reward 2050.0, memory_length 2000, epsilon 0.4074710229615515\n",
      "state terminated\n",
      "episode 4490, reward 1626.0, memory_length 2000, epsilon 0.40738953890563645\n",
      "state terminated\n",
      "episode 4491, reward 1636.0, memory_length 2000, epsilon 0.407308071144903\n",
      "state terminated\n",
      "episode 4492, reward 1414.0, memory_length 2000, epsilon 0.4072266196760923\n",
      "state terminated\n",
      "episode 4493, reward 1208.0, memory_length 2000, epsilon 0.40714518449594655\n",
      "state terminated\n",
      "episode 4494, reward 1300.0, memory_length 2000, epsilon 0.40706376560120827\n",
      "state terminated\n",
      "episode 4495, reward 1611.0, memory_length 2000, epsilon 0.40698236298862067\n",
      "state terminated\n",
      "episode 4496, reward 1710.0, memory_length 2000, epsilon 0.4069009766549276\n",
      "state terminated\n",
      "episode 4497, reward 1533.0, memory_length 2000, epsilon 0.4068196065968736\n",
      "state terminated\n",
      "episode 4498, reward 1720.0, memory_length 2000, epsilon 0.40673825281120396\n",
      "state terminated\n",
      "episode 4499, reward 1422.0, memory_length 2000, epsilon 0.40665691529466447\n",
      "state terminated\n",
      "episode 4500, reward 1782.0, memory_length 2000, epsilon 0.40657559404400173\n",
      "state terminated\n",
      "episode 4501, reward 2007.0, memory_length 2000, epsilon 0.40649428905596274\n",
      "state terminated\n",
      "episode 4502, reward 1592.0, memory_length 2000, epsilon 0.4064130003272954\n",
      "state terminated\n",
      "episode 4503, reward 1795.0, memory_length 2000, epsilon 0.406331727854748\n",
      "state terminated\n",
      "episode 4504, reward 1908.0, memory_length 2000, epsilon 0.40625047163506994\n",
      "state terminated\n",
      "episode 4505, reward 1533.0, memory_length 2000, epsilon 0.40616923166501073\n",
      "state terminated\n",
      "episode 4506, reward 1622.0, memory_length 2000, epsilon 0.4060880079413209\n",
      "state terminated\n",
      "episode 4507, reward 1582.0, memory_length 2000, epsilon 0.40600680046075127\n",
      "state terminated\n",
      "episode 4508, reward 1381.0, memory_length 2000, epsilon 0.4059256092200539\n",
      "state terminated\n",
      "episode 4509, reward 1443.0, memory_length 2000, epsilon 0.4058444342159809\n",
      "state terminated\n",
      "episode 4510, reward 1505.0, memory_length 2000, epsilon 0.4057632754452853\n",
      "state terminated\n",
      "episode 4511, reward 1478.0, memory_length 2000, epsilon 0.40568213290472077\n",
      "state terminated\n",
      "episode 4512, reward 2088.0, memory_length 2000, epsilon 0.40560100659104154\n",
      "state terminated\n",
      "episode 4513, reward 1919.0, memory_length 2000, epsilon 0.40551989650100273\n",
      "state terminated\n",
      "episode 4514, reward 1562.0, memory_length 2000, epsilon 0.40543880263135984\n",
      "state terminated\n",
      "episode 4515, reward 1794.0, memory_length 2000, epsilon 0.40535772497886907\n",
      "state terminated\n",
      "episode 4516, reward 1695.0, memory_length 2000, epsilon 0.40527666354028735\n",
      "state terminated\n",
      "episode 4517, reward 1718.0, memory_length 2000, epsilon 0.4051956183123723\n",
      "state terminated\n",
      "episode 4518, reward 1551.0, memory_length 2000, epsilon 0.4051145892918819\n",
      "state terminated\n",
      "episode 4519, reward 1604.0, memory_length 2000, epsilon 0.40503357647557525\n",
      "state terminated\n",
      "episode 4520, reward 1957.0, memory_length 2000, epsilon 0.40495257986021166\n",
      "state terminated\n",
      "episode 4521, reward 1315.0, memory_length 2000, epsilon 0.4048715994425513\n",
      "state terminated\n",
      "episode 4522, reward 1628.0, memory_length 2000, epsilon 0.40479063521935493\n",
      "state terminated\n",
      "episode 4523, reward 1656.0, memory_length 2000, epsilon 0.4047096871873841\n",
      "state terminated\n",
      "episode 4524, reward 1909.0, memory_length 2000, epsilon 0.4046287553434008\n",
      "state terminated\n",
      "episode 4525, reward 1584.0, memory_length 2000, epsilon 0.4045478396841678\n",
      "state terminated\n",
      "episode 4526, reward 1834.0, memory_length 2000, epsilon 0.4044669402064484\n",
      "state terminated\n",
      "episode 4527, reward 1765.0, memory_length 2000, epsilon 0.40438605690700663\n",
      "state terminated\n",
      "episode 4528, reward 1510.0, memory_length 2000, epsilon 0.4043051897826072\n",
      "state terminated\n",
      "episode 4529, reward 1825.0, memory_length 2000, epsilon 0.40422433883001546\n",
      "state terminated\n",
      "episode 4530, reward 1782.0, memory_length 2000, epsilon 0.40414350404599736\n",
      "state terminated\n",
      "episode 4531, reward 1751.0, memory_length 2000, epsilon 0.4040626854273194\n",
      "state terminated\n",
      "episode 4532, reward 1493.0, memory_length 2000, epsilon 0.4039818829707489\n",
      "state terminated\n",
      "episode 4533, reward 1986.0, memory_length 2000, epsilon 0.40390109667305385\n",
      "state terminated\n",
      "episode 4534, reward 1699.0, memory_length 2000, epsilon 0.40382032653100264\n",
      "state terminated\n",
      "episode 4535, reward 1980.0, memory_length 2000, epsilon 0.4037395725413646\n",
      "state terminated\n",
      "episode 4536, reward 1461.0, memory_length 2000, epsilon 0.4036588347009095\n",
      "state terminated\n",
      "episode 4537, reward 1415.0, memory_length 2000, epsilon 0.40357811300640783\n",
      "state terminated\n",
      "episode 4538, reward 1723.0, memory_length 2000, epsilon 0.40349740745463075\n",
      "state terminated\n",
      "episode 4539, reward 1700.0, memory_length 2000, epsilon 0.40341671804235\n",
      "state terminated\n",
      "episode 4540, reward 1440.0, memory_length 2000, epsilon 0.4033360447663381\n",
      "state terminated\n",
      "episode 4541, reward 1876.0, memory_length 2000, epsilon 0.403255387623368\n",
      "state terminated\n",
      "episode 4542, reward 1855.0, memory_length 2000, epsilon 0.4031747466102134\n",
      "state terminated\n",
      "episode 4543, reward 1693.0, memory_length 2000, epsilon 0.4030941217236488\n",
      "state terminated\n",
      "episode 4544, reward 1857.0, memory_length 2000, epsilon 0.40301351296044907\n",
      "state terminated\n",
      "episode 4545, reward 1877.0, memory_length 2000, epsilon 0.4029329203173899\n",
      "state terminated\n",
      "episode 4546, reward 1647.0, memory_length 2000, epsilon 0.4028523437912476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4547, reward 1876.0, memory_length 2000, epsilon 0.40277178337879915\n",
      "state terminated\n",
      "episode 4548, reward 1593.0, memory_length 2000, epsilon 0.4026912390768221\n",
      "state terminated\n",
      "episode 4549, reward 1467.0, memory_length 2000, epsilon 0.40261071088209466\n",
      "state terminated\n",
      "episode 4550, reward 1769.0, memory_length 2000, epsilon 0.4025301987913957\n",
      "state terminated\n",
      "episode 4551, reward 1421.0, memory_length 2000, epsilon 0.40244970280150466\n",
      "state terminated\n",
      "episode 4552, reward 2013.0, memory_length 2000, epsilon 0.40236922290920185\n",
      "state terminated\n",
      "episode 4553, reward 1845.0, memory_length 2000, epsilon 0.40228875911126805\n",
      "state terminated\n",
      "episode 4554, reward 1690.0, memory_length 2000, epsilon 0.4022083114044846\n",
      "state terminated\n",
      "episode 4555, reward 1942.0, memory_length 2000, epsilon 0.4021278797856337\n",
      "state terminated\n",
      "episode 4556, reward 1617.0, memory_length 2000, epsilon 0.40204746425149807\n",
      "state terminated\n",
      "episode 4557, reward 1405.0, memory_length 2000, epsilon 0.401967064798861\n",
      "state terminated\n",
      "episode 4558, reward 1801.0, memory_length 2000, epsilon 0.4018866814245066\n",
      "state terminated\n",
      "episode 4559, reward 1440.0, memory_length 2000, epsilon 0.4018063141252195\n",
      "state terminated\n",
      "episode 4560, reward 1780.0, memory_length 2000, epsilon 0.40172596289778506\n",
      "state terminated\n",
      "episode 4561, reward 1644.0, memory_length 2000, epsilon 0.4016456277389892\n",
      "state terminated\n",
      "episode 4562, reward 1927.0, memory_length 2000, epsilon 0.40156530864561846\n",
      "state terminated\n",
      "episode 4563, reward 1743.0, memory_length 2000, epsilon 0.40148500561446016\n",
      "state terminated\n",
      "episode 4564, reward 1561.0, memory_length 2000, epsilon 0.40140471864230204\n",
      "state terminated\n",
      "episode 4565, reward 1569.0, memory_length 2000, epsilon 0.40132444772593284\n",
      "state terminated\n",
      "episode 4566, reward 1921.0, memory_length 2000, epsilon 0.4012441928621415\n",
      "state terminated\n",
      "episode 4567, reward 1487.0, memory_length 2000, epsilon 0.40116395404771804\n",
      "state terminated\n",
      "episode 4568, reward 1807.0, memory_length 2000, epsilon 0.4010837312794527\n",
      "state terminated\n",
      "episode 4569, reward 1817.0, memory_length 2000, epsilon 0.4010035245541367\n",
      "state terminated\n",
      "episode 4570, reward 1798.0, memory_length 2000, epsilon 0.4009233338685617\n",
      "state terminated\n",
      "episode 4571, reward 1748.0, memory_length 2000, epsilon 0.4008431592195202\n",
      "state terminated\n",
      "episode 4572, reward 1767.0, memory_length 2000, epsilon 0.40076300060380504\n",
      "state terminated\n",
      "episode 4573, reward 1606.0, memory_length 2000, epsilon 0.40068285801820996\n",
      "state terminated\n",
      "episode 4574, reward 1735.0, memory_length 2000, epsilon 0.40060273145952924\n",
      "state terminated\n",
      "episode 4575, reward 1697.0, memory_length 2000, epsilon 0.4005226209245579\n",
      "state terminated\n",
      "episode 4576, reward 1587.0, memory_length 2000, epsilon 0.4004425264100914\n",
      "state terminated\n",
      "episode 4577, reward 1917.0, memory_length 2000, epsilon 0.4003624479129261\n",
      "state terminated\n",
      "episode 4578, reward 1849.0, memory_length 2000, epsilon 0.40028238542985867\n",
      "state terminated\n",
      "episode 4579, reward 1557.0, memory_length 2000, epsilon 0.4002023389576867\n",
      "state terminated\n",
      "episode 4580, reward 1596.0, memory_length 2000, epsilon 0.4001223084932084\n",
      "state terminated\n",
      "episode 4581, reward 1510.0, memory_length 2000, epsilon 0.40004229403322245\n",
      "state terminated\n",
      "episode 4582, reward 1529.0, memory_length 2000, epsilon 0.3999622955745284\n",
      "state terminated\n",
      "episode 4583, reward 1743.0, memory_length 2000, epsilon 0.39988231311392614\n",
      "state terminated\n",
      "episode 4584, reward 1559.0, memory_length 2000, epsilon 0.39980234664821646\n",
      "state terminated\n",
      "episode 4585, reward 1809.0, memory_length 2000, epsilon 0.39972239617420074\n",
      "state terminated\n",
      "episode 4586, reward 1451.0, memory_length 2000, epsilon 0.39964246168868084\n",
      "state terminated\n",
      "episode 4587, reward 1600.0, memory_length 2000, epsilon 0.39956254318845963\n",
      "state terminated\n",
      "episode 4588, reward 1852.0, memory_length 2000, epsilon 0.39948264067034\n",
      "state terminated\n",
      "episode 4589, reward 1813.0, memory_length 2000, epsilon 0.39940275413112614\n",
      "state terminated\n",
      "episode 4590, reward 1766.0, memory_length 2000, epsilon 0.3993228835676225\n",
      "state terminated\n",
      "episode 4591, reward 1744.0, memory_length 2000, epsilon 0.39924302897663433\n",
      "state terminated\n",
      "episode 4592, reward 1701.0, memory_length 2000, epsilon 0.3991631903549673\n",
      "state terminated\n",
      "episode 4593, reward 1568.0, memory_length 2000, epsilon 0.39908336769942787\n",
      "state terminated\n",
      "episode 4594, reward 1390.0, memory_length 2000, epsilon 0.39900356100682327\n",
      "state terminated\n",
      "episode 4595, reward 1062.0, memory_length 2000, epsilon 0.3989237702739612\n",
      "state terminated\n",
      "episode 4596, reward 1656.0, memory_length 2000, epsilon 0.39884399549764993\n",
      "state terminated\n",
      "episode 4597, reward 1928.0, memory_length 2000, epsilon 0.39876423667469857\n",
      "state terminated\n",
      "episode 4598, reward 1636.0, memory_length 2000, epsilon 0.3986844938019167\n",
      "state terminated\n",
      "episode 4599, reward 1588.0, memory_length 2000, epsilon 0.3986047668761147\n",
      "state terminated\n",
      "episode 4600, reward 1394.0, memory_length 2000, epsilon 0.3985250558941033\n",
      "state terminated\n",
      "episode 4601, reward 1495.0, memory_length 2000, epsilon 0.39844536085269433\n",
      "state terminated\n",
      "episode 4602, reward 1843.0, memory_length 2000, epsilon 0.3983656817486998\n",
      "state terminated\n",
      "episode 4603, reward 1528.0, memory_length 2000, epsilon 0.39828601857893253\n",
      "state terminated\n",
      "episode 4604, reward 2000.0, memory_length 2000, epsilon 0.39820637134020614\n",
      "state terminated\n",
      "episode 4605, reward 1586.0, memory_length 2000, epsilon 0.3981267400293346\n",
      "state terminated\n",
      "episode 4606, reward 1845.0, memory_length 2000, epsilon 0.39804712464313274\n",
      "state terminated\n",
      "episode 4607, reward 1600.0, memory_length 2000, epsilon 0.397967525178416\n",
      "state terminated\n",
      "episode 4608, reward 1742.0, memory_length 2000, epsilon 0.39788794163200014\n",
      "state terminated\n",
      "episode 4609, reward 1507.0, memory_length 2000, epsilon 0.3978083740007021\n",
      "state terminated\n",
      "episode 4610, reward 1928.0, memory_length 2000, epsilon 0.3977288222813391\n",
      "state terminated\n",
      "episode 4611, reward 1849.0, memory_length 2000, epsilon 0.397649286470729\n",
      "state terminated\n",
      "episode 4612, reward 1683.0, memory_length 2000, epsilon 0.39756976656569043\n",
      "state terminated\n",
      "episode 4613, reward 1754.0, memory_length 2000, epsilon 0.39749026256304254\n",
      "state terminated\n",
      "episode 4614, reward 1632.0, memory_length 2000, epsilon 0.39741077445960526\n",
      "state terminated\n",
      "episode 4615, reward 1974.0, memory_length 2000, epsilon 0.397331302252199\n",
      "state terminated\n",
      "episode 4616, reward 1992.0, memory_length 2000, epsilon 0.39725184593764484\n",
      "state terminated\n",
      "episode 4617, reward 1484.0, memory_length 2000, epsilon 0.3971724055127646\n",
      "state terminated\n",
      "episode 4618, reward 1871.0, memory_length 2000, epsilon 0.3970929809743806\n",
      "state terminated\n",
      "episode 4619, reward 1422.0, memory_length 2000, epsilon 0.397013572319316\n",
      "state terminated\n",
      "episode 4620, reward 1210.0, memory_length 2000, epsilon 0.39693417954439425\n",
      "state terminated\n",
      "episode 4621, reward 1772.0, memory_length 2000, epsilon 0.39685480264643974\n",
      "state terminated\n",
      "episode 4622, reward 1692.0, memory_length 2000, epsilon 0.3967754416222774\n",
      "state terminated\n",
      "episode 4623, reward 1488.0, memory_length 2000, epsilon 0.3966960964687328\n",
      "state terminated\n",
      "episode 4624, reward 1501.0, memory_length 2000, epsilon 0.39661676718263206\n",
      "state terminated\n",
      "episode 4625, reward 1557.0, memory_length 2000, epsilon 0.3965374537608021\n",
      "state terminated\n",
      "episode 4626, reward 1863.0, memory_length 2000, epsilon 0.39645815620007036\n",
      "state terminated\n",
      "episode 4627, reward 2015.0, memory_length 2000, epsilon 0.39637887449726494\n",
      "state terminated\n",
      "episode 4628, reward 1551.0, memory_length 2000, epsilon 0.3962996086492145\n",
      "state terminated\n",
      "episode 4629, reward 1583.0, memory_length 2000, epsilon 0.39622035865274846\n",
      "state terminated\n",
      "episode 4630, reward 1862.0, memory_length 2000, epsilon 0.3961411245046968\n",
      "state terminated\n",
      "episode 4631, reward 1795.0, memory_length 2000, epsilon 0.39606190620189025\n",
      "state terminated\n",
      "episode 4632, reward 1701.0, memory_length 2000, epsilon 0.3959827037411599\n",
      "state terminated\n",
      "episode 4633, reward 1714.0, memory_length 2000, epsilon 0.3959035171193378\n",
      "state terminated\n",
      "episode 4634, reward 1868.0, memory_length 2000, epsilon 0.39582434633325647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4635, reward 1795.0, memory_length 2000, epsilon 0.39574519137974906\n",
      "state terminated\n",
      "episode 4636, reward 1926.0, memory_length 2000, epsilon 0.39566605225564927\n",
      "state terminated\n",
      "episode 4637, reward 1413.0, memory_length 2000, epsilon 0.3955869289577917\n",
      "state terminated\n",
      "episode 4638, reward 1818.0, memory_length 2000, epsilon 0.3955078214830112\n",
      "state terminated\n",
      "episode 4639, reward 1704.0, memory_length 2000, epsilon 0.3954287298281438\n",
      "state terminated\n",
      "episode 4640, reward 1700.0, memory_length 2000, epsilon 0.3953496539900256\n",
      "state terminated\n",
      "episode 4641, reward 1768.0, memory_length 2000, epsilon 0.3952705939654936\n",
      "state terminated\n",
      "episode 4642, reward 1930.0, memory_length 2000, epsilon 0.3951915497513854\n",
      "state terminated\n",
      "episode 4643, reward 1539.0, memory_length 2000, epsilon 0.39511252134453917\n",
      "state terminated\n",
      "episode 4644, reward 1790.0, memory_length 2000, epsilon 0.3950335087417939\n",
      "state terminated\n",
      "episode 4645, reward 1728.0, memory_length 2000, epsilon 0.39495451193998904\n",
      "state terminated\n",
      "episode 4646, reward 1836.0, memory_length 2000, epsilon 0.3948755309359647\n",
      "state terminated\n",
      "episode 4647, reward 1768.0, memory_length 2000, epsilon 0.39479656572656174\n",
      "state terminated\n",
      "episode 4648, reward 1640.0, memory_length 2000, epsilon 0.39471761630862134\n",
      "state terminated\n",
      "episode 4649, reward 1532.0, memory_length 2000, epsilon 0.3946386826789857\n",
      "state terminated\n",
      "episode 4650, reward 1744.0, memory_length 2000, epsilon 0.3945597648344974\n",
      "state terminated\n",
      "episode 4651, reward 1480.0, memory_length 2000, epsilon 0.3944808627719998\n",
      "state terminated\n",
      "episode 4652, reward 1556.0, memory_length 2000, epsilon 0.39440197648833675\n",
      "state terminated\n",
      "episode 4653, reward 1952.0, memory_length 2000, epsilon 0.3943231059803527\n",
      "state terminated\n",
      "episode 4654, reward 1531.0, memory_length 2000, epsilon 0.39424425124489304\n",
      "state terminated\n",
      "episode 4655, reward 1622.0, memory_length 2000, epsilon 0.3941654122788035\n",
      "state terminated\n",
      "episode 4656, reward 1764.0, memory_length 2000, epsilon 0.39408658907893046\n",
      "state terminated\n",
      "episode 4657, reward 1898.0, memory_length 2000, epsilon 0.394007781642121\n",
      "state terminated\n",
      "episode 4658, reward 1714.0, memory_length 2000, epsilon 0.3939289899652229\n",
      "state terminated\n",
      "episode 4659, reward 2001.0, memory_length 2000, epsilon 0.39385021404508447\n",
      "state terminated\n",
      "episode 4660, reward 1431.0, memory_length 2000, epsilon 0.39377145387855467\n",
      "state terminated\n",
      "episode 4661, reward 1660.0, memory_length 2000, epsilon 0.3936927094624831\n",
      "state terminated\n",
      "episode 4662, reward 1572.0, memory_length 2000, epsilon 0.3936139807937199\n",
      "state terminated\n",
      "episode 4663, reward 1860.0, memory_length 2000, epsilon 0.39353526786911597\n",
      "state terminated\n",
      "episode 4664, reward 1811.0, memory_length 2000, epsilon 0.3934565706855228\n",
      "state terminated\n",
      "episode 4665, reward 1466.0, memory_length 2000, epsilon 0.39337788923979256\n",
      "state terminated\n",
      "episode 4666, reward 1705.0, memory_length 2000, epsilon 0.39329922352877794\n",
      "state terminated\n",
      "episode 4667, reward 1799.0, memory_length 2000, epsilon 0.39322057354933226\n",
      "state terminated\n",
      "episode 4668, reward 1971.0, memory_length 2000, epsilon 0.3931419392983096\n",
      "state terminated\n",
      "episode 4669, reward 1739.0, memory_length 2000, epsilon 0.3930633207725646\n",
      "state terminated\n",
      "episode 4670, reward 1673.0, memory_length 2000, epsilon 0.3929847179689524\n",
      "state terminated\n",
      "episode 4671, reward 1766.0, memory_length 2000, epsilon 0.39290613088432913\n",
      "state terminated\n",
      "episode 4672, reward 1648.0, memory_length 2000, epsilon 0.39282755951555104\n",
      "state terminated\n",
      "episode 4673, reward 1763.0, memory_length 2000, epsilon 0.3927490038594753\n",
      "state terminated\n",
      "episode 4674, reward 1606.0, memory_length 2000, epsilon 0.3926704639129599\n",
      "state terminated\n",
      "episode 4675, reward 1467.0, memory_length 2000, epsilon 0.3925919396728631\n",
      "state terminated\n",
      "episode 4676, reward 1206.0, memory_length 2000, epsilon 0.3925134311360439\n",
      "state terminated\n",
      "episode 4677, reward 1795.0, memory_length 2000, epsilon 0.39243493829936194\n",
      "state terminated\n",
      "episode 4678, reward 1480.0, memory_length 2000, epsilon 0.39235646115967765\n",
      "state terminated\n",
      "episode 4679, reward 1881.0, memory_length 2000, epsilon 0.3922779997138518\n",
      "state terminated\n",
      "episode 4680, reward 1692.0, memory_length 2000, epsilon 0.39219955395874606\n",
      "state terminated\n",
      "episode 4681, reward 1843.0, memory_length 2000, epsilon 0.3921211238912225\n",
      "state terminated\n",
      "episode 4682, reward 1667.0, memory_length 2000, epsilon 0.392042709508144\n",
      "state terminated\n",
      "episode 4683, reward 1718.0, memory_length 2000, epsilon 0.3919643108063738\n",
      "state terminated\n",
      "episode 4684, reward 1683.0, memory_length 2000, epsilon 0.3918859277827762\n",
      "state terminated\n",
      "episode 4685, reward 2141.0, memory_length 2000, epsilon 0.39180756043421566\n",
      "state terminated\n",
      "episode 4686, reward 1520.0, memory_length 2000, epsilon 0.39172920875755773\n",
      "state terminated\n",
      "episode 4687, reward 1800.0, memory_length 2000, epsilon 0.39165087274966814\n",
      "state terminated\n",
      "episode 4688, reward 1781.0, memory_length 2000, epsilon 0.39157255240741345\n",
      "state terminated\n",
      "episode 4689, reward 1806.0, memory_length 2000, epsilon 0.39149424772766095\n",
      "state terminated\n",
      "episode 4690, reward 1732.0, memory_length 2000, epsilon 0.39141595870727847\n",
      "state terminated\n",
      "episode 4691, reward 1611.0, memory_length 2000, epsilon 0.3913376853431343\n",
      "state terminated\n",
      "episode 4692, reward 1522.0, memory_length 2000, epsilon 0.39125942763209764\n",
      "state terminated\n",
      "episode 4693, reward 1575.0, memory_length 2000, epsilon 0.39118118557103815\n",
      "state terminated\n",
      "episode 4694, reward 1771.0, memory_length 2000, epsilon 0.39110295915682614\n",
      "state terminated\n",
      "episode 4695, reward 1678.0, memory_length 2000, epsilon 0.3910247483863325\n",
      "state terminated\n",
      "episode 4696, reward 1751.0, memory_length 2000, epsilon 0.3909465532564289\n",
      "state terminated\n",
      "episode 4697, reward 1669.0, memory_length 2000, epsilon 0.3908683737639875\n",
      "state terminated\n",
      "episode 4698, reward 1610.0, memory_length 2000, epsilon 0.39079020990588104\n",
      "state terminated\n",
      "episode 4699, reward 1651.0, memory_length 2000, epsilon 0.390712061678983\n",
      "state terminated\n",
      "episode 4700, reward 1411.0, memory_length 2000, epsilon 0.39063392908016753\n",
      "state terminated\n",
      "episode 4701, reward 1915.0, memory_length 2000, epsilon 0.3905558121063093\n",
      "state terminated\n",
      "episode 4702, reward 1512.0, memory_length 2000, epsilon 0.39047771075428356\n",
      "state terminated\n",
      "episode 4703, reward 1700.0, memory_length 2000, epsilon 0.3903996250209663\n",
      "state terminated\n",
      "episode 4704, reward 1687.0, memory_length 2000, epsilon 0.3903215549032341\n",
      "state terminated\n",
      "episode 4705, reward 1918.0, memory_length 2000, epsilon 0.3902435003979642\n",
      "state terminated\n",
      "episode 4706, reward 1456.0, memory_length 2000, epsilon 0.3901654615020343\n",
      "state terminated\n",
      "episode 4707, reward 1982.0, memory_length 2000, epsilon 0.39008743821232295\n",
      "state terminated\n",
      "episode 4708, reward 1645.0, memory_length 2000, epsilon 0.3900094305257092\n",
      "state terminated\n",
      "episode 4709, reward 1677.0, memory_length 2000, epsilon 0.3899314384390727\n",
      "state terminated\n",
      "episode 4710, reward 1948.0, memory_length 2000, epsilon 0.38985346194929377\n",
      "state terminated\n",
      "episode 4711, reward 1566.0, memory_length 2000, epsilon 0.38977550105325337\n",
      "state terminated\n",
      "episode 4712, reward 1487.0, memory_length 2000, epsilon 0.3896975557478331\n",
      "state terminated\n",
      "episode 4713, reward 1602.0, memory_length 2000, epsilon 0.3896196260299151\n",
      "state terminated\n",
      "episode 4714, reward 2154.0, memory_length 2000, epsilon 0.38954171189638215\n",
      "state terminated\n",
      "episode 4715, reward 1809.0, memory_length 2000, epsilon 0.3894638133441178\n",
      "state terminated\n",
      "episode 4716, reward 1637.0, memory_length 2000, epsilon 0.38938593037000596\n",
      "state terminated\n",
      "episode 4717, reward 1372.0, memory_length 2000, epsilon 0.38930806297093146\n",
      "state terminated\n",
      "episode 4718, reward 1777.0, memory_length 2000, epsilon 0.3892302111437795\n",
      "state terminated\n",
      "episode 4719, reward 1960.0, memory_length 2000, epsilon 0.389152374885436\n",
      "state terminated\n",
      "episode 4720, reward 2058.0, memory_length 2000, epsilon 0.3890745541927875\n",
      "state terminated\n",
      "episode 4721, reward 1870.0, memory_length 2000, epsilon 0.3889967490627214\n",
      "state terminated\n",
      "episode 4722, reward 2107.0, memory_length 2000, epsilon 0.3889189594921252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4723, reward 1505.0, memory_length 2000, epsilon 0.38884118547788743\n",
      "state terminated\n",
      "episode 4724, reward 1673.0, memory_length 2000, epsilon 0.38876342701689715\n",
      "state terminated\n",
      "episode 4725, reward 1783.0, memory_length 2000, epsilon 0.388685684106044\n",
      "state terminated\n",
      "episode 4726, reward 1596.0, memory_length 2000, epsilon 0.38860795674221826\n",
      "state terminated\n",
      "episode 4727, reward 1831.0, memory_length 2000, epsilon 0.38853024492231086\n",
      "state terminated\n",
      "episode 4728, reward 1825.0, memory_length 2000, epsilon 0.38845254864321327\n",
      "state terminated\n",
      "episode 4729, reward 1798.0, memory_length 2000, epsilon 0.38837486790181774\n",
      "state terminated\n",
      "episode 4730, reward 1529.0, memory_length 2000, epsilon 0.3882972026950169\n",
      "state terminated\n",
      "episode 4731, reward 2107.0, memory_length 2000, epsilon 0.3882195530197043\n",
      "state terminated\n",
      "episode 4732, reward 1764.0, memory_length 2000, epsilon 0.38814191887277383\n",
      "state terminated\n",
      "episode 4733, reward 1981.0, memory_length 2000, epsilon 0.38806430025112015\n",
      "state terminated\n",
      "episode 4734, reward 1740.0, memory_length 2000, epsilon 0.3879866971516385\n",
      "state terminated\n",
      "episode 4735, reward 1456.0, memory_length 2000, epsilon 0.38790910957122493\n",
      "state terminated\n",
      "episode 4736, reward 1453.0, memory_length 2000, epsilon 0.3878315375067757\n",
      "state terminated\n",
      "episode 4737, reward 1830.0, memory_length 2000, epsilon 0.387753980955188\n",
      "state terminated\n",
      "episode 4738, reward 1802.0, memory_length 2000, epsilon 0.38767643991335965\n",
      "state terminated\n",
      "episode 4739, reward 1718.0, memory_length 2000, epsilon 0.3875989143781889\n",
      "state terminated\n",
      "episode 4740, reward 1705.0, memory_length 2000, epsilon 0.3875214043465747\n",
      "state terminated\n",
      "episode 4741, reward 1778.0, memory_length 2000, epsilon 0.3874439098154169\n",
      "state terminated\n",
      "episode 4742, reward 1777.0, memory_length 2000, epsilon 0.3873664307816155\n",
      "state terminated\n",
      "episode 4743, reward 1689.0, memory_length 2000, epsilon 0.3872889672420713\n",
      "state terminated\n",
      "episode 4744, reward 1908.0, memory_length 2000, epsilon 0.38721151919368585\n",
      "state terminated\n",
      "episode 4745, reward 1778.0, memory_length 2000, epsilon 0.38713408663336124\n",
      "state terminated\n",
      "episode 4746, reward 1622.0, memory_length 2000, epsilon 0.38705666955800017\n",
      "state terminated\n",
      "episode 4747, reward 1767.0, memory_length 2000, epsilon 0.38697926796450594\n",
      "state terminated\n",
      "episode 4748, reward 1757.0, memory_length 2000, epsilon 0.3869018818497825\n",
      "state terminated\n",
      "episode 4749, reward 1695.0, memory_length 2000, epsilon 0.3868245112107343\n",
      "state terminated\n",
      "episode 4750, reward 1585.0, memory_length 2000, epsilon 0.3867471560442667\n",
      "state terminated\n",
      "episode 4751, reward 1494.0, memory_length 2000, epsilon 0.3866698163472853\n",
      "state terminated\n",
      "episode 4752, reward 1813.0, memory_length 2000, epsilon 0.38659249211669666\n",
      "state terminated\n",
      "episode 4753, reward 1715.0, memory_length 2000, epsilon 0.38651518334940776\n",
      "state terminated\n",
      "episode 4754, reward 1417.0, memory_length 2000, epsilon 0.3864378900423262\n",
      "state terminated\n",
      "episode 4755, reward 2052.0, memory_length 2000, epsilon 0.38636061219236034\n",
      "state terminated\n",
      "episode 4756, reward 1305.0, memory_length 2000, epsilon 0.38628334979641904\n",
      "state terminated\n",
      "episode 4757, reward 1658.0, memory_length 2000, epsilon 0.38620610285141177\n",
      "state terminated\n",
      "episode 4758, reward 2054.0, memory_length 2000, epsilon 0.38612887135424856\n",
      "state terminated\n",
      "episode 4759, reward 1736.0, memory_length 2000, epsilon 0.3860516553018404\n",
      "state terminated\n",
      "episode 4760, reward 1798.0, memory_length 2000, epsilon 0.3859744546910984\n",
      "state terminated\n",
      "episode 4761, reward 1713.0, memory_length 2000, epsilon 0.38589726951893466\n",
      "state terminated\n",
      "episode 4762, reward 1676.0, memory_length 2000, epsilon 0.3858200997822618\n",
      "state terminated\n",
      "episode 4763, reward 1572.0, memory_length 2000, epsilon 0.385742945477993\n",
      "state terminated\n",
      "episode 4764, reward 1628.0, memory_length 2000, epsilon 0.38566580660304195\n",
      "state terminated\n",
      "episode 4765, reward 1617.0, memory_length 2000, epsilon 0.3855886831543233\n",
      "state terminated\n",
      "episode 4766, reward 1716.0, memory_length 2000, epsilon 0.385511575128752\n",
      "state terminated\n",
      "episode 4767, reward 1750.0, memory_length 2000, epsilon 0.38543448252324386\n",
      "state terminated\n",
      "episode 4768, reward 1708.0, memory_length 2000, epsilon 0.38535740533471496\n",
      "state terminated\n",
      "episode 4769, reward 1806.0, memory_length 2000, epsilon 0.3852803435600823\n",
      "state terminated\n",
      "episode 4770, reward 1857.0, memory_length 2000, epsilon 0.3852032971962635\n",
      "state terminated\n",
      "episode 4771, reward 1954.0, memory_length 2000, epsilon 0.38512626624017665\n",
      "state terminated\n",
      "episode 4772, reward 1630.0, memory_length 2000, epsilon 0.38504925068874046\n",
      "state terminated\n",
      "episode 4773, reward 1671.0, memory_length 2000, epsilon 0.3849722505388744\n",
      "state terminated\n",
      "episode 4774, reward 1872.0, memory_length 2000, epsilon 0.38489526578749833\n",
      "state terminated\n",
      "episode 4775, reward 1662.0, memory_length 2000, epsilon 0.38481829643153304\n",
      "state terminated\n",
      "episode 4776, reward 1629.0, memory_length 2000, epsilon 0.3847413424678996\n",
      "state terminated\n",
      "episode 4777, reward 1962.0, memory_length 2000, epsilon 0.3846644038935199\n",
      "state terminated\n",
      "episode 4778, reward 1546.0, memory_length 2000, epsilon 0.38458748070531645\n",
      "state terminated\n",
      "episode 4779, reward 1740.0, memory_length 2000, epsilon 0.38451057290021223\n",
      "state terminated\n",
      "episode 4780, reward 1624.0, memory_length 2000, epsilon 0.38443368047513105\n",
      "state terminated\n",
      "episode 4781, reward 1555.0, memory_length 2000, epsilon 0.3843568034269971\n",
      "state terminated\n",
      "episode 4782, reward 1812.0, memory_length 2000, epsilon 0.38427994175273533\n",
      "state terminated\n",
      "episode 4783, reward 1440.0, memory_length 2000, epsilon 0.3842030954492712\n",
      "state terminated\n",
      "episode 4784, reward 1179.0, memory_length 2000, epsilon 0.38412626451353105\n",
      "state terminated\n",
      "episode 4785, reward 1644.0, memory_length 2000, epsilon 0.38404944894244153\n",
      "state terminated\n",
      "episode 4786, reward 1602.0, memory_length 2000, epsilon 0.38397264873292997\n",
      "state terminated\n",
      "episode 4787, reward 1789.0, memory_length 2000, epsilon 0.3838958638819245\n",
      "state terminated\n",
      "episode 4788, reward 1683.0, memory_length 2000, epsilon 0.38381909438635353\n",
      "state terminated\n",
      "episode 4789, reward 2105.0, memory_length 2000, epsilon 0.3837423402431464\n",
      "state terminated\n",
      "episode 4790, reward 1726.0, memory_length 2000, epsilon 0.38366560144923295\n",
      "state terminated\n",
      "episode 4791, reward 2039.0, memory_length 2000, epsilon 0.3835888780015437\n",
      "state terminated\n",
      "episode 4792, reward 2208.0, memory_length 2000, epsilon 0.38351216989700954\n",
      "state terminated\n",
      "episode 4793, reward 1786.0, memory_length 2000, epsilon 0.3834354771325622\n",
      "state terminated\n",
      "episode 4794, reward 1709.0, memory_length 2000, epsilon 0.383358799705134\n",
      "state terminated\n",
      "episode 4795, reward 1842.0, memory_length 2000, epsilon 0.38328213761165786\n",
      "state terminated\n",
      "episode 4796, reward 1863.0, memory_length 2000, epsilon 0.3832054908490673\n",
      "state terminated\n",
      "episode 4797, reward 1463.0, memory_length 2000, epsilon 0.38312885941429636\n",
      "state terminated\n",
      "episode 4798, reward 1629.0, memory_length 2000, epsilon 0.3830522433042799\n",
      "state terminated\n",
      "episode 4799, reward 2124.0, memory_length 2000, epsilon 0.38297564251595323\n",
      "state terminated\n",
      "episode 4800, reward 2000.0, memory_length 2000, epsilon 0.38289905704625227\n",
      "state terminated\n",
      "episode 4801, reward 1813.0, memory_length 2000, epsilon 0.3828224868921137\n",
      "state terminated\n",
      "episode 4802, reward 1695.0, memory_length 2000, epsilon 0.3827459320504746\n",
      "state terminated\n",
      "episode 4803, reward 1647.0, memory_length 2000, epsilon 0.38266939251827287\n",
      "state terminated\n",
      "episode 4804, reward 1721.0, memory_length 2000, epsilon 0.3825928682924468\n",
      "state terminated\n",
      "episode 4805, reward 1417.0, memory_length 2000, epsilon 0.3825163593699356\n",
      "state terminated\n",
      "episode 4806, reward 1733.0, memory_length 2000, epsilon 0.38243986574767885\n",
      "state terminated\n",
      "episode 4807, reward 1718.0, memory_length 2000, epsilon 0.3823633874226168\n",
      "state terminated\n",
      "episode 4808, reward 1952.0, memory_length 2000, epsilon 0.38228692439169026\n",
      "state terminated\n",
      "episode 4809, reward 1296.0, memory_length 2000, epsilon 0.38221047665184066\n",
      "state terminated\n",
      "episode 4810, reward 2101.0, memory_length 2000, epsilon 0.38213404420001024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4811, reward 1534.0, memory_length 2000, epsilon 0.3820576270331417\n",
      "state terminated\n",
      "episode 4812, reward 1661.0, memory_length 2000, epsilon 0.3819812251481783\n",
      "state terminated\n",
      "episode 4813, reward 1799.0, memory_length 2000, epsilon 0.38190483854206386\n",
      "state terminated\n",
      "episode 4814, reward 1601.0, memory_length 2000, epsilon 0.381828467211743\n",
      "state terminated\n",
      "episode 4815, reward 1550.0, memory_length 2000, epsilon 0.3817521111541609\n",
      "state terminated\n",
      "episode 4816, reward 1816.0, memory_length 2000, epsilon 0.3816757703662633\n",
      "state terminated\n",
      "episode 4817, reward 1629.0, memory_length 2000, epsilon 0.3815994448449967\n",
      "state terminated\n",
      "episode 4818, reward 1566.0, memory_length 2000, epsilon 0.38152313458730786\n",
      "state terminated\n",
      "episode 4819, reward 1847.0, memory_length 2000, epsilon 0.38144683959014436\n",
      "state terminated\n",
      "episode 4820, reward 1658.0, memory_length 2000, epsilon 0.3813705598504546\n",
      "state terminated\n",
      "episode 4821, reward 1857.0, memory_length 2000, epsilon 0.3812942953651873\n",
      "state terminated\n",
      "episode 4822, reward 1773.0, memory_length 2000, epsilon 0.3812180461312918\n",
      "state terminated\n",
      "episode 4823, reward 1665.0, memory_length 2000, epsilon 0.3811418121457182\n",
      "state terminated\n",
      "episode 4824, reward 1574.0, memory_length 2000, epsilon 0.3810655934054171\n",
      "state terminated\n",
      "episode 4825, reward 1869.0, memory_length 2000, epsilon 0.3809893899073398\n",
      "state terminated\n",
      "episode 4826, reward 1691.0, memory_length 2000, epsilon 0.3809132016484382\n",
      "state terminated\n",
      "episode 4827, reward 1684.0, memory_length 2000, epsilon 0.3808370286256647\n",
      "state terminated\n",
      "episode 4828, reward 1991.0, memory_length 2000, epsilon 0.38076087083597243\n",
      "state terminated\n",
      "episode 4829, reward 1514.0, memory_length 2000, epsilon 0.380684728276315\n",
      "state terminated\n",
      "episode 4830, reward 1865.0, memory_length 2000, epsilon 0.38060860094364674\n",
      "state terminated\n",
      "episode 4831, reward 1641.0, memory_length 2000, epsilon 0.38053248883492263\n",
      "state terminated\n",
      "episode 4832, reward 1787.0, memory_length 2000, epsilon 0.38045639194709807\n",
      "state terminated\n",
      "episode 4833, reward 1871.0, memory_length 2000, epsilon 0.38038031027712926\n",
      "state terminated\n",
      "episode 4834, reward 1660.0, memory_length 2000, epsilon 0.3803042438219729\n",
      "state terminated\n",
      "episode 4835, reward 1926.0, memory_length 2000, epsilon 0.38022819257858637\n",
      "state terminated\n",
      "episode 4836, reward 1806.0, memory_length 2000, epsilon 0.38015215654392753\n",
      "state terminated\n",
      "episode 4837, reward 1546.0, memory_length 2000, epsilon 0.3800761357149551\n",
      "state terminated\n",
      "episode 4838, reward 1960.0, memory_length 2000, epsilon 0.38000013008862804\n",
      "state terminated\n",
      "episode 4839, reward 1741.0, memory_length 2000, epsilon 0.3799241396619063\n",
      "state terminated\n",
      "episode 4840, reward 1750.0, memory_length 2000, epsilon 0.3798481644317502\n",
      "state terminated\n",
      "episode 4841, reward 1802.0, memory_length 2000, epsilon 0.3797722043951207\n",
      "state terminated\n",
      "episode 4842, reward 1848.0, memory_length 2000, epsilon 0.37969625954897945\n",
      "state terminated\n",
      "episode 4843, reward 1650.0, memory_length 2000, epsilon 0.37962032989028865\n",
      "state terminated\n",
      "episode 4844, reward 1734.0, memory_length 2000, epsilon 0.379544415416011\n",
      "state terminated\n",
      "episode 4845, reward 1745.0, memory_length 2000, epsilon 0.3794685161231101\n",
      "state terminated\n",
      "episode 4846, reward 1644.0, memory_length 2000, epsilon 0.3793926320085499\n",
      "state terminated\n",
      "episode 4847, reward 1519.0, memory_length 2000, epsilon 0.379316763069295\n",
      "state terminated\n",
      "episode 4848, reward 1885.0, memory_length 2000, epsilon 0.3792409093023107\n",
      "state terminated\n",
      "episode 4849, reward 1747.0, memory_length 2000, epsilon 0.37916507070456285\n",
      "state terminated\n",
      "episode 4850, reward 1515.0, memory_length 2000, epsilon 0.3790892472730178\n",
      "state terminated\n",
      "episode 4851, reward 2017.0, memory_length 2000, epsilon 0.37901343900464274\n",
      "state terminated\n",
      "episode 4852, reward 1449.0, memory_length 2000, epsilon 0.3789376458964053\n",
      "state terminated\n",
      "episode 4853, reward 1642.0, memory_length 2000, epsilon 0.37886186794527366\n",
      "state terminated\n",
      "episode 4854, reward 2005.0, memory_length 2000, epsilon 0.3787861051482169\n",
      "state terminated\n",
      "episode 4855, reward 1779.0, memory_length 2000, epsilon 0.3787103575022043\n",
      "state terminated\n",
      "episode 4856, reward 1840.0, memory_length 2000, epsilon 0.37863462500420614\n",
      "state terminated\n",
      "episode 4857, reward 1628.0, memory_length 2000, epsilon 0.378558907651193\n",
      "state terminated\n",
      "episode 4858, reward 1501.0, memory_length 2000, epsilon 0.3784832054401362\n",
      "state terminated\n",
      "episode 4859, reward 1820.0, memory_length 2000, epsilon 0.3784075183680077\n",
      "state terminated\n",
      "episode 4860, reward 1282.0, memory_length 2000, epsilon 0.3783318464317799\n",
      "state terminated\n",
      "episode 4861, reward 1603.0, memory_length 2000, epsilon 0.37825618962842605\n",
      "state terminated\n",
      "episode 4862, reward 2037.0, memory_length 2000, epsilon 0.3781805479549199\n",
      "state terminated\n",
      "episode 4863, reward 1504.0, memory_length 2000, epsilon 0.3781049214082357\n",
      "state terminated\n",
      "episode 4864, reward 2056.0, memory_length 2000, epsilon 0.3780293099853484\n",
      "state terminated\n",
      "episode 4865, reward 1807.0, memory_length 2000, epsilon 0.37795371368323344\n",
      "state terminated\n",
      "episode 4866, reward 1953.0, memory_length 2000, epsilon 0.3778781324988672\n",
      "state terminated\n",
      "episode 4867, reward 1419.0, memory_length 2000, epsilon 0.37780256642922627\n",
      "state terminated\n",
      "episode 4868, reward 1716.0, memory_length 2000, epsilon 0.37772701547128806\n",
      "state terminated\n",
      "episode 4869, reward 1874.0, memory_length 2000, epsilon 0.37765147962203055\n",
      "state terminated\n",
      "episode 4870, reward 1646.0, memory_length 2000, epsilon 0.3775759588784322\n",
      "state terminated\n",
      "episode 4871, reward 1872.0, memory_length 2000, epsilon 0.37750045323747233\n",
      "state terminated\n",
      "episode 4872, reward 1737.0, memory_length 2000, epsilon 0.37742496269613063\n",
      "state terminated\n",
      "episode 4873, reward 1286.0, memory_length 2000, epsilon 0.37734948725138745\n",
      "state terminated\n",
      "episode 4874, reward 1631.0, memory_length 2000, epsilon 0.37727402690022377\n",
      "state terminated\n",
      "episode 4875, reward 1462.0, memory_length 2000, epsilon 0.3771985816396213\n",
      "state terminated\n",
      "episode 4876, reward 1535.0, memory_length 2000, epsilon 0.3771231514665621\n",
      "state terminated\n",
      "episode 4877, reward 1718.0, memory_length 2000, epsilon 0.377047736378029\n",
      "state terminated\n",
      "episode 4878, reward 1603.0, memory_length 2000, epsilon 0.37697233637100547\n",
      "state terminated\n",
      "episode 4879, reward 1842.0, memory_length 2000, epsilon 0.3768969514424754\n",
      "state terminated\n",
      "episode 4880, reward 1847.0, memory_length 2000, epsilon 0.3768215815894234\n",
      "state terminated\n",
      "episode 4881, reward 1663.0, memory_length 2000, epsilon 0.3767462268088348\n",
      "state terminated\n",
      "episode 4882, reward 1430.0, memory_length 2000, epsilon 0.37667088709769525\n",
      "state terminated\n",
      "episode 4883, reward 1732.0, memory_length 2000, epsilon 0.3765955624529913\n",
      "state terminated\n",
      "episode 4884, reward 1815.0, memory_length 2000, epsilon 0.37652025287170987\n",
      "state terminated\n",
      "episode 4885, reward 1505.0, memory_length 2000, epsilon 0.3764449583508385\n",
      "state terminated\n",
      "episode 4886, reward 1483.0, memory_length 2000, epsilon 0.37636967888736567\n",
      "state terminated\n",
      "episode 4887, reward 1991.0, memory_length 2000, epsilon 0.37629441447828005\n",
      "state terminated\n",
      "episode 4888, reward 1866.0, memory_length 2000, epsilon 0.37621916512057096\n",
      "state terminated\n",
      "episode 4889, reward 1776.0, memory_length 2000, epsilon 0.37614393081122854\n",
      "state terminated\n",
      "episode 4890, reward 1907.0, memory_length 2000, epsilon 0.3760687115472434\n",
      "state terminated\n",
      "episode 4891, reward 1747.0, memory_length 2000, epsilon 0.3759935073256068\n",
      "state terminated\n",
      "episode 4892, reward 1180.0, memory_length 2000, epsilon 0.3759183181433106\n",
      "state terminated\n",
      "episode 4893, reward 1809.0, memory_length 2000, epsilon 0.3758431439973471\n",
      "state terminated\n",
      "episode 4894, reward 1883.0, memory_length 2000, epsilon 0.3757679848847094\n",
      "state terminated\n",
      "episode 4895, reward 2016.0, memory_length 2000, epsilon 0.3756928408023912\n",
      "state terminated\n",
      "episode 4896, reward 1810.0, memory_length 2000, epsilon 0.3756177117473866\n",
      "state terminated\n",
      "episode 4897, reward 2043.0, memory_length 2000, epsilon 0.3755425977166906\n",
      "state terminated\n",
      "episode 4898, reward 1906.0, memory_length 2000, epsilon 0.37546749870729856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4899, reward 1492.0, memory_length 2000, epsilon 0.3753924147162065\n",
      "state terminated\n",
      "episode 4900, reward 1835.0, memory_length 2000, epsilon 0.37531734574041103\n",
      "state terminated\n",
      "episode 4901, reward 1833.0, memory_length 2000, epsilon 0.3752422917769095\n",
      "state terminated\n",
      "episode 4902, reward 2015.0, memory_length 2000, epsilon 0.3751672528226997\n",
      "state terminated\n",
      "episode 4903, reward 1836.0, memory_length 2000, epsilon 0.37509222887478\n",
      "state terminated\n",
      "episode 4904, reward 1908.0, memory_length 2000, epsilon 0.3750172199301495\n",
      "state terminated\n",
      "episode 4905, reward 1791.0, memory_length 2000, epsilon 0.3749422259858079\n",
      "state terminated\n",
      "episode 4906, reward 1597.0, memory_length 2000, epsilon 0.3748672470387554\n",
      "state terminated\n",
      "episode 4907, reward 1657.0, memory_length 2000, epsilon 0.3747922830859928\n",
      "state terminated\n",
      "episode 4908, reward 1700.0, memory_length 2000, epsilon 0.3747173341245216\n",
      "state terminated\n",
      "episode 4909, reward 1656.0, memory_length 2000, epsilon 0.37464240015134376\n",
      "state terminated\n",
      "episode 4910, reward 1902.0, memory_length 2000, epsilon 0.374567481163462\n",
      "state terminated\n",
      "episode 4911, reward 1728.0, memory_length 2000, epsilon 0.37449257715787954\n",
      "state terminated\n",
      "episode 4912, reward 1812.0, memory_length 2000, epsilon 0.3744176881316002\n",
      "state terminated\n",
      "episode 4913, reward 1917.0, memory_length 2000, epsilon 0.3743428140816285\n",
      "state terminated\n",
      "episode 4914, reward 1467.0, memory_length 2000, epsilon 0.37426795500496934\n",
      "state terminated\n",
      "episode 4915, reward 1642.0, memory_length 2000, epsilon 0.3741931108986285\n",
      "state terminated\n",
      "episode 4916, reward 1714.0, memory_length 2000, epsilon 0.3741182817596121\n",
      "state terminated\n",
      "episode 4917, reward 1793.0, memory_length 2000, epsilon 0.374043467584927\n",
      "state terminated\n",
      "episode 4918, reward 1599.0, memory_length 2000, epsilon 0.37396866837158066\n",
      "state terminated\n",
      "episode 4919, reward 1912.0, memory_length 2000, epsilon 0.3738938841165812\n",
      "state terminated\n",
      "episode 4920, reward 1659.0, memory_length 2000, epsilon 0.373819114816937\n",
      "state terminated\n",
      "episode 4921, reward 1691.0, memory_length 2000, epsilon 0.3737443604696576\n",
      "state terminated\n",
      "episode 4922, reward 1829.0, memory_length 2000, epsilon 0.3736696210717525\n",
      "state terminated\n",
      "episode 4923, reward 1412.0, memory_length 2000, epsilon 0.37359489662023243\n",
      "state terminated\n",
      "episode 4924, reward 1915.0, memory_length 2000, epsilon 0.37352018711210827\n",
      "state terminated\n",
      "episode 4925, reward 2074.0, memory_length 2000, epsilon 0.3734454925443915\n",
      "state terminated\n",
      "episode 4926, reward 1660.0, memory_length 2000, epsilon 0.37337081291409463\n",
      "state terminated\n",
      "episode 4927, reward 1876.0, memory_length 2000, epsilon 0.37329614821823026\n",
      "state terminated\n",
      "episode 4928, reward 1894.0, memory_length 2000, epsilon 0.3732214984538119\n",
      "state terminated\n",
      "episode 4929, reward 1770.0, memory_length 2000, epsilon 0.37314686361785354\n",
      "state terminated\n",
      "episode 4930, reward 1740.0, memory_length 2000, epsilon 0.37307224370736974\n",
      "state terminated\n",
      "episode 4931, reward 1728.0, memory_length 2000, epsilon 0.37299763871937575\n",
      "state terminated\n",
      "episode 4932, reward 1867.0, memory_length 2000, epsilon 0.3729230486508873\n",
      "state terminated\n",
      "episode 4933, reward 1768.0, memory_length 2000, epsilon 0.372848473498921\n",
      "state terminated\n",
      "episode 4934, reward 1644.0, memory_length 2000, epsilon 0.3727739132604936\n",
      "state terminated\n",
      "episode 4935, reward 1898.0, memory_length 2000, epsilon 0.3726993679326227\n",
      "state terminated\n",
      "episode 4936, reward 1641.0, memory_length 2000, epsilon 0.3726248375123266\n",
      "state terminated\n",
      "episode 4937, reward 1753.0, memory_length 2000, epsilon 0.3725503219966242\n",
      "state terminated\n",
      "episode 4938, reward 2038.0, memory_length 2000, epsilon 0.37247582138253454\n",
      "state terminated\n",
      "episode 4939, reward 1672.0, memory_length 2000, epsilon 0.3724013356670779\n",
      "state terminated\n",
      "episode 4940, reward 1783.0, memory_length 2000, epsilon 0.37232686484727473\n",
      "state terminated\n",
      "episode 4941, reward 1875.0, memory_length 2000, epsilon 0.37225240892014616\n",
      "state terminated\n",
      "episode 4942, reward 1559.0, memory_length 2000, epsilon 0.37217796788271396\n",
      "state terminated\n",
      "episode 4943, reward 1606.0, memory_length 2000, epsilon 0.3721035417320006\n",
      "state terminated\n",
      "episode 4944, reward 1758.0, memory_length 2000, epsilon 0.37202913046502895\n",
      "state terminated\n",
      "episode 4945, reward 1271.0, memory_length 2000, epsilon 0.37195473407882257\n",
      "state terminated\n",
      "episode 4946, reward 1962.0, memory_length 2000, epsilon 0.3718803525704056\n",
      "state terminated\n",
      "episode 4947, reward 1757.0, memory_length 2000, epsilon 0.37180598593680275\n",
      "state terminated\n",
      "episode 4948, reward 1641.0, memory_length 2000, epsilon 0.3717316341750394\n",
      "state terminated\n",
      "episode 4949, reward 1872.0, memory_length 2000, epsilon 0.3716572972821415\n",
      "state terminated\n",
      "episode 4950, reward 1505.0, memory_length 2000, epsilon 0.37158297525513545\n",
      "state terminated\n",
      "episode 4951, reward 1941.0, memory_length 2000, epsilon 0.37150866809104854\n",
      "state terminated\n",
      "episode 4952, reward 1955.0, memory_length 2000, epsilon 0.37143437578690836\n",
      "state terminated\n",
      "episode 4953, reward 1998.0, memory_length 2000, epsilon 0.3713600983397433\n",
      "state terminated\n",
      "episode 4954, reward 1783.0, memory_length 2000, epsilon 0.37128583574658225\n",
      "state terminated\n",
      "episode 4955, reward 1649.0, memory_length 2000, epsilon 0.37121158800445464\n",
      "state terminated\n",
      "episode 4956, reward 1471.0, memory_length 2000, epsilon 0.3711373551103906\n",
      "state terminated\n",
      "episode 4957, reward 1854.0, memory_length 2000, epsilon 0.3710631370614208\n",
      "state terminated\n",
      "episode 4958, reward 1817.0, memory_length 2000, epsilon 0.37098893385457654\n",
      "state terminated\n",
      "episode 4959, reward 1714.0, memory_length 2000, epsilon 0.3709147454868897\n",
      "state terminated\n",
      "episode 4960, reward 1864.0, memory_length 2000, epsilon 0.3708405719553927\n",
      "state terminated\n",
      "episode 4961, reward 1581.0, memory_length 2000, epsilon 0.3707664132571187\n",
      "state terminated\n",
      "episode 4962, reward 1678.0, memory_length 2000, epsilon 0.37069226938910116\n",
      "state terminated\n",
      "episode 4963, reward 1944.0, memory_length 2000, epsilon 0.3706181403483745\n",
      "state terminated\n",
      "episode 4964, reward 1892.0, memory_length 2000, epsilon 0.3705440261319735\n",
      "state terminated\n",
      "episode 4965, reward 2089.0, memory_length 2000, epsilon 0.37046992673693363\n",
      "state terminated\n",
      "episode 4966, reward 2020.0, memory_length 2000, epsilon 0.3703958421602908\n",
      "state terminated\n",
      "episode 4967, reward 1624.0, memory_length 2000, epsilon 0.3703217723990818\n",
      "state terminated\n",
      "episode 4968, reward 1951.0, memory_length 2000, epsilon 0.37024771745034374\n",
      "state terminated\n",
      "episode 4969, reward 1980.0, memory_length 2000, epsilon 0.3701736773111144\n",
      "state terminated\n",
      "episode 4970, reward 1879.0, memory_length 2000, epsilon 0.37009965197843225\n",
      "state terminated\n",
      "episode 4971, reward 1660.0, memory_length 2000, epsilon 0.37002564144933614\n",
      "state terminated\n",
      "episode 4972, reward 1849.0, memory_length 2000, epsilon 0.3699516457208657\n",
      "state terminated\n",
      "episode 4973, reward 1964.0, memory_length 2000, epsilon 0.36987766479006123\n",
      "state terminated\n",
      "episode 4974, reward 1691.0, memory_length 2000, epsilon 0.3698036986539634\n",
      "state terminated\n",
      "episode 4975, reward 1672.0, memory_length 2000, epsilon 0.36972974730961355\n",
      "state terminated\n",
      "episode 4976, reward 2020.0, memory_length 2000, epsilon 0.3696558107540536\n",
      "state terminated\n",
      "episode 4977, reward 1907.0, memory_length 2000, epsilon 0.3695818889843262\n",
      "state terminated\n",
      "episode 4978, reward 1632.0, memory_length 2000, epsilon 0.3695079819974744\n",
      "state terminated\n",
      "episode 4979, reward 1782.0, memory_length 2000, epsilon 0.3694340897905419\n",
      "state terminated\n",
      "episode 4980, reward 1889.0, memory_length 2000, epsilon 0.36936021236057304\n",
      "state terminated\n",
      "episode 4981, reward 1269.0, memory_length 2000, epsilon 0.3692863497046127\n",
      "state terminated\n",
      "episode 4982, reward 1755.0, memory_length 2000, epsilon 0.36921250181970644\n",
      "state terminated\n",
      "episode 4983, reward 1657.0, memory_length 2000, epsilon 0.36913866870290035\n",
      "state terminated\n",
      "episode 4984, reward 1660.0, memory_length 2000, epsilon 0.369064850351241\n",
      "state terminated\n",
      "episode 4985, reward 1701.0, memory_length 2000, epsilon 0.3689910467617757\n",
      "state terminated\n",
      "episode 4986, reward 1520.0, memory_length 2000, epsilon 0.3689172579315523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state terminated\n",
      "episode 4987, reward 1704.0, memory_length 2000, epsilon 0.3688434838576193\n",
      "state terminated\n",
      "episode 4988, reward 1318.0, memory_length 2000, epsilon 0.3687697245370257\n",
      "state terminated\n",
      "episode 4989, reward 1547.0, memory_length 2000, epsilon 0.36869597996682113\n",
      "state terminated\n",
      "episode 4990, reward 2141.0, memory_length 2000, epsilon 0.3686222501440558\n",
      "state terminated\n",
      "episode 4991, reward 1684.0, memory_length 2000, epsilon 0.3685485350657805\n",
      "state terminated\n",
      "episode 4992, reward 1852.0, memory_length 2000, epsilon 0.3684748347290467\n",
      "state terminated\n",
      "episode 4993, reward 1848.0, memory_length 2000, epsilon 0.3684011491309063\n",
      "state terminated\n",
      "episode 4994, reward 1900.0, memory_length 2000, epsilon 0.368327478268412\n",
      "state terminated\n",
      "episode 4995, reward 1936.0, memory_length 2000, epsilon 0.3682538221386168\n",
      "state terminated\n",
      "episode 4996, reward 1745.0, memory_length 2000, epsilon 0.36818018073857456\n",
      "state terminated\n",
      "episode 4997, reward 1710.0, memory_length 2000, epsilon 0.3681065540653396\n",
      "state terminated\n",
      "episode 4998, reward 1753.0, memory_length 2000, epsilon 0.3680329421159668\n",
      "state terminated\n",
      "episode 4999, reward 1563.0, memory_length 2000, epsilon 0.3679593448875118\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# to store rewards in each episode\n",
    "rewards_per_episode, episodes, avg_rewards_per_episode= [], [], []\n",
    "\n",
    "env = CabDriver()\n",
    "\n",
    "# agent needs to be initialised outside the loop since the DQN\n",
    "# network will be initialised along with the agent\n",
    "agent = DQNAgent(action_size=len(env.action_space), state_size=len(env.state_encod_arch1(env.state_init)))\n",
    "\n",
    "for episode in range(Episodes):\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    env = CabDriver()  \n",
    "    # Call all the initialised variables of the environment : reset at the start of each episode\n",
    "    action_space, state_space, state = env.reset()\n",
    "    terminal_state = False\n",
    "    t = 0\n",
    "    count = 1\n",
    "    score = 0\n",
    "    \n",
    "    while not terminal_state: \n",
    "        # Write your code here\n",
    "        count += 1\n",
    "        \n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        possible_actions_index, actions = env.requests(state)\n",
    "        action_index, action = agent.get_action(env.state_encod_arch1(state), env.action_space, possible_actions_index)\n",
    "        \n",
    "        # 2. Evaluate your reward and next state\n",
    "        next_state, wait_time, transit_time, ride_time = env.next_state_func(state,action,Time_matrix)\n",
    "        \n",
    "        # Evaluate your reward\n",
    "        reward = env.reward_func(state, action, Time_matrix)\n",
    "        \n",
    "        # 3. Append the experience to the memory : save the sample <s, a, r, s'> to the replay memory\n",
    "        agent.append_sample(env.state_encod_arch1(state), action_index,reward, env.state_encod_arch1(next_state))\n",
    "        \n",
    "        # 4. Train the model by calling function agent.train_model:  train after each step\n",
    "        agent.train_model()\n",
    "        \n",
    "        # 5. Keep a track of rewards, Q-values, loss  \n",
    "        # add reward to the total score of this episode\n",
    "        score += reward\n",
    "        state = next_state\n",
    "        \n",
    "        # Total time spend\n",
    "        t += wait_time + transit_time + ride_time\n",
    "        \n",
    "        # A terminal state is achieved when the cab completes his 30 days\n",
    "        if t >= 24 * 30:\n",
    "            print(\"state terminated\")\n",
    "            terminal_state = True\n",
    "    \n",
    "    # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "    \n",
    "    # epsilon decay\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon = agent.epsilon_min + (agent.epsilon_max - agent.epsilon_min) * np.exp(-agent.epsilon_decay*episode)\n",
    "\n",
    "    # every episode:\n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}\".format(episode,score,len(agent.memory),agent.epsilon))\n",
    "    # every few episodes:\n",
    "    if episode % 10 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        agent.store_q_values()\n",
    "    if episode % 1000 == 0:\n",
    "        # save DQN model \n",
    "        agent.save(name=\"model.pkl\")\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Total time taken ',elapsed_time)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken  28546.709778547287\n"
     ]
    }
   ],
   "source": [
    "elapsed_time = time.time() - start_time\n",
    "print('Total time taken ',elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.206728,\n",
       " 115.867,\n",
       " 123.61004,\n",
       " 147.86449,\n",
       " 176.1898,\n",
       " 193.60503,\n",
       " 178.74902,\n",
       " 201.13472,\n",
       " 209.25653,\n",
       " 216.5821,\n",
       " 188.17383,\n",
       " 196.71022,\n",
       " 203.49542,\n",
       " 216.63905,\n",
       " 239.91301,\n",
       " 229.04991,\n",
       " 225.56624,\n",
       " 236.86151,\n",
       " 235.04945,\n",
       " 224.2493,\n",
       " 221.66077,\n",
       " 227.31396,\n",
       " 239.72188,\n",
       " 211.74734,\n",
       " 214.7296,\n",
       " 234.72775,\n",
       " 230.89044,\n",
       " 230.52042,\n",
       " 240.7764,\n",
       " 225.05533,\n",
       " 224.04683,\n",
       " 230.97867,\n",
       " 243.12509,\n",
       " 243.9142,\n",
       " 256.55588,\n",
       " 237.07907,\n",
       " 241.13356,\n",
       " 246.88058,\n",
       " 241.2524,\n",
       " 255.13544,\n",
       " 254.25531,\n",
       " 242.88397,\n",
       " 253.96791,\n",
       " 244.64256,\n",
       " 228.96013,\n",
       " 241.01263,\n",
       " 243.24425,\n",
       " 234.9004,\n",
       " 246.13144,\n",
       " 256.2481,\n",
       " 245.5256,\n",
       " 236.95576,\n",
       " 241.11642,\n",
       " 242.00925,\n",
       " 243.18309,\n",
       " 264.26385,\n",
       " 247.88196,\n",
       " 234.66197,\n",
       " 238.84314,\n",
       " 250.54462,\n",
       " 249.712,\n",
       " 261.35526,\n",
       " 248.47313,\n",
       " 259.02887,\n",
       " 257.2647,\n",
       " 266.98358,\n",
       " 253.46764,\n",
       " 255.60916,\n",
       " 250.30739,\n",
       " 253.10538,\n",
       " 252.20099,\n",
       " 246.38525,\n",
       " 260.1185,\n",
       " 259.7269,\n",
       " 269.9152,\n",
       " 273.19885,\n",
       " 267.34833,\n",
       " 261.4032,\n",
       " 272.82767,\n",
       " 260.77963,\n",
       " 263.05188,\n",
       " 267.1497,\n",
       " 261.7838,\n",
       " 258.6078,\n",
       " 260.1642,\n",
       " 272.14154,\n",
       " 261.78076,\n",
       " 266.59094,\n",
       " 265.50647,\n",
       " 271.45572,\n",
       " 264.8446,\n",
       " 266.63495,\n",
       " 271.6672,\n",
       " 266.89142,\n",
       " 267.0594,\n",
       " 267.07986,\n",
       " 265.62775,\n",
       " 261.30356,\n",
       " 269.47888,\n",
       " 269.1178,\n",
       " 257.42505,\n",
       " 261.4309,\n",
       " 267.35138,\n",
       " 268.61728,\n",
       " 263.9014,\n",
       " 274.10287,\n",
       " 277.31973,\n",
       " 278.23932,\n",
       " 279.5381,\n",
       " 266.72467,\n",
       " 264.82837,\n",
       " 274.6934,\n",
       " 272.70316,\n",
       " 277.385,\n",
       " 272.14044,\n",
       " 266.79025,\n",
       " 277.2246,\n",
       " 273.99814,\n",
       " 273.7195,\n",
       " 268.75784,\n",
       " 276.5869,\n",
       " 276.65942,\n",
       " 278.38626,\n",
       " 282.09396,\n",
       " 273.95886,\n",
       " 280.614,\n",
       " 269.26523,\n",
       " 265.242,\n",
       " 272.20877,\n",
       " 270.31406,\n",
       " 281.99033,\n",
       " 271.99393,\n",
       " 279.6283,\n",
       " 277.8888,\n",
       " 271.41727,\n",
       " 278.36566,\n",
       " 277.3427,\n",
       " 281.09488,\n",
       " 285.13593,\n",
       " 282.6879,\n",
       " 284.5709,\n",
       " 270.37332,\n",
       " 271.31647,\n",
       " 271.16812,\n",
       " 283.8889,\n",
       " 285.44742,\n",
       " 277.89948,\n",
       " 290.5285,\n",
       " 282.14374,\n",
       " 278.1897,\n",
       " 282.2063,\n",
       " 284.23984,\n",
       " 285.93436,\n",
       " 277.8398,\n",
       " 284.08804,\n",
       " 293.0437,\n",
       " 285.1447,\n",
       " 282.68008,\n",
       " 272.43747,\n",
       " 281.08893,\n",
       " 283.61926,\n",
       " 280.3554,\n",
       " 292.3276,\n",
       " 281.65735,\n",
       " 277.86462,\n",
       " 281.3613,\n",
       " 288.2188,\n",
       " 282.26318,\n",
       " 282.1065,\n",
       " 290.10858,\n",
       " 284.24277,\n",
       " 278.5082,\n",
       " 282.87778,\n",
       " 285.5548,\n",
       " 283.1546,\n",
       " 283.6206,\n",
       " 290.39734,\n",
       " 282.45563,\n",
       " 282.34756,\n",
       " 276.6372,\n",
       " 273.0925,\n",
       " 274.595,\n",
       " 279.62354,\n",
       " 288.6535,\n",
       " 276.15717,\n",
       " 279.18015,\n",
       " 282.63376,\n",
       " 280.02652,\n",
       " 279.34152,\n",
       " 284.9871,\n",
       " 282.67813,\n",
       " 278.29092,\n",
       " 277.41696,\n",
       " 281.68448,\n",
       " 284.52228,\n",
       " 283.6171,\n",
       " 287.5547,\n",
       " 288.99225,\n",
       " 284.1657,\n",
       " 282.20233,\n",
       " 275.93488,\n",
       " 279.7227,\n",
       " 273.52618,\n",
       " 285.10803,\n",
       " 277.6356,\n",
       " 285.43344,\n",
       " 281.90503,\n",
       " 276.91818,\n",
       " 283.44586,\n",
       " 281.53305,\n",
       " 285.2478,\n",
       " 287.39923,\n",
       " 283.88968,\n",
       " 283.58218,\n",
       " 278.68216,\n",
       " 279.61697,\n",
       " 284.4531,\n",
       " 282.28088,\n",
       " 276.83383,\n",
       " 282.83875,\n",
       " 277.1693,\n",
       " 275.9641,\n",
       " 283.12985,\n",
       " 284.54086,\n",
       " 290.87274,\n",
       " 285.51956,\n",
       " 284.03867,\n",
       " 286.67435,\n",
       " 277.5928,\n",
       " 281.07733,\n",
       " 283.89523,\n",
       " 280.23184,\n",
       " 273.21475,\n",
       " 275.81,\n",
       " 275.70654,\n",
       " 278.75757,\n",
       " 290.1484,\n",
       " 282.511,\n",
       " 285.44046,\n",
       " 285.32233,\n",
       " 284.9639,\n",
       " 280.62836,\n",
       " 279.45294,\n",
       " 274.42337,\n",
       " 291.09415,\n",
       " 292.1627,\n",
       " 286.7046,\n",
       " 287.5271,\n",
       " 283.10724,\n",
       " 282.15057,\n",
       " 288.55972,\n",
       " 280.1745,\n",
       " 288.40582,\n",
       " 287.61624,\n",
       " 285.2143,\n",
       " 284.9145,\n",
       " 283.8419,\n",
       " 286.831,\n",
       " 283.97372,\n",
       " 286.40216,\n",
       " 281.60626,\n",
       " 282.1278,\n",
       " 285.11246,\n",
       " 287.34338,\n",
       " 280.9267,\n",
       " 289.9236,\n",
       " 279.4287,\n",
       " 282.06058,\n",
       " 283.48337,\n",
       " 276.99274,\n",
       " 288.97534,\n",
       " 283.714,\n",
       " 277.9866,\n",
       " 280.42474,\n",
       " 286.45154,\n",
       " 284.3104,\n",
       " 281.0694,\n",
       " 286.35324,\n",
       " 281.13004,\n",
       " 285.8991,\n",
       " 284.3549,\n",
       " 291.95416,\n",
       " 285.6887,\n",
       " 283.95496,\n",
       " 287.6126,\n",
       " 287.40637,\n",
       " 284.85977,\n",
       " 288.01767,\n",
       " 283.93655,\n",
       " 291.03284,\n",
       " 288.45728,\n",
       " 289.53323,\n",
       " 286.98648,\n",
       " 285.13583,\n",
       " 289.06314,\n",
       " 291.55936,\n",
       " 287.36987,\n",
       " 290.02103,\n",
       " 283.96814,\n",
       " 284.6762,\n",
       " 288.6249,\n",
       " 290.4526,\n",
       " 294.61258,\n",
       " 290.659,\n",
       " 289.6675,\n",
       " 287.6315,\n",
       " 287.0979,\n",
       " 289.30347,\n",
       " 297.31055,\n",
       " 296.30835,\n",
       " 297.83594,\n",
       " 286.72952,\n",
       " 289.28754,\n",
       " 294.3316,\n",
       " 287.3518,\n",
       " 283.65152,\n",
       " 285.6193,\n",
       " 286.5491,\n",
       " 288.63785,\n",
       " 285.51627,\n",
       " 290.57446,\n",
       " 286.03946,\n",
       " 293.12143,\n",
       " 290.4344,\n",
       " 295.21747,\n",
       " 296.70316,\n",
       " 286.28845,\n",
       " 289.55008,\n",
       " 288.3744,\n",
       " 290.33423,\n",
       " 286.8112,\n",
       " 285.48776,\n",
       " 286.63733,\n",
       " 286.2912,\n",
       " 292.27792,\n",
       " 286.85748,\n",
       " 287.90567,\n",
       " 292.65274,\n",
       " 284.92773,\n",
       " 291.05463,\n",
       " 287.4968,\n",
       " 293.37558,\n",
       " 288.88892,\n",
       " 292.91824,\n",
       " 287.0704,\n",
       " 288.73813,\n",
       " 293.86597,\n",
       " 287.23608,\n",
       " 290.69028,\n",
       " 291.81802,\n",
       " 293.06436,\n",
       " 287.5186,\n",
       " 286.74283,\n",
       " 289.90112,\n",
       " 292.22733,\n",
       " 292.44745,\n",
       " 289.80353,\n",
       " 289.6988,\n",
       " 282.40945,\n",
       " 288.14072,\n",
       " 293.53906,\n",
       " 295.90088,\n",
       " 297.1746,\n",
       " 294.74252,\n",
       " 293.0573,\n",
       " 296.19528,\n",
       " 291.16928,\n",
       " 287.50177,\n",
       " 289.8459,\n",
       " 292.2199,\n",
       " 288.26895,\n",
       " 294.26236,\n",
       " 292.745,\n",
       " 297.50327,\n",
       " 290.09058,\n",
       " 291.12537,\n",
       " 300.3725,\n",
       " 298.7856,\n",
       " 296.04623,\n",
       " 300.22882,\n",
       " 296.92828,\n",
       " 293.16776,\n",
       " 293.28986,\n",
       " 291.9453,\n",
       " 293.21118,\n",
       " 295.1317,\n",
       " 292.8535,\n",
       " 294.62534,\n",
       " 296.33728,\n",
       " 290.36633,\n",
       " 297.92117,\n",
       " 295.4424,\n",
       " 292.41104,\n",
       " 293.9533,\n",
       " 291.38528,\n",
       " 296.52164,\n",
       " 300.7026,\n",
       " 299.2426,\n",
       " 296.7854,\n",
       " 295.5126,\n",
       " 292.1352,\n",
       " 296.48297,\n",
       " 297.9992,\n",
       " 293.77234,\n",
       " 298.74228,\n",
       " 301.92953,\n",
       " 299.79938,\n",
       " 293.3798,\n",
       " 295.52454,\n",
       " 294.21576,\n",
       " 296.13885,\n",
       " 296.00717,\n",
       " 293.7967,\n",
       " 300.3398,\n",
       " 292.51672,\n",
       " 288.81757,\n",
       " 296.14948,\n",
       " 298.48376,\n",
       " 294.22836,\n",
       " 290.4624,\n",
       " 288.22867,\n",
       " 288.0822,\n",
       " 292.79068,\n",
       " 290.62842,\n",
       " 289.8751,\n",
       " 293.60544,\n",
       " 294.6125,\n",
       " 287.83014,\n",
       " 290.25992,\n",
       " 297.22415,\n",
       " 292.93848,\n",
       " 297.32184,\n",
       " 295.20767,\n",
       " 291.09134,\n",
       " 293.81137,\n",
       " 293.09973,\n",
       " 293.87814,\n",
       " 297.14355,\n",
       " 291.35666,\n",
       " 291.17374,\n",
       " 289.14713,\n",
       " 291.31296,\n",
       " 293.30807,\n",
       " 289.54385,\n",
       " 293.68536,\n",
       " 295.21808,\n",
       " 286.27945,\n",
       " 294.0016,\n",
       " 294.4556,\n",
       " 293.24503,\n",
       " 299.21033,\n",
       " 295.59714,\n",
       " 298.03406,\n",
       " 295.23737,\n",
       " 295.67334,\n",
       " 285.08087,\n",
       " 295.25708,\n",
       " 296.47964,\n",
       " 290.60684,\n",
       " 292.31378,\n",
       " 287.60394,\n",
       " 290.66867,\n",
       " 291.53348,\n",
       " 291.0401,\n",
       " 292.2213,\n",
       " 297.05737,\n",
       " 295.60272,\n",
       " 289.59442,\n",
       " 291.19717,\n",
       " 296.9184,\n",
       " 291.03278,\n",
       " 291.5309,\n",
       " 294.47467,\n",
       " 296.01373,\n",
       " 293.35065,\n",
       " 293.29208,\n",
       " 297.26935,\n",
       " 294.437,\n",
       " 295.19565,\n",
       " 293.22403,\n",
       " 291.84445,\n",
       " 288.4234,\n",
       " 292.65335,\n",
       " 293.22153,\n",
       " 290.20346,\n",
       " 293.21298,\n",
       " 297.7235,\n",
       " 293.02646,\n",
       " 296.1391,\n",
       " 297.66843,\n",
       " 295.46024,\n",
       " 298.1628,\n",
       " 296.41745,\n",
       " 297.14337,\n",
       " 295.37515,\n",
       " 296.97113,\n",
       " 297.98703,\n",
       " 294.77954,\n",
       " 297.12415,\n",
       " 298.2841]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.states_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Convergence by tracking total rewards per episode vs episode number\n",
    "plt.plot(list(range(len(rewards_per_episode))), rewards_per_episode)\n",
    "plt.ylabel(\"total rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-219.11, -146.87, -75.15, 21.84, 81.24, 105.2, 197.18, 247.06, 311.91, 365.35, 457.11, 470.23, 549.26, 613.66, 664.72, 703.2, 812.42, 827.98, 831.19, 855.74, 927.45, 962.11, 985.68, 1045.19, 1105.85, 1154.9, 1210.34, 1217.01, 1272.38, 1292.5, 1284.81, 1315.02, 1359.77, 1385.16, 1409.15, 1480.54, 1470.93, 1503.57, 1529.66, 1569.64, 1574.06, 1623.57, 1586.69, 1613.73, 1630.62, 1686.74, 1699.7, 1732.75, 1721.79, 1764.45]\n"
     ]
    }
   ],
   "source": [
    "# Average reward per 100 episode\n",
    "avg_rewards = []\n",
    "episodes = len(rewards_per_episode)\n",
    "index = 0\n",
    "track_total_reward = 0\n",
    "for episode_number in range(episodes):\n",
    "    if index != 100:\n",
    "        track_total_reward += rewards_per_episode[episode_number]\n",
    "        index += 1\n",
    "    else:\n",
    "        avg_rewards.append(track_total_reward/index)\n",
    "        track_total_reward = rewards_per_episode[episode_number]\n",
    "        index = 1\n",
    "\n",
    "avg_rewards.append(track_total_reward/index)\n",
    "        \n",
    "    \n",
    "print(avg_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8lfX9///Hi7BnGGEThmwQEMJwUVcrrjrqBCviAFv9Wb9trdra2urHDlc/HRaLiopVcI+2WledlRWUKXsHYhJGQsger98f56KfqAEO8ZxcycnzfrvllnO9z3XOeV0a8sz1fr+v623ujoiISE00CrsAERGpvxQiIiJSYwoRERGpMYWIiIjUmEJERERqTCEiIiI1phAREZEaU4iIiEiNKURERKTGGoddQLx16tTJ+/TpE3YZIiL1xpIlS3a5e0o0+yZ8iPTp04f09PSwyxARqTfMbGu0+6o7S0REakwhIiIiNaYQERGRGlOIiIhIjSlERESkxhQiIiJSY3EPETObbWbZZrayStszZrY0+NpiZkuD9j5mVlTluYeqvGaMma0wsw1m9kczs3jXLiIih1YbZyKPA5OqNrj7Je4+yt1HAS8AL1Z5euOB59z9uirtM4HpwIDg6wvvKSIiEYu37OGh9zfWymfFPUTc/QNgT3XPBWcTFwNzD/UeZtYNaOvu8z2yKPwc4LxY1yoiUp8Vl1Xwm9dWc/Ff5zN30TYKS8vj/plhX7F+IpDl7uurtPU1s0+BfcDt7v4h0APIqLJPRtAmIiLAyh15/PDZpazL2s9l41L52VlDaNk0/r/iww6Ry/jiWUgmkOruu81sDPCymQ0Dqhv/8IO9qZlNJ9L1RWpqagzLFRGpXe7Ogk17aNrYGNilDW2aN/nC8+UVlcx8byN/eGc9HVo15bErx3Ly4M61Vl9oIWJmjYELgDEH2ty9BCgJHi8xs43AQCJnHj2rvLwnsPNg7+3us4BZAGlpaQcNGxGRuuyj9bu45401LM/I+29bj+QWDO7ahkFd29AvpTVPLtjKsu25nDOyO3edO4zklk1rtcYwz0ROA9a4+3+7qcwsBdjj7hVm1o/IAPomd99jZvlmNgFYCFwB/CmUqkVE4mzZ9lzueWMN/9mwmx7JLfjdd46mY6tmrM3KZ83n+az9fB/vr8uhvNJJbtmEP08+hrNHdA+l1riHiJnNBU4COplZBnCHuz8KXMpXB9QnAneaWTlQAVzn7gcG5b9HZKZXC+D14EtEJGFsyN7PfW+s5V+rPqdDq6b84uyhTJmQSrPGSQCcNrTLf/ctLa9k864CurZtTruWTQ72lnFnkclOiSstLc11K3gRqWsKS8tZuWMfyzNyWZaRx/KMXLbuLqRV0ySundiPa07sR+tm4XQWmdkSd0+LZt+wB9ZFRBqUtz/L4r4317IuK5/K4G/47u2aM7JXMpPHpXLhmJ50bN0s3CKPgEJERKSWPL1wG7e/vIIBndtwwykDGNmzHSN6JpPSpv6ExpcpRERE4szd+cM76/nft9dz8qAUHpwyulau4agNiXEUIiJ1VEWl8/NXVvL0wm1cOKYnv7ngaJokJc69bxUiIiJxUlxWwY1zP+XNz7L4/klHcfPpg0i0e8cqRERE4mBPQSkznkwnfetefnnOUK48vm/YJcWFQkREJJBXVMbrKzI5Y3i3I772oryikmUZuXy4fhcfrt/F0u25JJnxp8vCuxCwNihERESAdVn5zHhyCZt3FXDPG2u5ZdIgLhrTi0aNDt79VFxWwavLdvL2Z1nM37ib/JJyzGBEj3Zc941+nD2iO0O6ta3Fo6h9ChERafBeW5HJj59bRsumjbn/opHMXbSNW15YwdMLt/Grc4czqlfyF/bPzCviyflbmbtoG3sLy+iR3IKzR3bjhP4pHHdUR9q3qt37V4VJISIiDVZFpXPvG2t56P2NHJOazMwpY+jarjkXjO7By0t38OvX1nDeg//h4rSe/GTSYLbtKWT2R5t5feXnuDvfHNqFacf3ZXzfDgk3YB4t3fZERBqkvQWl3DjvUz5cv4vJ41O545yh/71H1QH5xWX86d8bmP3RZhqZUVpRSZvmjbkkrRdTj+tDrw4tQ6o+vnTbExERIoPdmXnF5BaWkVtUyt7CMvIKS8ktLOOZ9O1k7yvhtxcczaXjql93qE3zJvz0zCFcnNaTRz/awpBubfjO6J60CumeVnWR/kuISEL6eOMufvriCrbsLqz2+d4dW/LMjAkck9r+sO/Vv3MbfnPB0bEuMSEoREQkoeQVlvGb11czb/F2endsya/PP5qUNs1o37IJyS2b0K5FU9q1aELTxolz1XiYFCIikjBeX5HJL15dxZ6CUq77xlHcdNoAmjdJOvwLpcYUIiJS72XtK+YXr6zkjVVZDOvelseuHMvwHu3CLqtBiPv5nJnNNrNsM1tZpe2XZrbDzJYGX2dWee42M9tgZmvN7PQq7ZOCtg1mdmu86xaRum9FRh43P7eMife8y3trc7j1jMG8cv3xCpBaVBtnIo8DfwbmfKn99+5+X9UGMxtKZNncYUB34G0zGxg8/SDwTSADWGxmr7r7Z/EsXETqnpLyCv65PJM587eydHsuLZsmceGYnkyf2I/eHVuFXV6DE/cQcfcPzKxPlLufC8xz9xJgs5ltAMYFz21w900AZjYv2FchItJA7Cko5dGPNjFv0XZ2F5TSL6UVd5wzlO+M6Unb5uGtMd7QhTkmcoOZXQGkAz9y971AD2BBlX0ygjaA7V9qH18rVYpIqPKLy3jkw808+tFmCkrL+eaQLlxxbB+O79+xwV4lXpeEFSIzgbsAD77fD1wFVPcT4VQ/dnPQS+3NbDowHSA1tfqLiEQkXOUVlWzdU0iP5BbVzqAqLqtgzvwtzHxvI3sLyzhjeFd++M2BDOjSpvaLlYMKJUTcPevAYzN7GPhHsJkB9Kqya09gZ/D4YO3Vvf8sYBZEbnsSg5JFJIZKyiuYOnsRCzbtwQx6JLfgqJTW9EtpxVEprSmrqOSh9zeSta+EiQNT+PG3BjKiZ/Lh31hqXSghYmbd3D0z2DwfODBz61XgaTN7gMjA+gBgEZEzlAFm1hfYQWTwfXLtVi0iseDu/OT55SzYtIebThsAwKacAjbm7GfR5j0UlVUAMKZ3e/5w6TFM6NcxzHLlMOIeImY2FzgJ6GRmGcAdwElmNopIl9QWYAaAu68ys2eJDJiXA9e7e0XwPjcAbwBJwGx3XxXv2kUk9u57cy2vLN3JzacP4vqT+3/hucpK5/N9xeQVlTG4axuNedQDuouviNSauYu2cduLK7hsXC9+ff7RCok66kju4qubx4hIrXhvbTa3v7ySbwxM4a5zhytAEoRCRETibtXOPK5/6hMGdWnDg1NG0zhJv3oShf5Pikhc7cwt4qrHF9OuRRMemzaW1lqLI6Ho/6aIxJy7s3LHPp5N384rS3fgDs9/7zi6tG0edmkSYwoREYmZvQWlvLx0B88s3s6az/Np1rgRZwzvyrUT+zGoqy4STEQKERH5Wtyd+Zt28/TCbby5KovSikpG9GzHXecN59sju9Ouhe5rlcgUIiJSI7mFpbzwyQ6eWriVTTkFtGvRhMnjU7k4rRdDu7cNuzypJQoRETkiS7fn8uT8rfxj+U5Kyis5JjWZ+y8ayVkjumkVwQZIISIiUSkqreB//vkZTy3cRqtgDY/J41MZ1l0LQDVkChEROazPdu7jxnmfsiF7P9Mn9uPGUwdoqq4AChEROYTKSuexj7fwu9fXkNyyCX+7ejwnDOgUdllShyhERKRaOfkl/Pi5Zby/LofThnThngtH0KFV07DLkjpGISIiX1BaXsmLn2Rw35tryS8u567zhnP5+FTd60qqpRARESCykuAzi7fz0PsbycwrZmSvZO69cAQDtZKgHIJCRCTB7S0o5d9rsiksLadn+5b0bN+CHu1b0LJp5J9/QUk5Ty3cyqwPNrNrfwlj+7Tnd98ZwYkDOunsQw5LISKSgLLzi3ljVRb/WpnJgk17qKj86rpBHVo1pUdyC7bvLSS3sIwT+nfihlO0kqAcmdpY2XA2cDaQ7e7Dg7Z7gXOAUmAjMM3dc82sD7AaWBu8fIG7Xxe8ZgzwONACeA34gSf6iloiR6Cy0nl60TZe/nQHS7btxR36dWrFjIn9OGN4Nzq3bUbG3iIy9hayI7eIjL1F7NhbRK8OLbjmxH6MTm0f9iFIPVQbZyKPA38G5lRpewu4zd3Lzex3wG3ALcFzG919VDXvMxOYDiwgEiKTgNfjVbRIfVJaXsnNzy/jlaU7Gdy1DTedOpAzju7KgM6tv9Al1aVtc8b0VlhI7MQ9RNz9g+AMo2rbm1U2FwAXHuo9zKwb0Nbd5wfbc4DzUIiIsK+4jO/9bQn/2bCbm08fxPdPOkpjGVJr6sKYyFXAM1W2+5rZp8A+4HZ3/xDoAWRU2ScjaBNp0LL2FTN19iI2ZO/ngYtHcsHonmGXJA1MqCFiZj8DyoGngqZMINXddwdjIC+b2TCguj+rDjoeYmbTiXR9kZqaGtuiReqI9Vn5TJ29iLyiMh6bNpYTB6SEXZI0QKEtj2tmU4kMuE85MEDu7iXuvjt4vITIoPtAImceVf/E6gnsPNh7u/ssd09z97SUFP3DksSzaPMevjPzY8oqnWdmHKsAkdCEciZiZpOIDKR/w90Lq7SnAHvcvcLM+gEDgE3uvsfM8s1sArAQuAL4Uxi1i9SWotIKPlyfQ2ZeMZl5xWTtKyYzr4isfSVs21NI744teWLaOHp1aBl2qdKA1cYU37nASUAnM8sA7iAyG6sZ8FYwAHhgKu9E4E4zKwcqgOvcfU/wVt/j/6b4vo4G1SWB5eSXcNXji1mxIw+AJklGl7bN6dq2OcO6t40sOXtiP9rrXlYSMkv0Sy3S0tI8PT097DJEorZ5VwFTZy8iO7+Yey8cybFHdaRDy6Y0aqQZV1I7zGyJu6dFs29dmJ0lIoFPt+3l6icif/TMvXYCx+gCQKnjFCIidcQ7q7O4/ulP6NymOU9cNY6+nVqFXZLIYSlEROqAuYu28bOXVjC8RzsenTqWlDbNwi5JJCoKEZEQVVQ6D7y1lgff3chJg1J4cPJoWmnZWalH9NMqEpLcwlJunLeUD9blcNm4Xtx57nCaJIV26ZZIjShEREKwamce1/1tCVl5JfzmgqO5bJzurCD1k0JEpJa9+EkGt724gvYtm/LMDM3AkvpNISJSS0rLK/mff37GnPlbmdCvA3+ePJpOrTWALvWbQkSkFuQXl3H1E+ks2ryH6RP78ZPTB9FY4x+SABQiInGWV1jGFY8tYtWOPP5w6SjOHaVVDCRxKERE4mhvQSmXP7qQ9Vn7mXn5GL45tEvYJYnElEJEJE527S/h8kcWsmlXAbOuGMNJgzqHXZJIzB1Rp6yZtTezEfEqRiRRZO8r5tJZC9iyu4DHrhyrAJGEddgQMbP3zKytmXUAlgGPmdkD8S9NpH7KzCviklkL2JlbxOPTxnF8/05hlyQSN9GcibRz933ABcBj7j4GOC2+ZYnUT9v3FHLxX+ezK7+EJ68ex4R+HcMuSSSuogmRxmbWDbgY+Eec6xGptzbm7Ofiv85nX1E5f7tmPGN6dwi7JJG4iyZE7gTeADa4++Jg2dr1R/IhZjbbzLLNbGWVtg5m9paZrQ++tw/azcz+aGYbzGy5mY2u8pqpwf7rgzXaReqE1Zn7uOSv8ymrqGTe9AmM7JUcdkkiteKwIeLuz7n7CHf/frC9yd2/c4Sf8zgw6UtttwLvuPsA4J1gG+AMImurDwCmAzMhEjpEltYdD4wD7jgQPCJhWrY9l0tnLaBxo0bMm34sQ7q1DbskkVpz0Cm+ZvYn4KBr57r7jdF+iLt/YGZ9vtR8LpG11wGeAN4Dbgna53hk3d4FZpYcdKedBLx1YM11M3uLSDDNjbYOkVhbtHkPVz2+mPatmvD0NRPo1aFl2CWJ1KpDnYmkA0uA5sBoIl1Y64FRQEUMPruLu2cCBN8PzIHsAWyvsl9G0Haw9q8ws+lmlm5m6Tk5OTEoVeSrPlyfwxWzF9K5bTOenXGsAkQapIOeibj7EwBmdiVwsruXBdsPAW/GsSarrpxDtH+10X0WMAsgLS3toGdTIkfK3fl0ey7PpWfwwpIM+qW04m/XjNeNFKXBiuaK9e5AG2BPsN06aPu6ssysm7tnBt1V2UF7BtCryn49gZ1B+0lfan8vBnWIHFb2vmJe/HQHz6VvZ2NOAc2bNOKckd35+dlDSG7ZNOzyREITTYj8FvjUzN4Ntr8B/DIGn/0qMDV4/6nAK1XabzCzeUQG0fOCoHkD+HWVwfRvAbfFoA6Rg5q/cTcPf7iJ99flUFHppPVuz28v6MdZI7rRpnmTsMsTCd0hQ8TMDHgbeJ3IL3SAW9398yP5EDObS+QsopOZZRCZZfVb4FkzuxrYBlwU7P4acCawASgEpgG4+x4zuwtYHOx354FBdpFY25C9n9++vpq3V2fTuU0zZkzsx4VjetIvpXXYpYnUKRaZBHWIHcyWBFep10tpaWmenp4edhlST+zaX8If3l7P04u20bJJEt8/uT/Tju9D8yZJYZcmUmuC3/tp0ewbTXfWAjMb6+6LD7+rSP1UXFbB7P9s5i/vbqSorIIp41P5wakD6KgBc5FDiiZETgZmmNlWoIDILCl3d93NVxJCYWk5l81awLKMPE4b0oXbzhzMUeq2EolKNCFyRtyrEAlJRaVz49xPWbEjj5lTRnPG0d3CLkmkXjlsiLj7VgAz60zkwkORhODu/Orvq3h7dTZ3nTtMASJSA9GsJ/JtM1sPbAbeB7YQma0lUq89+tFm5szfyvSJ/fjusX3CLkekXormLr53AROAde7eFzgV+E9cqxKJs9dXZHL3a6s58+iu3DppcNjliNRb0YRImbvvBhqZWSN3f5fI/bNE6qUlW/dy0zNLOaZXMg9cPIpGjaq7o46IRCOagfVcM2sNfAA8ZWbZQHl8yxKJj627C7h2Tjpd2zXn4SvSdP2HyNcUTYicCxQB/w+YArQjslCVSL2RmVfEs4szeGrhVtydx6eN0zUgIjEQTYhcAnzo7uuJrPshUi+UVVTy7zXZzFu0jffX5VDpcEL/TtwyaTB9O7UKuzyRhBBNiPQBLg8WlUoHPiQSKkvjV5bI4ZWUV7Axu4D84jIKSsvJLy6noKSCgpJyPt9XzKvLdpKTX0LnNs34/kn9uWRsL635IRJj0Vwn8gsAM2sBXAvcDPwvoM5kqVUl5RUs257Hgk27WbBpN0u27qWkvLLafZMaGScNTOHScamcPCiFxknRzCERkSN12BAxs9uB44msI/Ip8GMiZyMitWLJ1j3c/+a6/4aGGQzp2pYp43szuncy7Vs2pVWzxrQOvlo1S6JV08aadSVSC6LpzrqAyGysfxK52HCBuxfHtSqRQHFZBTfOXUp5ZSVTxvdmQr8OjOvbQQtBidQR0XRnjTazNsAJwDeBh80sy91PiHt10uA9+tFmduQW8fS14znuqE5hlyMiXxJNd9Zw4EQiKxqmAdtRd5bUgux9xTz47gZOH9ZFASJSR0XTnfU7Ihca/hFY7O5lsfhgMxsEPFOlqR/wCyCZyAB+TtD+U3d/LXjNbcDVQAVwo7u/EYtapG669421lFVU8tMzh4RdiogcRDTdWWcFM7NSYxUgwfuuJbh9ipklATuAl4gsh/t7d7+v6v5mNhS4FBgGdAfeNrOB7l4Rq5qk7liRkcfzn2Qw/cR+9O6oazpE6qpo7uJ7DrAU+FewPcrMXo1xHacCGw/cdv4gzgXmuXuJu28msgb7uBjXIXWAu3PXPz6jQ8umXH9K/7DLEZFDiGby/C+J/LLOBQguMuwT4zouBeZW2b7BzJab2Wwzax+09SAyHnNARtD2FWY23czSzSw9Jyenul2kDnt95ecs2rKHH31rEG2bNwm7HBE5hGhCpNzd8+JVgJk1Bb4NPBc0zQSOItLVlQncf2DXal7u1b2nu89y9zR3T0tJSYlxxRJPxWUV/Pq11Qzu2oZLxvYKuxwROYxoQmSlmU0GksxsgJn9Cfg4hjWcAXzi7lkA7p7l7hXuXgk8zP91WWUAVX+r9AR2xrAOqQNm/2czGXuL+MU5Q0nSxYIidV40IfL/ERnMLgGeBvKAm2JYw2VU6coys6prlJ4PrAwevwpcambNzKwvMABYFMM6JGTZ+4p58N8b+NZQTekVqS8OOTsrmDX1K3e/GfhZrD/czFoSuYBxRpXme8xsFJGuqi0HnnP3VWb2LPAZkSvor9fMrMSRV1jGbS+uoFRTekXqlUOGiLtXmNmYeH24uxcCHb/U9t1D7H83cHe86pHa5+68vHQHd/9zNXsLy7jtjMH00W3aReqNaC42/DSY0vscUHCg0d1fjFtV0iBszNnP7S+tZP6m3YzqlcwTVw1nWPd2YZclIkcgmhDpAOwGTqnS5oBCRGqkuKyCv7y7gYfe30TzJo24+/zhXDY2VXfdFamHorlifVptFCINw/qsfGY8uYRNuwo4b1R3fnbWUFLaaJlakfoqmjMRkZh4+7MsbnpmKc2bJPG3q8dzwgDNwBKp7xQiEnfuzsz3N3LvG2sZ3r0ds64YQ7d2LcIuS0RiQCEicVVUWsEtLyzn1WU7OWdkd+75zghaNNXKyiKJIpr1RH5YTXMesCS4j5ZItTLzipg+Zwkrd+Zx8+mD+P5JR2GmwXORRBLNmUha8PX3YPssYDFwnZk95+73xKs4qb/Wfp7P5Y8upLCknIe/m8ZpQ7uEXZKIxEE0IdIRGO3u+wHM7A7geWAisARQiMgXbMzZz5RHFpDUyHjp+uMZ2KVN2CWJSJxEEyKpQGmV7TKgt7sXmVlJfMqS+mrr7gImP7wAgKeumUD/zq1DrkhE4imaEHkaWGBmrwTb5wBzzawVkftYiQCQsbeQyQ8vpLS8knnTj1WAiDQA0VxseJeZvQacQGRNj+vcPT14eko8i5P64/O8YqY8spB9xWXMvXYCg7qqC0ukIYhmdtYfgGfc/Q+1UI/UQzn5JUx+ZAG78kv42zXjGd5D978SaSiiWU/kE+B2M9tgZveaWVq8i5L6Y29BKd99dCGZucU8Nm0cx6S2P/yLRCRhHDZE3P0Jdz+TyAqD64Dfmdn6uFcmdV55RSXXP/0Jm3YV8MjUNMb17RB2SSJSy6I5EzmgPzAY6AOsiUs1Uq/c+8ZaPt64m7vPG87x/XUfLJGG6LAhYmYHzjzuBFYBY9z9nFgVYGZbzGyFmS01s/SgrYOZvWVm64Pv7YN2M7M/Bl1ry81sdKzqkCPzz+WZ/PWDTVw+IZWL0nqFXY6IhCSaM5HNwLHuPsndZ7t7bhzqONndR7n7gfGWW4F33H0A8E6wDXAGkbXVBwDTgZlxqEUOY31WPjc/v4xjUpP5xdnDwi5HREIUzRTfh8ysvZmNA5pXaf8gjnWdC5wUPH4CeA+4JWif4+5O5NqVZDPr5u6ZcaxFqthXXMaMJ5fQsmljZk4ZQ9PGR9IjKiKJJprurGuAD4A3gF8F338ZwxoceNPMlpjZ9KCty4FgCL53Dtp7ANurvDYjaPtyzdPNLN3M0nNycmJYasNWWen86NllbNtTyF+mjKZru+aHf5GIJLRo/oz8ATAW2OruJwPHALH8zXy8u48m0lV1vZlNPMS+1d0C1r/S4D7L3dPcPS0lJSVWdTZ4f3lvA299lsXPzhqimVgiAkR325Nidy82M8ysmbuvMbNBsSrA3XcG37PN7CUiU4mzDnRTmVk3IDvYPQOoOorbE9gZq1rkq0rKK1iTmc/HG3dz/1vrOG9Ud648rk/YZYlIHRFNiGSYWTLwMvCWme0lRr+4g/tvNXL3/ODxt4jMAnsVmAr8Nvh+4L5drwI3mNk8YDyQp/GQ2MrJL+GDdTksy8hlWUYeq3fuo7SiEoAxvdvzmwtGaE0QEfmvaAbWzw8e/tLM3gXaAf+K0ed3AV4Kfik1Bp5293+Z2WLgWTO7GtgGXBTs/xpwJrABKASmxagOAfYUlHLmHz8kJ7+EVk2TOLpnO6ad0IdRPZMZ2SuZbu2aK0BE5AuOaHlcd38/lh/u7puAkdW07wZOrabdgetjWYP8n5+/spLcwlLmXjuBcX07kNRIgSEih6b5mQLA35ft5J/LM7nptIEce1RHBYiIREUhImTvK+bnr6xkVK9kZkzsF3Y5IlKPKEQaOHfnthdXUFRawf0Xj6Rxkn4kRCR6+o3RwD23JIN31mTzk0mDOSpFKxGKyJFRiDRgO3KLuPPvnzG+bwem6doPEakBhUgDVVnp3PL8cirdue+ikTTSQLqI1IBCpIF6auFWPtqwi9vPGkqvDi3DLkdE6imFSAP01mdZ3P3aaiYOTOGycVoLRERqTiHSgLg7sz/azPQn0xnUpQ0PXDxSV6CLyNdyRFesS/1VXlHJnf/4jDnzt3L6sC787yXH0KJpUthliUg9pxBpAPaXlHPD05/w3tocpk/sx62TBmsgXURiQiGS4DLzipj22GLWZ+/n1+cfzeTxqWGXJCIJRCGSwNZn5XP5owspKKngsSvHMnGgFugSkdhSiCSozbsKmPzIQgBe+N5xDOraJuSKRCQRKUQSUMbeQqY8vICKSueZ6RMY0EUBIiLxoSm+CebzvGImP7yQ/SXlPHn1OAWIiMRVaCFiZr3M7F0zW21mq8zsB0H7L81sh5ktDb7OrPKa28xsg5mtNbPTw6q9rtq1v4QpjyxgT0Epc64ez7Du7cIuSUQSXJjdWeXAj9z9EzNrAywxs7eC537v7vdV3dnMhgKXAsOA7sDbZjbQ3Stqteo6KrewlMsfWciO3CLmXDWeUb2Swy5JRBqA0M5E3D3T3T8JHucDq4Eeh3jJucA8dy9x981E1lkfF/9K6759xWVcMXsRm3YV8MgVYxnXt0PYJYlIA1EnxkTMrA9wDLAwaLrBzJab2Wwzax+09QC2V3lZBgcJHTObbmbpZpaek5MTp6rrhk05+7ngLx/z2c59zJwymhMGdAq7JBFpQEIPETNrDbwA3OTu+4CZwFHAKCATuP/ArtW83Kt7T3ef5e5p7p6WkpK410b8e00W5z74H3bvL2HOVeM4dUiXsEsSkQZsbDfBAAAKyElEQVQm1Cm+ZtaESIA85e4vArh7VpXnHwb+EWxmAFVvOdsT2FlLpdYplZXOg+9u4IG31zG0W1v++t0x9Gyv27mLSO0Lc3aWAY8Cq939gSrt3arsdj6wMnj8KnCpmTUzs77AAGBRbdVbV+wvKed7Ty3h/rfWce7I7jx/3XEKEBEJTZhnIscD3wVWmNnSoO2nwGVmNopIV9UWYAaAu68ys2eBz4jM7Lq+oc3M2ryrgGvnpLN5VwG3nzWEq0/oq1u5i0ioQgsRd/+I6sc5XjvEa+4G7o5bUXVYYWk50x5bRF5RGU9eNY7j+msAXUTCp9ue1BP3/GstW3YX8vS14znuKAWIiNQNoc/OksP7eOMuHv94C1ce10cBIiJ1ikKkjssvLuPm55bTt1Mrbpk0OOxyRES+QN1ZddyvX1tNZl4Rz113rJazFZE6R2ciddi7a7OZu2g7107sx5jeupWJiNQ9CpE6Kq+wjFtfWM7ALq35f6cNDLscEZFqqTurjvrl31exa38pj1wxluZN1I0lInWTzkTqoH+t/JyXPt3BDSf35+ieWhNEROounYnUEWUVlby3NodnFm/n3bXZDOvelhtO6R92WSIih6QQCdmG7P08l76dFz7Zwa79JXRq3YxrTuzL1cf3pUmSThRFpG5TiITk87xifjDvUxZu3kNSI+OUwZ25OK0XJw1KUXiISL2hEAnB9j2FTH5kAXsLyrj1jMFcMLoHnds0D7ssEZEjphCpZRtz9jPl4YUUlVXw1DXjGam10EWkHlOI1KLVmfv47qORFYDnTZ/AkG5tQ65IROTrUYjUkqXbc5k6exEtmybxt2vGc1RK67BLEhH52urdCK6ZTTKztWa2wcxuDbueaCzctJspDy+gXYsmPDvjWAWIiCSMehUiZpYEPAicAQwlsgri0HCrOrRl23OZ+tgiurZrzrMzjqVXBy1lKyKJo16FCDAO2ODum9y9FJgHnBtyTQdVWl7Jzc8vo33Lpjwz41i6ttMMLBFJLPUtRHoA26tsZwRtddLM9zayLms//3PecDq1bhZ2OSIiMVffQqS6Ndn9KzuZTTezdDNLz8nJqYWyvmp9Vj5/fnc954zszqlDuoRSg4hIvNW3EMkAelXZ7gns/PJO7j7L3dPcPS0lJaXWijugstK55YXltGrWmDvOqdNDNiIiX0t9C5HFwAAz62tmTYFLgVdDrukrnlywlU+25fLzs4aqG0tEElq9uk7E3cvN7AbgDSAJmO3uq0Iu6wt25BZxz7/WcOKATlwwus4O14iIxES9ChEAd38NeC3sOqrj7tz+0goqHX59/tGYVTeEIyKSOOpbd1ad9uqynby7Nocfnz5I14OISIOgEImRPQWl/OrvnzGyVzJXHtcn7HJERGqFQiQGyisq+eGzS9lXVMbvvnM0SY3UjSUiDUO9GxOpa9ydO15dxXtrc7j7/OEM7qo784pIw6Ezka/prx9s4qmF27juG0cxZXzvsMsREalVCpGv4R/Ld/Lb19dw9ohu/OT0QWGXIyJS6xQiNZS+ZQ8/fHYZY/u0576LRtJI4yAi0gApRGpg864Crp2TTo/kFsz6bhrNmySFXZKISCgUIkdo9/4SrnxsEWbG49PG0r5V07BLEhEJjULkCBSXVTD9ySV8nlfMw1ek0btjq7BLEhEJlab4Rqmy0vnRc8v4ZNte/jJ5NGN6tw+7JBGR0OlMJEr3vrmWfy7P5LYzBnPG0d3CLkdEpE5QiERh7qJtzHxvI5PHp3Ltif3CLkdEpM5QiBzGB+tyuP3llXxjYAp3fnuY7swrIlKFQuQQ1ny+j+8/9QkDOrfmz5OPoXGS/nOJiFSl34oHkb2vmKseW0yrZkk8Nm0sbZo3CbskEZE6J5QQMbN7zWyNmS03s5fMLDlo72NmRWa2NPh6qMprxpjZCjPbYGZ/tDj2KxWWlnP1E+nkFpXx6NSxdGvXIl4fJSJSr4V1JvIWMNzdRwDrgNuqPLfR3UcFX9dVaZ8JTAcGBF+T4lVcIzP6B11Yw3u0i9fHiIjUe6FcJ+Lub1bZXABceKj9zawb0Nbd5wfbc4DzgNfjUV/zJkn8/pJR8XhrEZGEUhfGRK7ii2HQ18w+NbP3zezEoK0HkFFln4ygTUREQhS3MxEzexvoWs1TP3P3V4J9fgaUA08Fz2UCqe6+28zGAC+b2TCguvEPP8RnTyfS9UVqamrND0JERA4pbiHi7qcd6nkzmwqcDZzq7h68pgQoCR4vMbONwEAiZx49q7y8J7DzEJ89C5gFkJaWdtCwERGRryes2VmTgFuAb7t7YZX2FDNLCh73IzKAvsndM4F8M5sQzMq6AnglhNJFRKSKsG7A+GegGfBWMFN3QTATayJwp5mVAxXAde6+J3jN94DHgRZExlDiMqguIiLRC2t2Vv+DtL8AvHCQ59KB4fGsS0REjkxdmJ0lIiL1lEJERERqzIKJUQnLzHKArTV8eSdgVwzLqS903A2Ljrthiea4e7t7SjRvlvAh8nWYWbq7p4VdR23TcTcsOu6GJdbHre4sERGpMYWIiIjUmELk0GaFXUBIdNwNi467YYnpcWtMREREakxnIiIiUmMKkWqY2SQzWxusonhr2PXEk5nNNrNsM1tZpa2Dmb1lZuuD7+3DrDHWzKyXmb1rZqvNbJWZ/SBoT+jjBjCz5ma2yMyWBcf+q6C9r5ktDI79GTNrGnatsWZmScEyE/8IthP+mAHMbEuwKuxSM0sP2mL2s64Q+ZLgBpAPAmcAQ4HLzGxouFXF1eN8dZXIW4F33H0A8E6wnUjKgR+5+xBgAnB98P840Y8bInfJPsXdRwKjgElmNgH4HfD74Nj3AleHWGO8/ABYXWW7IRzzAScHq8UemNobs591hchXjQM2uPsmdy8F5gHnhlxT3Lj7B8CeLzWfCzwRPH6CyCqSCcPdM939k+BxPpFfLD1I8OMG8Ij9wWaT4MuBU4Dng/aEO3Yz6wmcBTwSbBsJfsyHEbOfdYXIV/UAtlfZboirKHYJbr9P8L1zyPXEjZn1AY4BFtJAjjvo1lkKZANvARuBXHcvD3ZJxJ/5/wV+AlQG2x1J/GM+wIE3zWxJsGAfxPBnPaxbwddlR7SKotRfZtaayF2jb3L3fcGyBAnP3SuAUWaWDLwEDKlut9qtKn7M7GwgO1jo7qQDzdXsmjDH/CXHu/tOM+tMZPmNNbF8c52JfFUG0KvK9iFXUUxQWWbWDSD4nh1yPTFnZk2IBMhT7v5i0Jzwx12Vu+cC7xEZF0o2swN/VCbaz/zxwLfNbAuR7ulTiJyZJPIx/5e77wy+ZxP5o2EcMfxZV4h81WJgQDBzoylwKfBqyDXVtleBqcHjqSTYKpJBf/ijwGp3f6DKUwl93PDf1UOTg8ctgNOIjAm9C1wY7JZQx+7ut7l7T3fvQ+Tf87/dfQoJfMwHmFkrM2tz4DHwLWAlMfxZ18WG1TCzM4n8pZIEzHb3u0MuKW7MbC5wEpE7e2YBdwAvA88CqcA24KIqK0zWe2Z2AvAhsIL/6yP/KZFxkYQ9bgAzG0FkIDWJyB+Rz7r7ncFy1POADsCnwOXuXhJepfERdGf92N3PbgjHHBzjS8FmY+Bpd7/bzDoSo591hYiIiNSYurNERKTGFCIiIlJjChEREakxhYiIiNSYQkRERGpMISIiIjWmEBERkRpTiIiISI39/+svgQbQtfT0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Check Convergence by tracking average rewards per episode vs episode number\n",
    "plt.plot(list(range(len(avg_rewards))), avg_rewards)\n",
    "plt.ylabel(\"avg rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(12,8))\n",
    "plt.title('Q_value for state [0,0,0] action (0,2)')\n",
    "xaxis = np.asarray(range(0, len(agent.states_tracked)))\n",
    "plt.semilogy(xaxis,np.asarray(agent.states_tracked))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0003*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
